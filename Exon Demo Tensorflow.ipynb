{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Sequence Models to do Exon Calling in TF2.0\n",
    "\n",
    "CpG islands were kind of a simple problem that the sequence models were basically too overpowered to do a very good job with, so for this demo, maybe we can do something more interesting.\n",
    "\n",
    "In eukaryotic cells, the transcripts produced by RPolII aren't the final messanger RNA, but rather pre-mRNA, that then gets processed by the [Spliceosome](https://en.wikipedia.org/wiki/Spliceosome), producing the final mRNA that then gets translated by ribosomes.\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/RNA_splicing) has a pretty good picture of this process.\n",
    "\n",
    "![title](images/splicesome.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "Last time we built a convolutional neural network to predict CpG islands, then looked at some of the other architectures people use for sequence prediction.\n",
    "\n",
    "Today, we'll look at practical sequence models, and how they apply to the problem of exon calling and splice prediction.\n",
    "\n",
    "Useful links:\n",
    "\n",
    "* [Tensorflow Docs](https://www.tensorflow.org/tutorials/)\n",
    "* [Keras Docs](https://keras.io/)\n",
    "* [Seq2Seq in Tensorflow 2.0](https://machinetalk.org/2019/03/29/neural-machine-translation-with-attention-mechanism/)\n",
    "* [Seq2Seq Paper](https://arxiv.org/abs/1409.3215)\n",
    "* [Luong Attention Paper](https://arxiv.org/abs/1508.04025)\n",
    "\n",
    "Hopefully ready for next time:\n",
    "\n",
    "* [Transformer in Tensorflow 2.0](https://machinetalk.org/2019/04/29/create-the-transformer-with-tensorflow-2-0/)\n",
    "* [Transformer Paper](https://arxiv.org/abs/1706.03762)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "We can use the same libraries as last time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard lib\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "# 3rd party libraries\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.0.0\n",
      "Eager mode:  True\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exon Data\n",
    "\n",
    "I took the first 10,000 genes from the GRCh38 human genome, chopped out every section labeled `transcript` then marked all the parts within labeled `exon` or `intron` as `E` or `I` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_gene = []\n",
    "raw_data_seq = []\n",
    "raw_data_cls = []\n",
    "\n",
    "with open('short_transcripts.txt', 'rt') as fp:\n",
    "    gene, seq, cls = None, None, None\n",
    "    for line in fp:\n",
    "        if line.startswith('#'):\n",
    "            if seq is not None and cls is not None:\n",
    "                raw_data_gene.append(gene)\n",
    "                raw_data_seq.append(seq)\n",
    "                raw_data_cls.append(cls)\n",
    "            seq, cls = None, None\n",
    "            gene = line.split(' ', 1)[1].strip()\n",
    "            continue\n",
    "        line = line.strip()\n",
    "        if seq is None:\n",
    "            seq = line\n",
    "        elif cls is None:\n",
    "            cls = line\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HES4\n"
     ]
    }
   ],
   "source": [
    "print(raw_data_gene[104])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCTGGAATAATAAATACGTTTTCTCTGCTACAGTCTCGGCAAAGGCCACGGCCCTAGAACGGGGCGCCGCCTCCGATGCAGTCTCAGGGCCACAGCCTCAGCGCAGCCACGGCCTCCAGGGCCCACCCGGGCCCTGCGGCCCCGCCCTGGGGGCGGCGGGCAGCGCCCGGGTCAGACCCGGCAGCAGCGGCGGCGCGAGCAGAGGGAAGGGGCCGCCGAGCGATGGCAGCAGCGGGCGGCCCGCGTAGACCTCGGGCGCTGGGGCCTCTGCGGGGGCAGCCGGGGACAGCGAGGCCGGGCGGCGGGAGGGTCCCAGCTGGCGCAGGCAGGCTGCCAGGTGGCCCAGCAGGCGGGAGCGCACGTCGGCCGGGACGCCCTCGCAGCCGGCCAGGAAGCGGTTCACCTCCGCCAGACACTCGTGGAAGCCGGCGCGGTACTTGCCCAGAACGGCGGGGTCGGCGCTGAGCGCGGCTGCGGGAGCGACACAGGAGGAGAGGTCGGTGCCGGGTCCCGGGGGTCCCGCGCCCTCCCCCCGCCTCCAAGCCGCCGCCGCCCGCGCCTCACCCGTCACCTGCACGCGACGCAGGCTCCGCAGGTGTCTCACGGTCATCTCCAGGATGTCCGCCTTCTCCAGCTTCGAGTGGCGGGAGCTCTGGGGGCGGGGATAGGCGGGAGGTCCAGGTCAGCTGCGACCCAGACTCCGGGTCTCGGGCCTTCGCCCCCGACTTACCTCTTTTCTGAGGGCGTCCAGGATGAGGGTTTTGAGCTGAGCGAGGCTCTCGTTAATACGCGCTCGGCGCCGCTTCTCCATGACCGGCTTGGAGGACTGCGGGTCGGGCACCGGCTGAGTCCCGCGTCCCTCCCGCCCCCCGGTCGCCCCCCTCACGCCCGGCCGGGACCCCACCTTGCGGTGCTCGGCCGCGCTCCGGGGCTTGTCTGGGGTCCGGCTGGCGCTGGCCGGCGCTCCTGCCATCGGCGAGGCGCTCGGTTTCCCCGGCGTGTCTGCGGCCATGGTGCGCCCCGCGCCTCCCCGTGCCGGGTGGAGCGCGCCGCCACGGACCACGGGCGGGCTGGCGGGCGAGCGGCGAGCGCGCGGCGATCCGAGCCCCTAGGGCGGATCCCGGCTCCAGGCCCGCGCGCGCCTCAGGCCGTTTCCCTATTTAAGGCCTCGCCGCCGCGGGGTGTGTGAACCCGGCTCCGCATTCTTTCCC\n"
     ]
    }
   ],
   "source": [
    "print(raw_data_seq[104])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n"
     ]
    }
   ],
   "source": [
    "print(raw_data_cls[104])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to hack with the data a bit to make keras's native tokenizer work with it, specifically by spliting each record into k-mers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should probably be larger, like 9 or 11, but for demo purposes...\n",
    "NUM_K: int = 6\n",
    "\n",
    "def split_into_kmers(raw_seq: str, raw_cls: str, k: int = NUM_K):\n",
    "    \"\"\" Split a sequence into padded k-mers \"\"\"\n",
    "    seq_kmers = []\n",
    "    cls_kmers = []\n",
    "    for i in range(0, len(raw_seq), k):\n",
    "        seq_kmers.append(raw_seq[i:i+k])\n",
    "        cls_kmers.append(raw_cls[i:i+k])\n",
    "    if len(seq_kmers[-1]) < k:\n",
    "        seq_kmers[-1] = seq_kmers[-1] + 'X'*(k-len(seq_kmers[-1]))\n",
    "        cls_kmers[-1] = cls_kmers[-1] + 'X'*(k-len(cls_kmers[-1]))\n",
    "    return ' '.join(seq_kmers), ' '.join(cls_kmers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "788\n"
     ]
    }
   ],
   "source": [
    "# Reduce the dataset size so it runs on a laptop\n",
    "kmer_data = [split_into_kmers(seq, cls) for seq, cls in zip(raw_data_seq, raw_data_cls)\n",
    "             if len(seq) < 2000]\n",
    "print(len(kmer_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('TGAGGT TGTTGG GAAAAA TTTAAT CAGCTA CAGATA TTTTAA GTACCA AAGGCT GCCTCT GGAGGG AAAAGA AAACTA CCCCTC TGGTTC TGGTTG ACAGAA GTATGT ATTATC AGATTC CCTGTG AGGCTT TACATC CCATGT TTGCTG GAGAAC AGAGGG ATTCTC TAAGAG TGTAGT GATTTC TTCAGA TAGTTC CTTCAT CTTGCC TTCAAT TATTTC AGAGGC TTAAAA GAAAAG AATATA AATATT AGCAAC ACCAGG AACTGA ATAATA CAAGTC TTTCAA TATCTC CAGCTA ACCTTT GCACCA TTTTGG CTTGCT CCAAAG GGTCTC CATGTT TGAGGC AAAACT AAATAG ACACAG CTTTGC ATCTTC CCTGAT AAACAT GAAGAG ACCTCA CAGGAA AGCAAT GAACAC TTTACA AGTCTT CCAAAA GCTGCT GTCTCT GCTAAA GAACAG CTTATA CAAGTC AAGGCC TGCCAT AATGCC TAGGGC AATCCA GGCACT ATCTGC CACTGA GCATAA ATTTAC TGAAGC TATCCA GGCTGG TATTCT CTCTAA TAGTGC ATAATA GAGCAA TGGAAA AATAAG CTGCCC TTGGAC ACTAAG CCTGTC TCTTGC ATCTCC CTACAA AGAAAT CAAATA CTATTT TATTTT ATTTTA TTTTAT GTTTTA TTTTAT TTTAAT TTTATT TTATAC AAATCC AAGGAA ATCTGC TCTTCT ATGAGT GGCCTA GACCAG GGATCA GCAAAC TGTTTT TGTAAA TAAAAT TTTATT GGAACA CAGCCA TGCTTG TTCACT TACATA TTGTCT ATGGTT GCTTTC CTGCTA CAACAG CAGAAT TGAGTA GTTGCC GCAGGA ACTGCA TGGCTC ATAAGC CTAAGA TATTTA CTCTCT GACCTT ACAGAA AGTCTG TCAACC CCTGGC CTAGAC TATGAT GACTCT AACCAC AACAGC CCCCAC ATATAC ATTTAT AGGTGT ACTTAT ATTTTT TTTTTC CTGGCC CAAGGT GCATTC CATTTT CCCCAA ACACTA ACTCTG TCATGG GCTGTC ATGCGT GTCCTG CTAACT GTGCCA GTCAAA TGGGAG TATCTC AAAGGG GCAAGA TCCTGT GAGGCG AGTCCT ATAATA CCCGCC TCTATA CCAAGA TGACAG CTTGTC CATGAG AGAAAT GAACAA TCCTCG AAGATT CCATCT TACCCT CACAGG CAGTCC CCATTA TTCCCA GTCATG TATTCA TTTCAG CTTATT TCCAAC TCAGCT ATCCTT GGCTCT GAAAAG CTGTCA TCACTG GCATCA CTGTAT CTATCA CTAGAT TAAAAG AGGAAC TAATTT AGCAAG GTATAA AAAAAA AACCTG GACAAT TATTCA ATTTGC AATTTC AAACAC ATTCCA TATTAA CCCCTT AGTATG AGAGAA AATACT AAAGAA TATTCT TTTAGC ACTTTC TAGTCA CCACAG GAAGAG GTCAGT CCAATC ACATGC AATGGC CTCXXX',\n",
       " 'EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEI IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEXXX')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmer_data[104]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to add a special token to the output sequence to mark the beginning (`<start>`) and the end (`<end>`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_data, cls_data = zip(*kmer_data)\n",
    "seq_data = list(seq_data)\n",
    "cls_data = list(cls_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_data_in = ['<start> ' + cls for cls in cls_data]\n",
    "cls_data_out = [cls + ' <end>' for cls in cls_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CAGCTC CTGAGA CTGCTG GCATGA AGGGGA GCCGTG CCCTCC TGCTGG TGGCCC TCACCC TGTTCT GCATCT GCCGTG AGTCTG TGCCAC TGGGGT TTCCAG AACATT CAGGGG TGGGGG GGAGTG GGGGGT ACCTGA GAAGGT AAAATC CTGGCA TCGGGC CTCTGC AGTGAA CACTCC ACCTGC TTCTGT CACAGA AGTGGG CAAGGA CCCTGC AGAACC CGCGCC CACCCT ACTCCA CCCCAA CCAAGG ACAAAG CCCAGC TGACCC AACACC AGCCCA GTGTCT CCTACC CCAGCC CAGTCC AGCCTG ACCTGA CCCTTC AAGCCT CTGGTC ATAATA GCCTCT CATCAG GGGAAA TTTCCC CCACAC CAGGAG CTTAAC TTTCCT TCCCTG GTGATC CCAGGG AATGCT GAGTGG AAATTG GAGCAG CTAAGA TTAAGG GGGATG TGGAGG GGTCTT CGGGCA AGGTGG AGTTGG AGGTGT TGTGGA GGAAGC CCTGGG GAGGAG AGGTGG GCATTG AAGGGG AAGGTC TGGAGA CCATGG AGGTTG GAGCCC TGGGGC AGGTCC AGGGCT GTGGTT GCACCA GAGTCA CCCTGT CCTGTC CTGGCA TCATCT CGCTCG TGATGC AGGGAT GGCCAC AGGGGA GGACAA CGATGA GTTTTT CATGGA CTTCCT GCAAAC ACTACT GGTGGG GACCCC AGAGGA GCTCTA TGAGGG GACCTT GGGCAA GTACAA TGTCAA CGAAGA TGCCAA GGCAGC AATGAC TGAACT CAAGTC CTGTAT AGATGG CCTGCA GCCAAT GCACAA GGCGGA GCTGGT CAAGCT GCTGGT ATGAGG GCGGCG GGCACC CCATTT TCTAAA GATCTG CAGCCT TACCAA GACCAC CCAACA CAGCAC CCACAC AGCCTA CCCCAC CCACAG ACATCC ACCACC CACAGA CATTGC ACCCGC ATCAGC CAGCTC AGGTGG ACACCC CAGACC TCCTGT CCACCG AGCAGC CCCCAG ACTCCA TAGACC TCCTCC CCAGTC TGTGGG ATACTC CTCCAT GCACAC ATGTGA ACATAC ACAGAG ATCCAA ACACAG GTGCAG ACATGA AATGTA CACTGC GTGCAC ACATGT ATAAAC ACGTTC ACACCC ACATGC TCACAC TGGGAT ATGCAC ACACAT ACATGT GTGCAC ACCATC ACATGT GCACAC ACACCT CCCAGC TGCTGG GAGGAG ATAGGC AGCAAT ATGCCA GACCCC CCCCCA CTGAGG GCCTTG CTTGCC TGATGG AGCTGT GGCTCT CCACTT ATTGAG CACAGC CCTCTT AGTCCA CATGTG TCTGCC TTCCAG GTGCAA GTGCTG GGCAGT CAGGAC GGTGCC TAAGTG GACCTC AGACAT GGCTCA GCCATA GGACCT GCCACA CAAGCA GCCGTG GACACA ACGCCC ACTACC ACCTCC CACATG GAAATG TATCCT CAAACC GTTTAA TCAATA AAGCCT CTTCCG',\n",
       " 'GGCTCA AGTTCC ACATTG GTATCA ACCGGT ACGAGC TGTACT CCAGAC ACAACC CGGCCA TCGAGG CCCTGC TGCACG ACCTCA GCTCCC AGAGGA TCACCA GCGTGG GTAGGT GTCCTT GGGTGC ACTCAG GGCCGT CTGTGT GCCGGC TGTGTG GCATCA GGGCTG CTGGGG CAGGCT ATGTGT TAGAGA GGTCTG GGAGGC CGTTGC TCATTA CGGCAG CGTCAC CTCCTG CAGCAA TCTGCA CGGGCA GCGAGG AGGGAC AGAGGG CTCGCG TCTCGT GTGCTC TCACAC TGGATG TGCTCC TGATCT GCCGCA CGATGA GCGGGG AGACGC CTGGAC AGCCGG TCCACT GCGCTC TGCGTC CTCACC TGGGTG GTCCCG GGGGTG CCAACT GGATGA CAGAGT CCTTCC CTCCTG GGGTAG AGGAAT AGAGGG GTATCT CTGGCG GCGGTG ACCCCT CCACCG GAAGCG TGTGCA TGGAAC TCTCCT GCTTTT CTACAC ACGACC CTGGCT GGGTGG GGAGAC AGCCAT GAGCCT GCTTCT TGTGGT TTTGAA GCCGTC CTTCGT CAGACC TCAGCA AGGCGC TGTGCA GTTTCA TACTGA GGAGAC ATAGGC AGGGCT CAGGAC GGAGGC CTGGGC CTCCCA GATGGA GGAGTT TGAAGG CAACAT CTCCAG GTACTT TGGGAT CTGCTG AATTGG ACAAAA AAGGGC ATCCAG TTGCTG ATTTCA GGAAAA TATGCC ACTGCA GCTTCT GAGCGT GGAGGT TTGGTG CCATTG TTCTCA GCTTGT AGGCGA TTGTTT GTGAAG GTCCCA TTTGTC ACCAGT GCTTGG AGAGGT AGTGAG GGCGGG GCTGAG GCCCTT TAGTGG GAGCAG CTGCTC CCCGGG GATTGC AGGGAG TGGGCC TGGGTG CACACA GCTGTG GGCAGG TGCAGA GGCCAT GACAGC CTGAAG GCAGGG CTTTCT TTGCGC TGTGTG ATGAGG CCAGCA GTCCCA GGCATT AGCTTC ATGTGT GTCTCA GAAGCA ACCTTG GTGCTG AAAGGG TCCCAG CAGCCT GGGGTT CTGTCC AGTTGC TGACAC AGGACT TAGGTG TCCCCT TTCAGG CCAGCA GGTAGG TTCTCC TGAGCT CTTCGG GGCTGT TTCTGG CTCTCT CTGCCG GGTGCT GAGTTG TTTGCT GGGCAC TCACCT GGTCAT GGGGAG ACAGAA CTTGCA GCTCTC TCCCCA CCCCTT GATCAG CTCACC TCATAA CAGAGA TCAGCT GGACAA GCTGGG AGTCCT CTTCCC TCCATG CTGCCT GGGAGT AACCTG AACCCC TGCCCC CCTCCA GGCCCC CCTCCG TGAAAG CGCTGC CTTTCT CCTGCC CCTGCA GCGGTC TGAGGG CTTTCA GCTGTG CTGGGG AACAGT CCTGCA GACAGC CACAGC CAGAAC GTCCCT TCTGCC CCTGAG AGTGAG CATGGC CATTAA GGAAAT ATCCGA TGCATT GATCAA CATGTT TGTCCA TTCAGC AGATTT TACTGG CACCTC CTGCAT GTCAGA CCCCCT TTCTGG GTGGTG GGGAGT TGAGGA TGAGTT CAGCCT CAACGA GATCTG CTGCCT CTGTGG ACCTGA CAGCCC CAGGAA GAGACA CACACG CACAGT GCCCGA TCCTGA GGAGGA ACGAGC ACTTCA GAGCCG TGCACG CCAGCC AGGCCG TGTGGA GAGGAG GGGGCT CCACTG GGAGGG GCTGAG GACCTT CCACAG GGTCTG TCGGGC AGCTTA CCTTCC AGGTGG GTCCGT CTTGGC AGGGAG AGGAAT GAGAGA GCCGTG CACACC AGCCAG GGCGTT CGGGAG GAGCAG CACGCA AGTTAG AAAGTC CCCAGT GCCGCT GTCCGT ATGAGC TTCTCT CCAGCT CATTTT CCCCAT CTGTCC AGTGGG ATCTCG CTGCGT GGGACC AATGCA AGGATA GGATGA GXXXXX',\n",
       " 'TTTCTG GAACCA GGCACT TTTAAT CGTGGA ACCGAG GGGCCT GGAGTG TGAGGA GGGAGG GGCAGG ATCGGG GGCAGA GTTAGG GCCCGG GAACTC TCGGGT TAGGGT GAAGAC CCCGGG GTCTGA CTGGTT CAGCCT TAGGTG CCCATG TTGGGG CTGGAG GGCCCC AGGATC AGGATG GGGCAG GGATGG AGGCCC CACAGA AGGAGG GCCAGG CTCCGG GGAGTC AGTATT GGGCCC CAGGGG CAGCAG CCTGGG GTCAGT GTCCTG GGGCTA GTGCCC CAGATC AGGACC CAGCCT GTCAGT CATAGT CCGCGT CATCAA ACTTGG TGCTGA AGAAGG CGGCAG AGTCCT TGGCCA GCCGGG CCAGGT GCAGGG CACCAG TCACCA CCAGCC CCAGGA GCAGCA GTGGCG GCACCA GCGTCC ACATCG CGGCCA GGATGT TGTAGC ACTTGG CTTTGG AGCCAA AACGCC GGGCCG CTTCCA GGTCAC CAACCA CCTTCT GATCTC GGGCCT GCAGAG AGACCA GACCAC AGGGCC AGATCT CTATGT GTCCTC GGGGCC TGGGGG CCCTTC CCCACC CACACC CTGGGC ACCTGG AAGGCC CCTACT GCACCC AAAATC TGGATG GAGGGG TGTGGC CTGAGG AGATAC TCCTTG GGGCCC CAGCTA TGGACC CGGGGG CCATCC CAGGCC AGTGTC AGCCTA TCAGAG CTCTCT ATGGGT GAGGGT CCCCCA GGGTGC TGAGAC ACCCCC CACCCT GCCAGC CAGGAG CTGAAG TCAAAG GGACCT CTGTTC CAGAAG CCCACA GCATGT GAACCC CCTCTT GATTGC AGAGAC CTCTGT GGGTGC CTCCCA ATGGCC TCTGTG CTCTTG GATGGG CCAGAC CCCGTT AAGAAG AGGCCC CCCGGC CTTGCC TTCGTG AGGAGC TCTTTC CCGGCC ATACTG ATAGCT GTGCCC ACAGAG CCCCTC ACGGAC AAGCAG AGCCCC CCGCGG CCCCCA GCACGG CAAGGA CCCCCC ACGGAG CTCCCC ATCCCT CCCCCT TCCCCC CACCTT GATGGA GTAGTG GAGCCT CCCCCG CAACCT CGGTAG GGCCCC TGCCCA CCTTGA TGGAGT AGGCCA GCGCCA GGAAGC CGAGGC AACACA GATTCA GGTAGA GGGTGC TGAACA CCGACC AGATCA AGTGGT CTCGAG GCGGGG GGTGCG GGGCCC CCAGTG TGAGGG CTGTGT GGGCAC CGGCCT TGCTGG GCGTGG GGGCCC GGGTGT CCTCGC GGGGAT ACGCCG TGTCCA TGGGTT CCAGCG CCGTCT CTTCCA CACTCA GACTGG TXXXXX']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_data[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE',\n",
       " '<start> EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE IIIIII IIIIII IIIIII IIIIII IEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEI IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IXXXXX',\n",
       " '<start> EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EXXXXX']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_data_in[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE <end>',\n",
       " 'EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE IIIIII IIIIII IIIIII IIIIII IEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEI IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IXXXXX <end>',\n",
       " 'EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EXXXXX <end>']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_data_out[2:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, `cls_data_in` and `cls_data_out` are identical, but phase shifted by one token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the NLP tools built into keras, but for our sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "# Careful, by default filters strips out ?.!\n",
    "seq_tokenizer.fit_on_texts(seq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373\n"
     ]
    }
   ],
   "source": [
    "# Note that by increasing or decreasing k, you drastically change this table\n",
    "print(len(seq_tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaaaa 1\n",
      "tttttt 2\n",
      "aaaaat 3\n",
      "gggagg 4\n",
      "cagcag 5\n",
      "attttt 6\n",
      "cccagg 7\n",
      "cctccc 8\n",
      "caggag 9\n",
      "ggctgg 10\n",
      "taaaaa 11\n",
      "aaaata 12\n"
     ]
    }
   ],
   "source": [
    "# What's actually in the table? It's just a dense index over k-mers\n",
    "for i, (k, v) in enumerate(seq_tokenizer.word_index.items()):\n",
    "    print(k, v)\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "# If you fit on multiple texts, it just updates the database\n",
    "cls_tokenizer.fit_on_texts(cls_data_in)\n",
    "cls_tokenizer.fit_on_texts(cls_data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "# Of course the clasification has a much smaller index\n",
    "print(len(cls_tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, now we have a tokenization scheme, so we can convert tokens to token indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the k-mers into k-mer indices\n",
    "seq_idx = seq_tokenizer.texts_to_sequences(seq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[114, 617, 20, 2306, 804, 2564, 119, 180, 756, 700, 618, 1601, 2564, 1549, 590, 160, 454, 1022, 326, 137, 864, 771, 1219, 1220, 357, 424, 2971, 252, 772, 677, 407, 566, 392, 487, 338, 82, 1847, 2362, 1140, 491, 616, 1053, 379, 27, 1512, 2123, 746, 1602, 1186, 40, 839, 83, 1219, 701, 747, 492, 1352, 434, 1702, 489, 796, 567, 9, 2872, 177, 194, 1513, 121, 1703, 418, 1259, 136, 2192, 2124, 900, 324, 1550, 2363, 199, 2125, 1221, 967, 702, 25, 92, 199, 1965, 1092, 2517, 104, 658, 1353, 840, 308, 2022, 420, 1057, 989, 1966, 647, 437, 424, 673, 3940, 2250, 1962, 508, 804, 1659, 3611, 285, 1514, 192, 2873, 2615, 49, 1023, 251, 2925, 703, 1756, 1461, 2722, 2193, 2972, 1757, 171, 1915, 1704, 2194, 2126, 527, 280, 2818, 1515, 2254, 358, 344, 358, 1058, 2023, 1183, 704, 1187, 1412, 18, 2519, 897, 1462, 568, 567, 2616, 130, 270, 2024, 1516, 392, 1141, 3100, 2025, 114, 199, 1097, 1517, 696, 1967, 144, 44, 491, 3342, 61, 1603, 619, 2819, 841, 805, 1024, 2127, 408, 2454, 549, 941, 1663, 1551, 281, 2075, 1604, 1094, 3876, 1097, 1463, 1059, 620, 2128, 1098, 1604, 2075, 1605, 1604, 805, 1464, 27, 180, 92, 2926, 1664, 837, 1023, 173, 99, 842, 1312, 1222, 725, 593, 1518, 2404, 254, 1142, 1916, 1519, 309, 454, 1705, 699, 2129, 1054, 1849, 1758, 1260, 1261, 142, 2780, 1262, 654, 1354, 2564, 1465, 3261, 3612, 455, 990, 991, 2076, 2255, 2723, 2669, 747, 3177]\n"
     ]
    }
   ],
   "source": [
    "print(seq_idx[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_idx_in = cls_tokenizer.texts_to_sequences(cls_data_in)\n",
    "cls_idx_out = cls_tokenizer.texts_to_sequences(cls_data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 11, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 10, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 2, 2, 2, 2, 2, 14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 11, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 11, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 10, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 2, 2, 2, 2, 2, 14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 11, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]\n"
     ]
    }
   ],
   "source": [
    "print(cls_idx_in[2])\n",
    "print(cls_idx_out[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, assuming everything is correct, `cls_idx_in` and `cls_idx_out` are still just the same sequence shifted by one token (apparently `10` is `<start>` and `11` is `<end>`).\n",
    "\n",
    "One last trick: we need to pad all the sequences to the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_idx = tf.keras.preprocessing.sequence.pad_sequences(seq_idx,\n",
    "                                                        padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[333, 333, 333, 333, 333, 333, 333, 333, 333, 333]\n"
     ]
    }
   ],
   "source": [
    "print([len(s) for s in seq_idx[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_idx_in = tf.keras.preprocessing.sequence.pad_sequences(cls_idx_in,\n",
    "                                                           padding='post')\n",
    "cls_idx_out = tf.keras.preprocessing.sequence.pad_sequences(cls_idx_out,\n",
    "                                                            padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[334, 334, 334, 334, 334, 334, 334, 334, 334, 334]\n",
      "[334, 334, 334, 334, 334, 334, 334, 334, 334, 334]\n"
     ]
    }
   ],
   "source": [
    "print([len(s) for s in cls_idx_in[:10]])\n",
    "print([len(s) for s in cls_idx_out[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is finally sort of matrix-shaped, so we can hand it to `tensorflow` as a `Dataset`, which automagically handles splitting, batching, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOCK_SIZE = 100\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (seq_idx, cls_idx_in, cls_idx_out))\n",
    "\n",
    "# Shuffle transcripts, taking them in blocks of 1,000, with a batch size of 5\n",
    "dataset = dataset.shuffle(BLOCK_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 333), (None, 334), (None, 334)), types: (tf.int32, tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Naive Sequence Model\n",
    "\n",
    "The first model is just the basic sequence framing. We try to predict a sequence with a shift of 1 from the input alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder/Decoder fusion model\n",
    "# Embedding followed by an LSTM, followed by a decoder\n",
    "class SeqEncoderDecoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 in_vocab_size: int,\n",
    "                 out_vocab_size: int,\n",
    "                 embedding_size: int,\n",
    "                 lstm_size: int):\n",
    "        super(SeqEncoderDecoder, self).__init__()\n",
    "        \n",
    "        # Sizes for matrices\n",
    "        self.lstm_size = lstm_size\n",
    "        self.in_vocab_size = in_vocab_size\n",
    "        self.out_vocab_size = out_vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        # Layers\n",
    "        # Embed the input vocab in a smaller embedding space\n",
    "        self.embedding = tf.keras.layers.Embedding(\n",
    "            in_vocab_size, embedding_size)\n",
    "        # Stateful layer, generate both outputs and internal states\n",
    "        self.lstm = tf.keras.layers.LSTM(\n",
    "            lstm_size, return_sequences=True, return_state=True)\n",
    "        # Finally decode back onto the output vocab size\n",
    "        self.dense = tf.keras.layers.Dense(out_vocab_size)\n",
    "        \n",
    "    def call(self, sequence, state):\n",
    "        \"\"\" Call for a single step, output as single step \"\"\"\n",
    "        # Input -> embedding\n",
    "        embed = self.embedding(sequence)\n",
    "        # Embedding -> LSTM\n",
    "        lstm_out, state_h, state_c = self.lstm(embed, initial_state=state)\n",
    "        # Next stage of LSTM + output\n",
    "        logits = self.dense(lstm_out)\n",
    "        return logits, state_h, state_c\n",
    "    \n",
    "    def init_states(self, batch_size: int):\n",
    "        \"\"\" Initial states for a batch\n",
    "        \n",
    "        Set the hidden state and the output state to all 0s\n",
    "        \"\"\"\n",
    "        return (tf.zeros([batch_size, self.lstm_size]),\n",
    "                tf.zeros([batch_size, self.lstm_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the actual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 32\n",
    "LSTM_SIZE = 64\n",
    "\n",
    "seq_vocab_size = len(seq_tokenizer.word_index) + 1\n",
    "cls_vocab_size = len(cls_tokenizer.word_index) + 1\n",
    "\n",
    "# Build the encoder/decoder model\n",
    "enc_dec = SeqEncoderDecoder(seq_vocab_size, cls_vocab_size, EMBEDDING_SIZE, LSTM_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send in a test input and make sure the sizes of things make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source vocab size 4374\n",
      "Source sequences (1, 8)\n",
      "Encoder outputs (1, 8, 29)\n",
      "Encoder state_h (1, 64)\n",
      "Encoder state_c (1, 64)\n"
     ]
    }
   ],
   "source": [
    "source_input = tf.constant([[1, 3, 5, 7, 2, 0, 0, 0]])\n",
    "initial_state = enc_dec.init_states(1)\n",
    "\n",
    "enc_output, enc_state_h, enc_state_c = enc_dec(source_input, initial_state)\n",
    "\n",
    "print('Source vocab size', seq_vocab_size)\n",
    "print('Source sequences', source_input.shape)\n",
    "print('Encoder outputs', enc_output.shape)\n",
    "print('Encoder state_h', enc_state_h.shape)\n",
    "print('Encoder state_c', enc_state_c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a loss, we can do cross entropy. But we also need to be careful to avoid penalizing the padded parts of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(targets, logits):\n",
    "    \"\"\" cross entropy ignoring the padding \"\"\"\n",
    "    crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True)\n",
    "    mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
    "    mask = tf.cast(mask, dtype=tf.int64)\n",
    "    loss = crossentropy(targets, logits, sample_weight=mask)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize using Adam, because Adam always works pretty okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Tensorflow 2.0 has a magic autogradient method called the `GradientTape` which can capture all the tensor operations inside a function, back out all the gradients, and then solve the chain rule for you. Magical!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training step\n",
    "@tf.function\n",
    "def train_step(source_seq, target_seq_in, target_seq_out, en_initial_states):\n",
    "    # Record all the operations in the forward pass\n",
    "    with tf.GradientTape() as tape:\n",
    "        en_outputs = enc_dec(source_seq, en_initial_states)\n",
    "        logits = en_outputs[0]\n",
    "        # Expand the output sequence into 1-hot encoding\n",
    "        target = target_seq_out[:, :-1]\n",
    "        loss = loss_func(target, logits)\n",
    "    \n",
    "    # Work out the gradients automagically\n",
    "    variables = enc_dec.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    \n",
    "    # Optimize\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "For prediction, we just pass the input in and hope..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction step\n",
    "def predict(test_seq=None):\n",
    "    \"\"\" Predict on the source sequence only \"\"\"\n",
    "    if test_seq is None:\n",
    "        test_seq = seq_data[np.random.choice(len(seq_data))]\n",
    "    elif isinstance(test_seq, int):\n",
    "        test_seq = seq_data[test_seq]\n",
    "    test_seq_idx = seq_tokenizer.texts_to_sequences([test_seq])\n",
    "    \n",
    "    # Initialize the encoder and generate the forward state\n",
    "    seq_initial_states = enc_dec.init_states(1)\n",
    "    enc_outputs = enc_dec(tf.constant(test_seq_idx), seq_initial_states)[0]\n",
    "    \n",
    "    out_score = tf.argmax(enc_outputs[0, ...], axis=-1).numpy()\n",
    "    out_kmers = [cls_tokenizer.index_word[i] if i in cls_tokenizer.index_word else 'X'*NUM_K\n",
    "                 for i in out_score]\n",
    "    print('')\n",
    "    print(test_seq)\n",
    "    print(' '.join(out_kmers))\n",
    "    print('')\n",
    "    return out_kmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CGCCCT CAAACA ACCAGT CAAAGT CTTCTC CATTAA GATTAT CAGCTT TGGGAT AACCAA TTTTTT TTAATG TTTCCA CAAACT CATTTC CACAAC TCATGG TTTTAA CTACCC CAATTT TGTTGT ATCTGA TATGGG TTTACG GTGTTG ATTTTT AGAAAA TAAATC CAAGCA GAAAAA AAGCTA CGTTTT ATACCA AGTCCA CAGAGA AGGGAA AATATA TTTTTA GAATCT ATAATG ATTCCT CCTAGG GGGGAA GAAAAC AAGTAT TAGACC ACAAAT ATGACG ACAGTG TTTTTA AAAAGA AGACAC AGACAA ATATCA CATGAT ATCCGA GAGCGG GATAAA TGACAG GTAGTC GTAGCT GCAATG TTTGAT GATGAT AAAGAG AAACAG AAACAA TTAGGC TAGTTC TCAGAA AACCGC AACAGT AACGAA AAGTAA TTAACA AGAAAG TGGATC TATTTG GATCCA TTTTAT CTTTTT TTCCAA AGATAA AATGGT TTAAAA TGCATT ACACTT TATAGA GCAGCA TTTGTT TTTAAT TCAAAA TAAATG GATCCA AACAAA CCCAAG CCACCA GGAGGC TAGGCA GCCTCT CTTCCC TGCCCT CCGTAC GTAAGA AGACGC AAATAA GCATGG CACATC TTCTGA AGATCA ACTAAA TATTTA CCTCAA CGTCTC GCCGGG CAAGGC TCCACC TCCAGA GTCCAC CACCGC GACGCG GAGAAC AGCAGG AGCAGC AGGGAA GCGCGC GGCCAC AATTAA GGGTGC TTCGGG CCGGCC TTCAGC CAGCGC TGAGGC AGCCCC GACGCC AGGGCC GCGCGA ACCCCA GAGGCA GCGGCA AGCCCC AGGGAT CCGCGG CCCCAA GGCCGC GATACA CCAGAC GCGCCA GCGGCA AAACCT TCCTTC GGAGGG TCACCC AGCTGT GACACC TAAGCA CGCTGA CAAAAC AAACGC ACAAGC CCACCG AATCGC CGTCGA CACCGA GCTGCA GAAGAC GGGGGT GACAGG CCCCGC ACAGCC CCCGCC CCAGCT CCTCGC CCAGCG GACCGG GCCCTG ATCCCC GGGCAG CTGCTG GAGCAC CTGGAA GGAGCC CCCAGG AGCGCA GGAAAA AAAAGA GGCACC TGGGTG CAGACG GGGATC GCGGCC ACTCCT CCAGCC CCACAC CCCTGC GCCCAG AACCGA GGCCCG CGTCAG TCACCT CAGGAA GTTCCG CTTGCT TCTCGC AGGAGC CCGCCG CCACCG CCCTCC GTGCCC CGCGCG CCTCGC ACTXXX\n",
      "eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii eeeeee iiiiii iiiiii iiiiii eeeeee eeeeee eeeeee eeeeee eeeeee iiiiii eeeeee iiiiii iiiiii eeeeee eeeeee iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on the untrained model to make sure it does a thing\n",
    "predict();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34924662\n",
      "0.38295937\n",
      "0.318132\n",
      "0.27396616\n",
      "0.3240919\n",
      "0.36765364\n",
      "0.36805332\n",
      "0.33588427\n",
      "0.42058823\n",
      "0.37192908\n",
      "0.38659108\n",
      "0.4680552\n",
      "0.3650541\n",
      "0.26808432\n",
      "0.33962733\n",
      "0.36672294\n",
      "0.3024968\n",
      "0.3674227\n",
      "0.24329516\n",
      "0.417697\n",
      "0.4290935\n",
      "0.29634416\n",
      "0.44853368\n",
      "0.3872811\n",
      "0.34016022\n",
      "0.3701311\n",
      "0.36340538\n",
      "0.3725462\n",
      "0.40783462\n",
      "0.30656648\n",
      "0.29142645\n",
      "0.3825042\n",
      "0.41786903\n",
      "0.49387482\n",
      "0.35500452\n",
      "0.37183547\n",
      "0.39814764\n",
      "0.3834224\n",
      "0.43434173\n",
      "0.36984035\n",
      "0.34237364\n",
      "0.49055374\n",
      "0.3610029\n",
      "0.32147327\n",
      "0.52348316\n",
      "0.33014265\n",
      "0.40120086\n",
      "0.4760288\n",
      "0.37663618\n",
      "0.43994895\n",
      "0.30760965\n",
      "0.33715203\n",
      "0.3829675\n",
      "0.41749173\n",
      "0.49310526\n",
      "0.35018975\n",
      "0.28204048\n",
      "0.43157429\n",
      "0.37286916\n",
      "0.25129375\n",
      "0.4450146\n",
      "0.47923273\n",
      "0.29233798\n",
      "0.29153058\n",
      "0.2771438\n",
      "0.40619758\n",
      "0.39219067\n",
      "0.3957338\n",
      "0.31603482\n",
      "0.48270357\n",
      "0.32254517\n",
      "0.3305024\n",
      "0.34674978\n",
      "0.32428008\n",
      "0.37988737\n",
      "0.29551786\n",
      "0.4537161\n",
      "0.37046242\n",
      "0.35148403\n",
      "0.3841143\n",
      "0.41653603\n",
      "0.47721848\n",
      "0.38496694\n",
      "0.56313694\n",
      "0.3626288\n",
      "0.4883033\n",
      "0.3610372\n",
      "0.3968038\n",
      "0.46488285\n",
      "0.34783173\n",
      "0.48100153\n",
      "0.39034322\n",
      "0.47594932\n",
      "0.5331434\n",
      "0.44944933\n",
      "0.3690291\n",
      "0.52418196\n",
      "0.34636596\n",
      "0.40966195\n",
      "0.47142264\n",
      "0.42361793\n",
      "0.35435575\n",
      "0.4044636\n",
      "0.47517744\n",
      "0.33554724\n",
      "0.4456378\n",
      "0.3885858\n",
      "0.35639712\n",
      "0.5056446\n",
      "0.4680425\n",
      "0.33112398\n",
      "0.41860065\n",
      "0.4280477\n",
      "0.39704663\n",
      "0.43915972\n",
      "0.35716423\n",
      "0.36411634\n",
      "0.4679886\n",
      "0.3404769\n",
      "0.40832534\n",
      "0.3766726\n",
      "0.4190946\n",
      "0.3077377\n",
      "0.45456544\n",
      "0.40142307\n",
      "0.3216516\n",
      "0.3598035\n",
      "0.3932318\n",
      "0.46692783\n",
      "0.40379503\n",
      "0.36640286\n",
      "0.4151994\n",
      "0.44304976\n",
      "0.40212256\n",
      "0.4036805\n",
      "0.35844755\n",
      "0.4555629\n",
      "0.35327017\n",
      "0.47652102\n",
      "0.34025922\n",
      "0.4073764\n",
      "0.3123553\n",
      "0.4298393\n",
      "0.37413195\n",
      "0.5111456\n",
      "0.38741532\n",
      "0.4076608\n",
      "0.483967\n",
      "0.40412304\n",
      "0.427058\n",
      "0.4207429\n",
      "0.41301888\n",
      "0.42382663\n",
      "0.34963292\n",
      "0.42946637\n",
      "0.44403863\n",
      "0.34806\n",
      "0.39243636\n",
      "Epoch 1 Loss 0.3924\n",
      "\n",
      "TGAGAC CTTAAT GCATTT GTGCAG TTGGTC CCACTT CCCCCA CCAGGA CCAGGT TTCCAA GGCCTC TGTTTG ATGCCA TCCAGA AGTCTG ACCAGC AAGATG TTACTG GGAAGC TCCTCG ACACCC GAGCCA ACAAGA GTCCTG CACTCG GGACAT CTGAGT TCATTT CGAGAA CCTACG ATCCCC AGCAAA CATCGC TTGCAA AACGTA TGCTGG CAAGGC AAGACC TTCGCA GAAGCA TCAAGG CGCTCT AGACAC ACCGGA CACTCC AAAAGA TCCAAC AAGGCT GATTCA TCCATC TTTATC TACTTT ACTGAG AAAAAA TCTTCA GAAATG TTCATA GTTGTG TGCATC CCTTAA AATGAC TCATGT AACATC CATTTC AGACTT TGCTCT AGAGTC ATGGGG AAAAGG GGGAAA AGAGAA CATGAG TGTTGT TATCTA GGGAAA AAGTTC AAAGGA GCCAAG AATCAA AAAGTA CCCAAA AGTACA CTATTC CCTGTC TGAATA GTGTAG CTTTGC TTTGGA ATGTGG GTTCCT AAACTC CAAAGT CAACAA CTGAAA ACAAAA CAGGCT TTCTAA ACAACG CAAAAT TAACCC CTAAAG ATATCT AGGGAT TCACTG GGCAAA CACAAG GCACAG AGTATT ACATAA TTCCCG CAGAAG GATTTA TGAAGT GCAATA AGGAAC ATAATT TCTTAA GCTCTG AAAGTG GTATCA GCTGCC TTAATA AAGTCT TCAACT CATAGG AGAAGC TGACAG AGGCCA TTGAAA GTTTCC TCTACC TGAAAT TTACTT TTATAT CCAACT AAATTC CCTTTT TTAAGC CACTTT AGCGTT TAAGAA ACCATG CCTCAT GTAATC GCTCGT GGTAAA TGATCC CAATAT TAAATA CATATG TTTCTT CGCTGT TATTAA AAATAG AACTGT TTAATT TTGCCC AACCAA AAAGAG CTGAAG GTTGAC AATTCT AAAAGA CACAGA TTTGCT TGAAAG CAGCTA AAACAG AAAAGC GCCCTT CAGGGC AGTAGT TGATAA ACTCTG AAACAC ATTTCT GAACGG CCTGTC CTAATC CCATTC AGAAAA GCTGGC AAAATT ATCACC AAAAGA ATTCGA CAATGG AAGGTT GGACTG GAAACT GTGGGC ATATGA AAATGA GGCCAT TCAGGA AAAAGC AAGCCA CTTACT GCGCCG CTCTCC CCCCAC CGCCAA AATAAA TGTAAA AGTGAA TGCCCA GGAGAA CGGGAG TAAAAA GATTTG GCTGGG AGCATT AACAGC TGTTCT TGACAA AGCCGG AGCGGG GGAGCC CCAGGG CTGCAC CCCCGC TCCCAC GGCGCC AAGCAC AGGTAC TCCCAA GCCCGC AGGGAG GCGCGG CGGCCG CTCGCC GCAGAC ACACCC CGGGGC CAGGTG TCGGCG GCACCC GGCAGG AGCCGG TCGCGG CCTGGG GCTGCG GCCCGG CCGGTC CCGGCG TGGGGA TCTCAC CCTACA GCCTCC CTCATC TCCGCC TCCCTT TAGCTC AGGCCG GGGACA CAAATC CCTCTA CACGAC TGCGGG AAGTTT TCAAGG ACTTAA AAATAA ATGCGC AGGCTT AAGTTG CGAAAC TCAGCC CCACAG AGTGCC ACGGGG AAGCAG CTTTCT AGCCCA GCCAAG ATAAGG CGACAG TCCCCA GAGAGA CCGCGC CATCCG GGAAGC AGGGGG TGCTGG GCTGCG CCCGGG GAGACC GCGGCA CGGAGC CCTGGC AGCTTC CTGCCC GGAGAA GGCAGA GGCCGC GGGCTG CTCCGC TTCCGC AGGTCC TGATTC CCGGCC CACGGG GACCCG AGGGCG AGGGGA GAGAGA GACCGA CCCAGG GCGGGG ATGGGG GAATGT CGAGAC CACCGC CTTCTC CGCGGC TAGGGG TCCGCC GACGCT GGGTCC CCGTCG ACCCCG CGCCGG CCGCXX\n",
      "eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee iiiiii iiiiii iiiiii iiiiii eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii eeeeee iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii eeeeee iiiiii eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii eeeeee eeeeee eeeeee iiiiii iiiiii iiiiii eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee iiiiii eeeeee eeeeee eeeeee eeeeee iiiiii\n",
      "\n",
      "0.48409978\n",
      "0.25084627\n",
      "0.30819815\n",
      "0.2950622\n",
      "0.31545126\n",
      "0.31800753\n",
      "0.3933011\n",
      "0.29181316\n",
      "0.38477588\n",
      "0.34544945\n",
      "0.36513862\n",
      "0.2849252\n",
      "0.20892645\n",
      "0.43649513\n",
      "0.38664335\n",
      "0.25513214\n",
      "0.33390915\n",
      "0.3679485\n",
      "0.43542284\n",
      "0.46198177\n",
      "0.36046705\n",
      "0.30918354\n",
      "0.32138658\n",
      "0.37797984\n",
      "0.31305328\n",
      "0.32184684\n",
      "0.38221234\n",
      "0.30451736\n",
      "0.35372028\n",
      "0.41129395\n",
      "0.29559037\n",
      "0.41871557\n",
      "0.26238027\n",
      "0.52124834\n",
      "0.43336576\n",
      "0.4847239\n",
      "0.26147082\n",
      "0.3505915\n",
      "0.4554234\n",
      "0.26363096\n",
      "0.34800154\n",
      "0.35907757\n",
      "0.35601956\n",
      "0.3979152\n",
      "0.38589293\n",
      "0.391507\n",
      "0.27906805\n",
      "0.37285912\n",
      "0.40604925\n",
      "0.3975698\n",
      "0.44794786\n",
      "0.5001986\n",
      "0.3292645\n",
      "0.33972618\n",
      "0.41707933\n",
      "0.24975649\n",
      "0.3124307\n",
      "0.38289556\n",
      "0.38200486\n",
      "0.42478347\n",
      "0.36914402\n",
      "0.3527733\n",
      "0.3368044\n",
      "0.31546295\n",
      "0.31054273\n",
      "0.32272694\n",
      "0.3738148\n",
      "0.2146729\n",
      "0.4236968\n",
      "0.27263334\n",
      "0.26740026\n",
      "0.2715023\n",
      "0.45846325\n",
      "0.28680512\n",
      "0.3469399\n",
      "0.28197068\n",
      "0.43682936\n",
      "0.42703208\n",
      "0.34731025\n",
      "0.35393903\n",
      "0.26834184\n",
      "0.38973296\n",
      "0.33000055\n",
      "0.39881596\n",
      "0.31959262\n",
      "0.3932159\n",
      "0.27691266\n",
      "0.30901462\n",
      "0.34113652\n",
      "0.25792608\n",
      "0.33773378\n",
      "0.27599457\n",
      "0.24834369\n",
      "0.44625443\n",
      "0.35840335\n",
      "0.36434528\n",
      "0.33520243\n",
      "0.32419777\n",
      "0.4920455\n",
      "0.42935687\n",
      "0.38621897\n",
      "0.336077\n",
      "0.43240428\n",
      "0.2772238\n",
      "0.3822182\n",
      "0.3217792\n",
      "0.25696105\n",
      "0.36499727\n",
      "0.35551494\n",
      "0.3032072\n",
      "0.2832136\n",
      "0.30294183\n",
      "0.4636473\n",
      "0.35951686\n",
      "0.44437099\n",
      "0.4202074\n",
      "0.32275608\n",
      "0.40796164\n",
      "0.3711311\n",
      "0.31383273\n",
      "0.33104253\n",
      "0.40165037\n",
      "0.41208887\n",
      "0.508154\n",
      "0.3825767\n",
      "0.3828602\n",
      "0.36359373\n",
      "0.30650082\n",
      "0.46741036\n",
      "0.34497544\n",
      "0.40105698\n",
      "0.42162147\n",
      "0.51615506\n",
      "0.41338605\n",
      "0.32112983\n",
      "0.45701107\n",
      "0.37539744\n",
      "0.42313763\n",
      "0.46263498\n",
      "0.45750928\n",
      "0.36744425\n",
      "0.29647455\n",
      "0.41699463\n",
      "0.47254458\n",
      "0.47527903\n",
      "0.33037594\n",
      "0.43424493\n",
      "0.36714268\n",
      "0.42929664\n",
      "0.43927062\n",
      "0.5130511\n",
      "0.35875934\n",
      "0.35614273\n",
      "0.30678067\n",
      "0.43031943\n",
      "0.46058866\n",
      "0.43871212\n",
      "0.38978988\n",
      "Epoch 2 Loss 0.3898\n",
      "\n",
      "TTTTTT TTTTTT TTTTTA GATGGA CTCTTG CTCTGT CGCCCA GGCTGG AGCGCA GTGGCG CAATCT CAGCTC ACTACA ACCTCT GCCTCC CGGGTT CAAGCA ATTCTC CTGCCT CAGCCT CCCGAG TAGCTG GGATTA CAGGCA CTCGCC ACCACG CCCGGA TGATTT TTTTGT ATTTTT AGTAGA GACAGG GATTCA CCATGT TGGACA GGCTGG TCTTGA ACTCCT GACCTC AGGATC CACCCA CCTTGG CCTCCC AAAGTG GTGGGA TTACAG GTGTGA GCCACA GTGCCT GGCCTA GAATAG ATGTTC TGTTAG TAGGTG CTGTAG TTATTT CCTGAA TATGTG AAATTA TACCAA TAGTCT ACCCCC TTCCTG GAGTTT GAGGTA CATAGA ATTTGA ATAAAT TGACTG TCGCCA CTTTTG GTGAAT AAATTT TCAAAC TTTTTT TTTTTT TTTTTT TGAGAC AAGAGT CTCACT CTGTCA CCTAGG CTGGAG TGCAGT GATGCG ATCTCG GCTCAC TGCAAC CTCTGC CTCCCA GGTTCA AGCAAT TCTCCT GCCTCA GCCTCC TGAGTA GCTGGG ATTACA GGTACA TGCCAC CATACT TGGCTA AGTTTT GTATTT TTAGTA GCGACA GGATTT CACCAT GTTGGC CAGGCT GGTCTC GAACTC CTGACC TCAGGT GATCCG CCTACC TCAGCC TCCCGA AGTGCT GGGATT ACAGGC GTGAGC CACCAT GCCCGG CCTAAA AAATAT AAAAAT TAACCA AGCGCA GCAGTG TGTGCC TGTAGT ACCAAC TACTGG GTGGGG ACTGAG ATGGGA GGATTG TTTGAG CCCAGG AGGTCG AGGCAG CAGTAA ACTGAA TCTGCA ACTGCA CTCAAG ACTGGG CAAGAA AGCGAG ACCCTG TCTCAA AAAGAA AAAAGT GAGACT GAAGAG ACAAAA TGTTTT GCTCTG GAGGCA GTTTTT TCCCTC AAGAAT TATACA CTAGAT AACGAG GGCAAA GGCACA CAGTCC TTCTCA TTCCAA TAGGAT CTAGGT GAAGTT ATTTAT GTGTGT ATCTGA TAGGAG AGTGTC AACTAG CTCAAA TTTTCT CTGTGG CCTAAA GCTCTG CCCAGC CTCCAG GGCCTT CCAGCA GCTTCA CAAAAG GAAGTC ATATTA GTTTGA AAACCA AAACTA GGCTGG GTGTGG TGGCTC ACACCT GTAATC CCAGCA CTTTGG GAGGCC AAGGTG AGTGGA TCACCA GAGGTC AGAAGT TTGAGA GAAGCC TGGCCA ACACGG AGAAAC CCGGTC TCTACT AAAAAT ACAAAA ATCACC CAGGCG TGGGGG CGTATG CCTGTA GTCCAA GCTACT TGGGAG GCTGAG ACAGGA GATTTG CTTGAA CCTGGA AGGCGG AGGTTG CAGTGA GCCAAG ATTGTG CCACTC AACTCC AGCCTG GGCAAC AGAGCG AGACCC CGCCTC TAAATC AATCAA TCAATC ATAACT GCTGAA AATGAT CTAAGT GAACCA ACGGCA TGGAAT ACGTGC TCTTTC TCTGTC CTGGGA CATACT GCACAG AGGACT CAATCT TAGCTC AGCTCC TTGGGC CAGCAT GACCTT AAACAA GTGGCT CAATAT CTTGGA GCAACC CCAGTT ATCATC ATTAAG GTAGGG ACAACC ATAACA ACACAA TCACTC TAACAC TAACTA TCCAGG CAACCC GAGGCC ACAAGC AGACCC TCAAAG GCTGTT TGTGGT AATGAC GACAAC ATCCTT GACCCA CCTGCT GCCCTG TCATGA CAGGGA GGGCTG CAGCAC AAGTTT ATTAAT AGATAC CTCATC ATCTTC AGCACA AACCTA AAGCAA GTTTTT TCAAGC CTGGTT TCXXXX\n",
      "eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii eeeeee iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee iiiiii iiiiii iiiiii iiiiii eeeeee iiiiii eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii eeeeee eeeeee eeeeee iiiiii eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee iiiiii iiiiii eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 2\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for batch, (source_seq, target_seq_in, target_seq_out) in enumerate(dataset.take(-1)):\n",
    "        enc_initial_states = enc_dec.init_states(source_seq.shape[0])\n",
    "        loss = train_step(source_seq, target_seq_in, target_seq_out, enc_initial_states)\n",
    "        print(loss.numpy())\n",
    "    print(f'Epoch {epoch+1} Loss {loss.numpy():.4f}')\n",
    "    \n",
    "    try:\n",
    "        predict();\n",
    "    except Exception:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well did it do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TCTAGG TGCAAC AATCAA GCTCTA TTTTTG TAATTA AAAATG TATCCA AAGGGA AAAAAG AAACAA AAGGAA CAATAT TTGTAC TCTATG TTGCTG CAGAGA GCAGAA CTGCGG AGGGGG TGCTAG TCCCAA GGGGTG GACTGT GCTGTG CTAGTG CCCTAA ATCCTG CAAGCG CGGGGT TGGGGG GGCGGG GGAGAC CGCTGT CGGGGG TCGTGA GTTCCG GGCCCT TGTGTG CATGTT CACGTC CTGTCA TTCTTG CCCCCA GCTGAG AGAGCA GTAGAG GAAAGG CACTAC ATCCAC CAGCCT TTGCAT TCTCCT CGGAGC ACACAG AAAGAC ATTTTC CAGTTA TCTTGC ACACAA GTGGGC GGCGGG ACCCGT TTTGGC CGGGAA CGTTGT CAGGAA CGCTGT ACACCA CTTCCA GGCGGT CACGTC CGAGCT GCCCAG GCAGTC CTTCTG CGCCCT CTGCTG GCCAGA TGGAGG CTGCAG ACCCTG CGGGGC CATCAG GAGAGA ACCACC AAGCAC CCTCTG CACACC GCATTG CCTGTG TTGGGC ACAAAG AATAAA CTTTTA TTGCAT CTTAAC CCACTA GAAATG TAGGCT TGTCCA TCACAG TGGGGC GTTACA TACCCT AATACA TAGGGA AGGCAT AGGTAG ATTTCA GTTGGC CTTTTA CAGACA AGGAAA CCAAGG CTTGAG AAGATT CAAACC TTACTG CAGCCA TGGCTC ACACCT ATATAC CCTCAG TACTTT GGGAGA CCAAGG CAGGTG GCTCGC TTGAGC CCAGGA GTTCCA GACAAG CCTGGG CAACAT AGAGAA ACCCCA TCTCTA CGAATA TTTTTT AAATTA GCTGGG TGTGGT GGCACG TGTCTG TGGTCC CAGCTA CTCGGG AGGCTG AGGTGG GAGGAT TGCTTG AGCCCA GGAGGT TGAGGC TATAGT GAGCCG TGATCG TGCCAC TACCTC TAGCCT GGACGA CAGAGC AAGACG CCCTCT AAAAAA AAAAAA GAAGAA GAAGAA GAAGAA AGAAGA AGAAGA AAAAGA AAAACT TGCTGC CCAAGC AGTTAA GGCAGG ATTAAC CTGCAG CCCTCA CTGCTG TGCGTT CCTTCT AGGAAA GACCCA GAAGCC AGAGAA GCCTAG GTCCCA ATCCTG GTGGAT CTTCGT GCTGGA ATCGTT AAGCCA GCTGTT TCCCAG GGGCCA CCCATG GGCCAG TCCTCA CCACAA CCTCAT GGGTGG TCGGTC AATGTC GTAGGC CCGCTT TACAGC CGAGGA GACAGA GGCTTC CAGAGG CAAACA CACTGG TCCATG AGTAGC AGAACG AGGGTA GGCCCA GGAAGC CATGXX\n",
      "eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii iiiiii eeeeee eeeeee iiiiii eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee\n",
      "\n",
      "EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IIIIII IEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEEE EEEEXX\n"
     ]
    }
   ],
   "source": [
    "pred_seq = predict(25)\n",
    "print(' '.join(cls_data_in[25].split(' ')[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot it in matplotlib\n",
    "CODES = {\n",
    "    'A': 0,\n",
    "    'T': 1,\n",
    "    'C': 2,\n",
    "    'G': 3,\n",
    "    'X': np.nan,\n",
    "}\n",
    "\n",
    "input_seq = np.array([CODES[s.upper()] for s in ''.join(seq_data[25].split(' '))])\n",
    "\n",
    "pred_seq_values = np.array([0 if s.lower() == 'i' else 1 for s in ''.join(pred_seq)])\n",
    "exp_seq_values = np.array([0 if s.lower() == 'i' else 1 for s in ''.join(cls_data_in[25].split(' ')[1:])])\n",
    "\n",
    "x = np.arange(pred_seq_values.shape[0])\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 6))\n",
    "ax1.plot(x, pred_seq_values, color='r')\n",
    "ax1.set_ylabel('Predicted')\n",
    "ax2.plot(x, exp_seq_values, color='k')\n",
    "ax2.set_ylabel('Actual')\n",
    "ax3.plot(x, input_seq)\n",
    "ax3.set_ylabel('Sequence')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Seq2Seq Model\n",
    "\n",
    "Seq2seq splits the model into an encoder stage, which processes the input sequence, and a decoder stage, which tries to generate the output sequence, using the previous outputs as context to generate the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder model\n",
    "# Has an embedding layer, and then a set of states\n",
    "class SeqEncoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size: int, embedding_size: int, lstm_size: int):\n",
    "        super(SeqEncoder, self).__init__()\n",
    "        self.lstm_size = lstm_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        # Layers\n",
    "        # Embedd a vocab in a smaller embedding space\n",
    "        self.embedding = tf.keras.layers.Embedding(\n",
    "            vocab_size, embedding_size)\n",
    "        # Stateful layer, generate both outputs and internal states\n",
    "        self.lstm = tf.keras.layers.LSTM(\n",
    "            lstm_size, return_sequences=True, return_state=True)\n",
    "        \n",
    "    def call(self, sequence, state):\n",
    "        \"\"\" Call for a single step, output as single step \"\"\"\n",
    "        # Input -> embedding\n",
    "        embed = self.embedding(sequence)\n",
    "        # Embedding -> LSTM\n",
    "        output, state_h, state_c = self.lstm(embed, initial_state=state)\n",
    "        # Next stage of LSTM + output\n",
    "        return output, state_h, state_c\n",
    "    \n",
    "    def init_states(self, batch_size: int):\n",
    "        \"\"\" Initial states for a batch\n",
    "        \n",
    "        Set the hidden state and the output state to all 0s\n",
    "        \"\"\"\n",
    "        return (tf.zeros([batch_size, self.lstm_size]),\n",
    "                tf.zeros([batch_size, self.lstm_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder model\n",
    "# Takes the output from the encoder and writes out the final word\n",
    "class SeqDecoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, vocab_size: int, embedding_size: int, lstm_size: int):\n",
    "        super(SeqDecoder, self).__init__()\n",
    "        self.lstm_size = lstm_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        # Layers\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = tf.keras.layers.LSTM(\n",
    "            lstm_size, return_sequences=True, return_state=True)\n",
    "        # New layer, map output of the lstm back onto the original vocab\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "    \n",
    "    def call(self, sequence, state):\n",
    "        embed = self.embedding(sequence)\n",
    "        lstm_out, state_h, state_c = self.lstm(embed, state)\n",
    "        logits = self.dense(lstm_out)\n",
    "        return logits, state_h, state_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have two stages, so make sure they're compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source vocab size 4374\n",
      "Source sequences (1, 8)\n",
      "Encoder outputs (1, 8, 64)\n",
      "Encoder state_h (1, 64)\n",
      "Encoder state_c (1, 64)\n",
      "\n",
      "Destination vocab size 29\n",
      "Destination sequences (1, 7)\n",
      "Decoder outputs (1, 7, 29)\n",
      "Decoder state_h (1, 64)\n",
      "Decoder state_c (1, 64)\n"
     ]
    }
   ],
   "source": [
    "# Generate a model and check for typos\n",
    "EMBEDDING_SIZE = 32\n",
    "LSTM_SIZE = 64\n",
    "\n",
    "encoder = SeqEncoder(seq_vocab_size, EMBEDDING_SIZE, LSTM_SIZE)\n",
    "\n",
    "decoder = SeqDecoder(cls_vocab_size, EMBEDDING_SIZE, LSTM_SIZE)\n",
    "\n",
    "source_input = tf.constant([[1, 3, 5, 7, 2, 0, 0, 0]])\n",
    "initial_state = encoder.init_states(1)\n",
    "\n",
    "# Notice that now we feed the hidden states of the encoder into the hidden state of the decoder\n",
    "encoder_output, enc_state_h, enc_state_c = encoder(source_input, initial_state)\n",
    "\n",
    "target_input = tf.constant([[1, 4, 6, 9, 2, 0, 0]])\n",
    "decoder_output, dec_state_h, dec_state_c = decoder(target_input, (enc_state_h, enc_state_c))\n",
    "\n",
    "print('Source vocab size', seq_vocab_size)\n",
    "print('Source sequences', source_input.shape)\n",
    "print('Encoder outputs', encoder_output.shape)\n",
    "print('Encoder state_h', enc_state_h.shape)\n",
    "print('Encoder state_c', enc_state_c.shape)\n",
    "\n",
    "print('')\n",
    "\n",
    "print('Destination vocab size', cls_vocab_size)\n",
    "print('Destination sequences', target_input.shape)\n",
    "print('Decoder outputs', decoder_output.shape)\n",
    "print('Decoder state_h', dec_state_h.shape)\n",
    "print('Decoder state_c', dec_state_c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same masked cross-entropy loss as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(targets, logits):\n",
    "    \"\"\" cross entropy ignoring the padding \"\"\"\n",
    "    crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True)\n",
    "    mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
    "    mask = tf.cast(mask, dtype=tf.int64)\n",
    "    loss = crossentropy(targets, logits, sample_weight=mask)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize using Adam, because Adam always works pretty okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training step\n",
    "\n",
    "@tf.function\n",
    "def train_step(source_seq, target_seq_in, target_seq_out, en_initial_states):\n",
    "    # Record all the operations in the forward pass\n",
    "    with tf.GradientTape() as tape:\n",
    "        en_outputs = encoder(source_seq, en_initial_states)\n",
    "        en_states = en_outputs[1:]\n",
    "        de_states = en_states  # Hidden encoder state becomes initial decoder state\n",
    "        \n",
    "        de_outputs = decoder(target_seq_in, de_states)\n",
    "        logits = de_outputs[0]\n",
    "        loss = loss_func(target_seq_out, logits)\n",
    "    \n",
    "    # Work out the gradients automagically\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    \n",
    "    # Optimize\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "Notice now we predict one character at a time, because we have to feed the previous result back into the decoder at every stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction step\n",
    "def predict(test_seq=None):\n",
    "    \"\"\" Predict on the source sequence only \"\"\"\n",
    "    if test_seq is None:\n",
    "        test_seq = seq_data[np.random.choice(len(seq_data))]\n",
    "    elif isinstance(test_seq, int):\n",
    "        test_seq = seq_data[test_seq]\n",
    "    test_seq_idx = seq_tokenizer.texts_to_sequences([test_seq])\n",
    "    \n",
    "    # Initialize the encoder and generate the forward state\n",
    "    en_initial_states = encoder.init_states(1)\n",
    "    en_outputs = encoder(tf.constant(test_seq_idx), en_initial_states)\n",
    "    \n",
    "    # Now, feed in the decoder state one token at a time\n",
    "    de_input = tf.constant([[cls_tokenizer.word_index['<start>']]])\n",
    "    de_state_h, de_state_c = en_outputs[1:]\n",
    "    out_kmers = []\n",
    "    max_len = len(test_seq.split(' ')) + 10\n",
    "    \n",
    "    # Now run until we emit a stop token, or make waaaay too long a word\n",
    "    while True:\n",
    "        de_output, de_state_h, de_state_c = decoder(\n",
    "            de_input, (de_state_h, de_state_c))\n",
    "        # Take the single strongest token as our prediction\n",
    "        de_input = tf.argmax(de_output, -1)\n",
    "        pred = de_input.numpy()[0][0]\n",
    "        \n",
    "        if pred in cls_tokenizer.index_word:\n",
    "            out_kmer = cls_tokenizer.index_word[pred]\n",
    "        else:\n",
    "            out_kmer = 'X'*NUM_K\n",
    "        out_kmers.append(out_kmer)\n",
    "        \n",
    "        if out_kmers[-1] == '<end>' or len(out_kmers) >= max_len:\n",
    "            break\n",
    "    print(test_seq)\n",
    "    print(' '.join(out_kmers))\n",
    "    return out_kmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-2.1373427   7.2983775   1.1161712  -1.6458035   0.73187685\n",
      "    1.203334    0.44427288 -2.0443015  -0.96153903 -1.7598507\n",
      "   -1.8000529   0.38197136  0.56249565  0.3523605  -1.253454\n",
      "   -0.60259235 -0.09598017  0.11230239 -0.28199998 -0.2330418\n",
      "   -2.8455436  -2.887426   -2.5774238  -1.9658434  -3.0639954\n",
      "   -2.1566808  -2.475602   -1.8239365  -2.2319126 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.3056068   7.397497    0.9215107  -1.5872486   0.70305634\n",
      "    1.0611016   0.42091823 -1.9781597  -1.0735756  -1.7503239\n",
      "   -1.793376    0.23452002  0.43223405  0.3190301  -1.1056558\n",
      "   -0.4037451   0.05223271  0.0913066  -0.23902604 -0.14891058\n",
      "   -2.76873    -3.037226   -2.4709494  -1.9464628  -3.1443684\n",
      "   -2.1453881  -2.401167   -2.05891    -2.2428384 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.4043045   7.2997365   1.0994731  -1.6351869   0.75137514\n",
      "    0.9815235   0.3792174  -1.9665823  -1.0829929  -1.7276938\n",
      "   -1.7759085   0.19783567  0.3194802   0.25340462 -1.0694575\n",
      "   -0.35891986  0.02684004  0.02469337 -0.27193865 -0.2584141\n",
      "   -2.8148909  -3.0797956  -2.4860244  -1.9762644  -3.1708255\n",
      "   -2.2402434  -2.4052014  -2.142907   -2.2600985 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.4666674e+00  7.1855712e+00  1.3026413e+00 -1.6882296e+00\n",
      "    8.2978362e-01  8.7231535e-01  3.4930634e-01 -1.9559346e+00\n",
      "   -1.0891168e+00 -1.6733036e+00 -1.7498618e+00  1.4447200e-01\n",
      "    2.3777589e-01  1.9627659e-01 -1.0312570e+00 -3.3184347e-01\n",
      "    1.0924034e-02  4.7735460e-03 -2.6793981e-01 -3.4739318e-01\n",
      "   -2.8141961e+00 -3.0775211e+00 -2.5473943e+00 -2.0068638e+00\n",
      "   -3.1570113e+00 -2.3494670e+00 -2.4030266e+00 -2.2315290e+00\n",
      "   -2.3312864e+00]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5021329e+00  7.0788155e+00  1.4938273e+00 -1.7384248e+00\n",
      "    9.2170519e-01  7.6198107e-01  3.2271415e-01 -1.9503487e+00\n",
      "   -1.0987358e+00 -1.6050024e+00 -1.7301339e+00  9.5339254e-02\n",
      "    1.8598881e-01  1.5095980e-01 -9.9719882e-01 -3.0259645e-01\n",
      "    3.0358061e-03  1.8171944e-02 -2.3490764e-01 -4.0656719e-01\n",
      "   -2.7999959e+00 -3.0473163e+00 -2.6238256e+00 -2.0235202e+00\n",
      "   -3.1152239e+00 -2.4514062e+00 -2.3908834e+00 -2.3113658e+00\n",
      "   -2.4210641e+00]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.52223969e+00  7.00105619e+00  1.62721550e+00 -1.77343178e+00\n",
      "    9.78547037e-01  6.93074048e-01  3.02157849e-01 -1.94004393e+00\n",
      "   -1.10003316e+00 -1.55188382e+00 -1.71343136e+00  6.58917576e-02\n",
      "    1.52713448e-01  1.18095055e-01 -9.75957632e-01 -2.82102376e-01\n",
      "   -5.24258614e-03  3.14035080e-02 -2.11705521e-01 -4.47832167e-01\n",
      "   -2.79477453e+00 -3.02175546e+00 -2.67183685e+00 -2.03992367e+00\n",
      "   -3.08195567e+00 -2.51785088e+00 -2.38408780e+00 -2.35388660e+00\n",
      "   -2.47663164e+00]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5330453   6.948957    1.707317   -1.7957971   1.0044636\n",
      "    0.6586245   0.2867353  -1.9246365  -1.0940554  -1.5174727\n",
      "   -1.6975513   0.05087803  0.13081464  0.09733114 -0.96291095\n",
      "   -0.27081636 -0.01538147  0.03663224 -0.20204908 -0.4759617\n",
      "   -2.7953508  -3.007616   -2.693433   -2.0553691  -3.0611565\n",
      "   -2.553949   -2.3837242  -2.367282   -2.4981759 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5387483   6.9126043   1.7557491  -1.8104315   1.0162112\n",
      "    0.6407944   0.27479073 -1.9083043  -1.0859991  -1.4948795\n",
      "   -1.6834198   0.04256448  0.11616399  0.08456958 -0.95390916\n",
      "   -0.26452488 -0.02493958  0.03786375 -0.19853261 -0.4943054\n",
      "   -2.796892   -3.0001264  -2.7019868  -2.067308   -3.0464292\n",
      "   -2.5740113  -2.3858643  -2.367937   -2.503512  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5419765   6.886075    1.7867863  -1.820291    1.02215\n",
      "    0.6306008   0.26548153 -1.8935679  -1.078511   -1.4793115\n",
      "   -1.6717811   0.03734225  0.10612629  0.07618643 -0.9475976\n",
      "   -0.26081893 -0.03282925  0.03782127 -0.19745561 -0.50642526\n",
      "   -2.7982743  -2.9959579  -2.7047668  -2.0759182  -3.0350053\n",
      "   -2.586198   -2.3885171  -2.3643515  -2.5028179 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5439656   6.8662586   1.8077565  -1.8271043   1.0255738\n",
      "    0.6242135   0.2582955  -1.8812463  -1.072357   -1.4681935\n",
      "   -1.6625783   0.03369113  0.09909294  0.07027949 -0.94322973\n",
      "   -0.25863078 -0.03902134  0.03747592 -0.19743599 -0.51467866\n",
      "   -2.7993388  -2.993586   -2.705076   -2.0820305  -3.0260134\n",
      "   -2.5941687  -2.3909633  -2.3598866  -2.5003023 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5452495   6.8513093   1.8224723  -1.8318844   1.0277708\n",
      "    0.6199055   0.252818   -1.8713413  -1.067546   -1.4600686\n",
      "   -1.6554427   0.03096323  0.09406734  0.0659094  -0.9402469\n",
      "   -0.2573927  -0.04379151  0.03709156 -0.197918   -0.5204358\n",
      "   -2.8001041  -2.9922533  -2.7044024  -2.0863655  -3.0189981\n",
      "   -2.599631   -2.39301    -2.3557272  -2.4975464 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.546086    6.839982    1.8330624  -1.8352566   1.0292715\n",
      "    0.6168334   0.24868923 -1.863558   -1.0638665  -1.4540502\n",
      "   -1.6499686   0.02886264  0.09042218  0.06257717 -0.93823\n",
      "   -0.25675184 -0.04743484  0.03672647 -0.19862963 -0.524508\n",
      "   -2.800628   -2.9915338  -2.7034106  -2.0894487  -3.0135922\n",
      "   -2.6034694  -2.3946357  -2.3522134  -2.495082  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466213   6.831387    1.8407964  -1.8376331   1.0303193\n",
      "    0.61455417  0.24560884 -1.857531   -1.0610814  -1.4495624\n",
      "   -1.6458013   0.02723524  0.08775248  0.05999367 -0.93688136\n",
      "   -0.2564771  -0.05019825  0.03639342 -0.19941385 -0.52740234\n",
      "   -2.8009713  -2.9911766  -2.7023866  -2.0916507  -3.0094688\n",
      "   -2.6061974  -2.395881   -2.3493724  -2.493036  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.54695     6.8248663   1.8464787  -1.8392968   1.0310464\n",
      "    0.6128191   0.24333534 -1.8529116  -1.0589854  -1.4462152\n",
      "   -1.6426542   0.02598379  0.0857904   0.05797543 -0.9359933\n",
      "   -0.2564147  -0.05227616  0.03609768 -0.20017637 -0.52945244\n",
      "   -2.8011854  -2.9910283  -2.7014427  -2.0932286  -3.0063465\n",
      "   -2.6081388  -2.3967972  -2.3471236  -2.4913888 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5471365   6.8199315   1.8506498  -1.8404477   1.0315378\n",
      "    0.61147755  0.2416777  -1.8494003  -1.057415   -1.4437295\n",
      "   -1.6402984   0.02503661  0.08435151  0.0563945  -0.93542176\n",
      "   -0.25646496 -0.05381954  0.03584412 -0.20086433 -0.5308882\n",
      "   -2.801312   -2.9909961  -2.7006156  -2.0943613  -3.003992\n",
      "   -2.6095138  -2.3974416  -2.3453624  -2.490076  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5472283   6.816208    1.8536881  -1.8412278   1.031855\n",
      "    0.61043197  0.24048674 -1.8467513  -1.0562439  -1.4419012\n",
      "   -1.6385558   0.02433452  0.08330324  0.05515748 -0.9350679\n",
      "   -0.25656548 -0.0549484   0.03563532 -0.20145229 -0.53187305\n",
      "   -2.8013818  -2.9910262  -2.6999054  -2.0951755  -3.0022235\n",
      "   -2.610474   -2.397867   -2.343988   -2.4890292 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5472562   6.813416    1.8558724  -1.8417416   1.0320456\n",
      "    0.6096142   0.23964754 -1.8447663  -1.0553743  -1.4405733\n",
      "   -1.6372833   0.02382658  0.08254794  0.05419246 -0.93486327\n",
      "   -0.2566788  -0.05575784  0.03547074 -0.20193453 -0.5325277\n",
      "   -2.8014164  -2.9910855  -2.699301   -2.0957615  -3.0008943\n",
      "   -2.611132   -2.3981206  -2.342916   -2.4881902 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.547244    6.8113346   1.8574126  -1.8420653   1.032146\n",
      "    0.60897434  0.23906982 -1.8432897  -1.0547326  -1.4396265\n",
      "   -1.6363702   0.02347016  0.0820118   0.0534422  -0.9347603\n",
      "   -0.25678542 -0.05632339  0.0353478  -0.20231655 -0.5329418\n",
      "   -2.8014295  -2.991157   -2.698789   -2.0961826  -2.9998963\n",
      "   -2.61157    -2.3982444  -2.342078   -2.4875116 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5472076   6.8097944   1.8584694  -1.8422546   1.0321856\n",
      "    0.6084741   0.23868519 -1.8421997  -1.0542622  -1.438968\n",
      "   -1.6357292   0.02322948  0.08163849  0.05286082 -0.93472594\n",
      "   -0.25687513 -0.05670527  0.03526169 -0.20260967 -0.5331829\n",
      "   -2.8014314  -2.9912298  -2.698354   -2.0964847  -2.999146\n",
      "   -2.6118488  -2.3982728  -2.3414185  -2.4869583 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5471585   6.808666    1.8591676  -1.8423502   1.0321844\n",
      "    0.60808325  0.23844072 -1.8414018  -1.0539203  -1.4385251\n",
      "   -1.6352907   0.02307556  0.08138474  0.0524108  -0.9347369\n",
      "   -0.25694513 -0.05695089  0.03520663 -0.20282857 -0.5333022\n",
      "   -2.801429   -2.9913006  -2.6979837  -2.0967002  -2.9985802\n",
      "   -2.6120148  -2.3982337  -2.340899   -2.486504  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5471034   6.807848    1.8596025  -1.8423822   1.0321589\n",
      "    0.6077782   0.23829648 -1.8408229  -1.0536735  -1.4382409\n",
      "   -1.6350024   0.02298468  0.08121818  0.05206323 -0.9347762\n",
      "   -0.25699624 -0.05709707  0.03517635 -0.20298703 -0.533338\n",
      "   -2.8014243  -2.9913669  -2.6976688  -2.0968535  -2.9981523\n",
      "   -2.6121025  -2.39815    -2.3404865  -2.4861276 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5470474   6.8072605   1.8598487  -1.8423724   1.032119\n",
      "    0.6075404   0.2382226  -1.8404077  -1.0534984  -1.4380715\n",
      "   -1.6348233   0.02293908  0.08111327  0.05179513 -0.93483365\n",
      "   -0.25703093 -0.05717312  0.03516549 -0.20309804 -0.5333186\n",
      "   -2.8014205  -2.9914281  -2.6973994  -2.0969627  -2.9978278\n",
      "   -2.6121364  -2.3980384  -2.3401573  -2.4858146 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5469933   6.8068447   1.8599615  -1.8423359   1.0320735\n",
      "    0.6073546   0.23819733 -1.8401138  -1.0533755  -1.437985\n",
      "   -1.6347222   0.02292453  0.08105237  0.05158704 -0.93489975\n",
      "   -0.2570517  -0.0571995   0.03516867 -0.20317267 -0.5332644\n",
      "   -2.801417   -2.991481   -2.6971695  -2.0970402  -2.9975803\n",
      "   -2.6121364  -2.3979118  -2.339893   -2.4855528 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5469441   6.8065557   1.859983   -1.8422844   1.0320269\n",
      "    0.6072094   0.23820329 -1.8399082  -1.0532906  -1.4379556\n",
      "   -1.6346759   0.02293105  0.08102113  0.05142573 -0.93496966\n",
      "   -0.2570619  -0.05719289  0.03518161 -0.20322071 -0.5331903\n",
      "   -2.801416   -2.991531   -2.6969728  -2.0970948  -2.9973917\n",
      "   -2.6121125  -2.3977797  -2.3396792  -2.4853344 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.546899    6.806358    1.8599455  -1.8422248   1.0319818\n",
      "    0.60709536  0.23822936 -1.839768   -1.0532331  -1.4379642\n",
      "   -1.6346661   0.02295094  0.08100989  0.05130002 -0.93503976\n",
      "   -0.25706458 -0.05716568  0.03520102 -0.20324902 -0.533107\n",
      "   -2.8014166  -2.9915748  -2.6968043  -2.0971336  -2.9972458\n",
      "   -2.612076   -2.397649   -2.3395061  -2.4851494 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5468593   6.806228    1.8598711  -1.8421628   1.0319407\n",
      "    0.6070058   0.23826745 -1.8396742  -1.0531956  -1.4379979\n",
      "   -1.6346809   0.02297862  0.08101144  0.05120111 -0.9351074\n",
      "   -0.25706196 -0.05712545  0.0352241  -0.20326354 -0.53302103\n",
      "   -2.8014178  -2.9916148  -2.6966598  -2.0971603  -2.9971342\n",
      "   -2.6120338  -2.3975239  -2.3393657  -2.4849935 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.546825    6.8061433   1.8597754  -1.8421016   1.0319037\n",
      "    0.6069351   0.23831081 -1.839614   -1.0531722  -1.438046\n",
      "   -1.6347109   0.02301031  0.0810207   0.05112288 -0.93517107\n",
      "   -0.257055   -0.05707955  0.03524877 -0.20326865 -0.5329373\n",
      "   -2.8014202  -2.99165    -2.6965356  -2.0971806  -2.9970472\n",
      "   -2.6119893  -2.3974059  -2.33925    -2.484862  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5467951   6.806095    1.8596703  -1.8420434   1.0318718\n",
      "    0.60687876  0.23835632 -1.8395768  -1.053159   -1.4381021\n",
      "   -1.6347492   0.02304347  0.0810342   0.05106048 -0.93523014\n",
      "   -0.2570465  -0.05703065  0.03527398 -0.20326723 -0.5328583\n",
      "   -2.8014226  -2.9916813  -2.6964295  -2.0971947  -2.9969797\n",
      "   -2.6119452  -2.3972971  -2.3391554  -2.484752  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5467699   6.80607     1.8595631  -1.841989    1.031844\n",
      "    0.6068337   0.23840144 -1.8395568  -1.053152   -1.4381613\n",
      "   -1.6347916   0.02307603  0.08104945  0.05101022 -0.9352838\n",
      "   -0.25703657 -0.0569827   0.03529828 -0.20326239 -0.5327856\n",
      "   -2.801426   -2.9917097  -2.6963391  -2.0972052  -2.9969273\n",
      "   -2.6119034  -2.3971992  -2.3390772  -2.484658  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5467482   6.806057    1.859459   -1.8419399   1.0318207\n",
      "    0.60679764  0.23844427 -1.8395473  -1.0531495  -1.4382195\n",
      "   -1.6348349   0.0231071   0.0810656   0.05096949 -0.9353322\n",
      "   -0.2570262  -0.05693681  0.03532108 -0.20325513 -0.5327203\n",
      "   -2.80143    -2.9917343  -2.696262   -2.0972123  -2.9968858\n",
      "   -2.611865   -2.3971114  -2.3390129  -2.484579  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5467296   6.8060555   1.8593608  -1.8418956   1.0318009\n",
      "    0.60676813  0.23848364 -1.8395447  -1.05315    -1.4382756\n",
      "   -1.634877    0.0231358   0.08108086  0.05093592 -0.93537533\n",
      "   -0.25701582 -0.05689388  0.0353425  -0.20324667 -0.53266203\n",
      "   -2.801433   -2.9917567  -2.6961954  -2.0972183  -2.9968526\n",
      "   -2.6118312  -2.3970332  -2.3389595  -2.484512  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.546715    6.8060617   1.8592701  -1.841856    1.0317848\n",
      "    0.6067444   0.23851982 -1.8395483  -1.0531522  -1.4383279\n",
      "   -1.6349169   0.02316246  0.08109523  0.05090836 -0.93541425\n",
      "   -0.25700608 -0.05685474  0.035362   -0.20323782 -0.53261095\n",
      "   -2.801437   -2.991776   -2.6961389  -2.097223   -2.996827\n",
      "   -2.6118007  -2.396964   -2.3389149  -2.4844549 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5467021   6.80607     1.8591887  -1.8418214   1.0317711\n",
      "    0.60672456  0.23855168 -1.8395535  -1.0531557  -1.4383754\n",
      "   -1.6349534   0.02318632  0.08110804  0.05088513 -0.935448\n",
      "   -0.25699708 -0.05681942  0.0353793  -0.20322931 -0.5325665\n",
      "   -2.80144    -2.991793   -2.6960902  -2.0972266  -2.9968064\n",
      "   -2.6117735  -2.3969035  -2.338878   -2.4844065 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.546691    6.806081    1.8591157  -1.8417914   1.0317597\n",
      "    0.60670835  0.23858058 -1.8395606  -1.0531591  -1.4384184\n",
      "   -1.6349868   0.02320758  0.08111972  0.05086599 -0.93547773\n",
      "   -0.25698856 -0.0567882   0.03539481 -0.20322126 -0.5325279\n",
      "   -2.8014426  -2.991808   -2.696049   -2.0972297  -2.9967904\n",
      "   -2.6117496  -2.3968506  -2.3388474  -2.484366  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466824   6.806092    1.8590504  -1.8417645   1.0317504\n",
      "    0.606695    0.23860577 -1.8395678  -1.0531633  -1.4384569\n",
      "   -1.6350163   0.02322641  0.08112977  0.05084958 -0.93550396\n",
      "   -0.256981   -0.05676051  0.03540837 -0.20321405 -0.5324946\n",
      "   -2.8014462  -2.9918218  -2.696014   -2.097232   -2.9967766\n",
      "   -2.6117287  -2.3968046  -2.338821   -2.4843314 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466754   6.8061037   1.8589936  -1.841742    1.0317428\n",
      "    0.60668385  0.23862791 -1.8395758  -1.0531675  -1.438491\n",
      "   -1.6350429   0.02324314  0.0811386   0.05083562 -0.93552667\n",
      "   -0.25697413 -0.05673614  0.03542052 -0.20320714 -0.5324659\n",
      "   -2.8014483  -2.9918332  -2.6959832  -2.0972345  -2.9967656\n",
      "   -2.6117113  -2.3967652  -2.3388     -2.4843023 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.546669    6.8061147   1.8589437  -1.8417222   1.0317366\n",
      "    0.60667425  0.23864713 -1.8395834  -1.0531712  -1.4385213\n",
      "   -1.6350663   0.0232576   0.08114615  0.0508242  -0.9355464\n",
      "   -0.25696817 -0.05671507  0.03543102 -0.20320144 -0.5324415\n",
      "   -2.8014505  -2.9918437  -2.6959586  -2.0972366  -2.996756\n",
      "   -2.611696   -2.39673    -2.3387816  -2.484277  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466645   6.8061256   1.8588998  -1.8417048   1.0317315\n",
      "    0.6066665   0.23866364 -1.8395903  -1.0531747  -1.438547\n",
      "   -1.6350868   0.02327021  0.08115262  0.05081409 -0.9355637\n",
      "   -0.25696287 -0.05669664  0.03544005 -0.203196   -0.5324207\n",
      "   -2.8014529  -2.9918518  -2.6959364  -2.097238   -2.9967484\n",
      "   -2.611683   -2.396701   -2.3387666  -2.4842563 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466597   6.806135    1.858863   -1.8416901   1.0317273\n",
      "    0.6066599   0.23867792 -1.8395967  -1.0531777  -1.4385698\n",
      "   -1.6351044   0.02328115  0.08115803  0.05080517 -0.9355787\n",
      "   -0.25695828 -0.05668066  0.03544794 -0.20319158 -0.5324031\n",
      "   -2.8014545  -2.991859   -2.6959176  -2.09724    -2.9967427\n",
      "   -2.6116729  -2.396675   -2.3387542  -2.4842384 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466568   6.806144    1.8588302  -1.8416774   1.0317237\n",
      "    0.6066544   0.23869047 -1.8396033  -1.0531805  -1.4385897\n",
      "   -1.63512     0.02329065  0.0811625   0.05079789 -0.9355915\n",
      "   -0.2569541  -0.05666688  0.0354547  -0.20318772 -0.5323881\n",
      "   -2.8014567  -2.9918654  -2.695902   -2.0972412  -2.9967403\n",
      "   -2.6116633  -2.3966537  -2.3387434  -2.484223  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.546654    6.806153    1.8588032  -1.8416667   1.0317211\n",
      "    0.60664934  0.23870099 -1.839608   -1.0531832  -1.4386061\n",
      "   -1.6351335   0.02329865  0.08116635  0.05079146 -0.9356025\n",
      "   -0.25695083 -0.05665529  0.03546057 -0.20318459 -0.53237545\n",
      "   -2.8014576  -2.9918716  -2.695888   -2.0972428  -2.9967349\n",
      "   -2.6116555  -2.3966339  -2.3387344  -2.48421   ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466518   6.806158    1.8587792  -1.8416574   1.0317189\n",
      "    0.60664546  0.23870987 -1.8396127  -1.0531855  -1.4386212\n",
      "   -1.6351451   0.02330577  0.08116964  0.05078597 -0.935612\n",
      "   -0.2569475  -0.05664486  0.03546542 -0.20318164 -0.5323649\n",
      "   -2.801459   -2.9918761  -2.6958768  -2.0972438  -2.9967313\n",
      "   -2.6116483  -2.396618   -2.3387272  -2.484199  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466495   6.806164    1.8587583  -1.8416493   1.0317171\n",
      "    0.60664195  0.2387177  -1.839617   -1.0531871  -1.4386334\n",
      "   -1.6351547   0.02331183  0.08117232  0.05078129 -0.93562037\n",
      "   -0.25694513 -0.05663597  0.03546976 -0.20317917 -0.5323557\n",
      "   -2.80146    -2.9918807  -2.6958673  -2.0972447  -2.9967282\n",
      "   -2.6116421  -2.3966045  -2.3387208  -2.4841895 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.546648    6.806168    1.858741   -1.8416429   1.031715\n",
      "    0.60663897  0.23872402 -1.8396201  -1.0531887  -1.4386442\n",
      "   -1.6351634   0.02331705  0.08117449  0.05077711 -0.93562716\n",
      "   -0.25694284 -0.0566287   0.03547357 -0.20317699 -0.532348\n",
      "   -2.8014603  -2.9918852  -2.6958585  -2.0972455  -2.9967265\n",
      "   -2.6116376  -2.3965924  -2.3387156  -2.4841814 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.546647    6.806174    1.8587258  -1.8416369   1.031714\n",
      "    0.6066364   0.23872966 -1.8396238  -1.0531902  -1.4386537\n",
      "   -1.6351707   0.02332169  0.08117646  0.0507737  -0.9356332\n",
      "   -0.25694075 -0.0566223   0.03547652 -0.2031752  -0.5323417\n",
      "   -2.8014617  -2.991888   -2.6958518  -2.0972466  -2.996725\n",
      "   -2.6116338  -2.3965824  -2.338711   -2.4841747 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466459   6.806176    1.8587133  -1.8416319   1.0317129\n",
      "    0.6066341   0.23873466 -1.8396264  -1.0531915  -1.4386613\n",
      "   -1.6351769   0.02332525  0.08117788  0.05077076 -0.93563837\n",
      "   -0.2569391  -0.05661667  0.03547931 -0.20317379 -0.5323361\n",
      "   -2.8014624  -2.991891   -2.6958451  -2.0972474  -2.9967232\n",
      "   -2.6116307  -2.396574   -2.3387072  -2.4841697 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466447   6.80618     1.8587028  -1.8416276   1.031712\n",
      "    0.60663235  0.23873883 -1.8396285  -1.0531924  -1.438668\n",
      "   -1.635182    0.02332855  0.08117925  0.05076817 -0.9356425\n",
      "   -0.25693777 -0.05661196  0.03548172 -0.2031725  -0.5323317\n",
      "   -2.8014627  -2.9918928  -2.6958408  -2.0972486  -2.9967213\n",
      "   -2.6116273  -2.3965666  -2.338704   -2.4841647 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466437   6.8061833   1.8586931  -1.841624    1.0317113\n",
      "    0.6066308   0.23874217 -1.8396306  -1.0531934  -1.4386736\n",
      "   -1.6351868   0.02333149  0.08118019  0.05076585 -0.9356466\n",
      "   -0.2569366  -0.056608    0.03548361 -0.20317133 -0.53232765\n",
      "   -2.8014634  -2.9918952  -2.6958365  -2.097249   -2.996721\n",
      "   -2.6116252  -2.3965602  -2.3387012  -2.4841602 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-2.546644    6.8061857   1.8586854  -1.8416209   1.0317106\n",
      "    0.60662925  0.23874521 -1.8396325  -1.0531943  -1.4386787\n",
      "   -1.6351907   0.02333388  0.08118124  0.0507637  -0.93565017\n",
      "   -0.25693548 -0.05660453  0.03548528 -0.20317052 -0.53232425\n",
      "   -2.8014636  -2.9918964  -2.6958318  -2.0972493  -2.9967191\n",
      "   -2.6116228  -2.396555   -2.3386989  -2.4841566 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466433   6.806189    1.8586788  -1.8416183   1.0317099\n",
      "    0.60662794  0.23874786 -1.8396343  -1.0531949  -1.4386826\n",
      "   -1.635194    0.02333578  0.08118193  0.05076201 -0.9356526\n",
      "   -0.25693446 -0.0566015   0.03548674 -0.20316981 -0.5323216\n",
      "   -2.8014643  -2.9918983  -2.6958287  -2.0972497  -2.9967194\n",
      "   -2.6116207  -2.3965504  -2.3386974  -2.4841537 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466425   6.806191    1.8586732  -1.8416159   1.03171\n",
      "    0.6066272   0.23874995 -1.8396354  -1.0531955  -1.4386863\n",
      "   -1.6351967   0.02333757  0.08118267  0.05076085 -0.93565536\n",
      "   -0.25693375 -0.05659903  0.03548802 -0.20316905 -0.53231925\n",
      "   -2.8014643  -2.9918993  -2.695826   -2.0972502  -2.9967182\n",
      "   -2.6116202  -2.3965461  -2.338696   -2.4841511 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.546642    6.8061914   1.8586683  -1.8416145   1.0317093\n",
      "    0.6066263   0.23875192 -1.839636   -1.053196   -1.4386892\n",
      "   -1.6351992   0.02333913  0.08118297  0.05075914 -0.93565714\n",
      "   -0.25693312 -0.05659704  0.03548902 -0.20316856 -0.53231734\n",
      "   -2.8014648  -2.9919007  -2.695824   -2.0972505  -2.9967175\n",
      "   -2.6116178  -2.3965428  -2.338694   -2.4841497 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466416   6.8061943   1.858664   -1.8416128   1.0317093\n",
      "    0.60662556  0.23875326 -1.8396372  -1.0531963  -1.4386917\n",
      "   -1.6352012   0.0233404   0.08118338  0.05075844 -0.9356588\n",
      "   -0.25693247 -0.05659514  0.03548991 -0.20316818 -0.53231555\n",
      "   -2.801465   -2.9919012  -2.6958213  -2.0972507  -2.9967177\n",
      "   -2.611617   -2.3965397  -2.3386931  -2.4841475 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.546641    6.806193    1.8586608  -1.8416114   1.0317092\n",
      "    0.606625    0.23875469 -1.8396376  -1.0531965  -1.4386941\n",
      "   -1.6352028   0.02334145  0.08118392  0.0507576  -0.9356603\n",
      "   -0.25693196 -0.05659361  0.03549043 -0.20316781 -0.5323142\n",
      "   -2.8014648  -2.9919019  -2.69582    -2.0972517  -2.996717\n",
      "   -2.6116157  -2.396538   -2.3386927  -2.484146  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466416   6.8061943   1.8586577  -1.8416102   1.0317092\n",
      "    0.6066244   0.23875594 -1.8396385  -1.0531968  -1.4386959\n",
      "   -1.6352046   0.02334232  0.08118416  0.05075672 -0.93566203\n",
      "   -0.25693142 -0.0565922   0.03549112 -0.2031674  -0.5323131\n",
      "   -2.8014648  -2.991903   -2.695819   -2.0972514  -2.9967165\n",
      "   -2.6116147  -2.396536   -2.338692   -2.4841447 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466413   6.806196    1.8586555  -1.8416092   1.0317096\n",
      "    0.60662353  0.23875701 -1.8396391  -1.0531969  -1.4386977\n",
      "   -1.6352057   0.02334303  0.08118442  0.05075583 -0.93566287\n",
      "   -0.25693092 -0.05659121  0.03549151 -0.20316736 -0.53231186\n",
      "   -2.8014643  -2.9919035  -2.6958177  -2.097252   -2.9967165\n",
      "   -2.6116145  -2.3965347  -2.3386915  -2.4841435 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466413   6.8061967   1.8586534  -1.8416085   1.03171\n",
      "    0.60662293  0.23875791 -1.8396388  -1.0531968  -1.4386989\n",
      "   -1.635207    0.02334388  0.08118467  0.05075496 -0.9356636\n",
      "   -0.25693026 -0.05659018  0.03549178 -0.2031671  -0.5323108\n",
      "   -2.8014648  -2.9919035  -2.6958172  -2.0972521  -2.9967155\n",
      "   -2.6116142  -2.3965335  -2.338691   -2.4841423 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466413   6.8061967   1.8586522  -1.8416083   1.0317112\n",
      "    0.6066222   0.23875844 -1.8396381  -1.0531964  -1.4387006\n",
      "   -1.635208    0.02334424  0.08118492  0.05075432 -0.93566483\n",
      "   -0.25692937 -0.05658941  0.03549158 -0.20316711 -0.53230995\n",
      "   -2.8014643  -2.991904   -2.695817   -2.0972526  -2.9967153\n",
      "   -2.611613   -2.3965325  -2.3386905  -2.4841416 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466409   6.806197    1.8586514  -1.8416088   1.0317132\n",
      "    0.606621    0.23875946 -1.8396373  -1.0531958  -1.4387019\n",
      "   -1.635209    0.02334475  0.0811853   0.05075397 -0.93566585\n",
      "   -0.2569282  -0.05658916  0.03549133 -0.20316695 -0.5323087\n",
      "   -2.8014638  -2.991903   -2.6958172  -2.0972528  -2.996715\n",
      "   -2.6116116  -2.3965325  -2.3386898  -2.4841413 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.546641    6.806197    1.8586507  -1.8416095   1.0317171\n",
      "    0.6066194   0.23876005 -1.839636   -1.0531945  -1.4387032\n",
      "   -1.6352102   0.0233451   0.08118559  0.0507531  -0.9356673\n",
      "   -0.2569265  -0.05658887  0.03549036 -0.2031673  -0.5323074\n",
      "   -2.8014631  -2.9919026  -2.695818   -2.0972536  -2.9967146\n",
      "   -2.6116102  -2.3965333  -2.3386898  -2.4841404 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466413   6.806197    1.8586512  -1.8416119   1.0317231\n",
      "    0.6066167   0.23876125 -1.8396327  -1.0531926  -1.4387051\n",
      "   -1.635211    0.02334527  0.08118606  0.05075239 -0.93566877\n",
      "   -0.25692308 -0.05658913  0.03548844 -0.20316769 -0.53230566\n",
      "   -2.8014607  -2.9919002  -2.6958203  -2.0972543  -2.9967139\n",
      "   -2.6116083  -2.3965359  -2.33869    -2.48414   ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466418   6.806198    1.8586528  -1.841615    1.0317333\n",
      "    0.6066128   0.23876214 -1.8396274  -1.0531892  -1.4387075\n",
      "   -1.6352127   0.02334528  0.08118709  0.05075185 -0.9356709\n",
      "   -0.2569185  -0.05658963  0.03548545 -0.20316832 -0.53230315\n",
      "   -2.8014581  -2.9918983  -2.6958241  -2.097256   -2.996713\n",
      "   -2.6116054  -2.3965404  -2.3386908  -2.4841392 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466428   6.8061986   1.858656   -1.8416207   1.0317491\n",
      "    0.6066071   0.23876399 -1.8396188  -1.0531838  -1.4387113\n",
      "   -1.6352144   0.02334534  0.08118848  0.05075035 -0.93567437\n",
      "   -0.25691104 -0.0565908   0.03548024 -0.20316942 -0.53229916\n",
      "   -2.801453   -2.9918945  -2.69583    -2.0972576  -2.99671\n",
      "   -2.6116     -2.3965485  -2.3386917  -2.484139  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466447   6.8061986   1.8586607  -1.84163     1.0317746\n",
      "    0.6065978   0.23876646 -1.8396051  -1.0531752  -1.4387169\n",
      "   -1.6352174   0.023345    0.08119074  0.05074871 -0.9356796\n",
      "   -0.25689945 -0.05659296  0.03547213 -0.20317113 -0.53229344\n",
      "   -2.801445   -2.9918869  -2.6958406  -2.097261   -2.9967077\n",
      "   -2.611592   -2.3965604  -2.3386943  -2.484138  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466464   6.806201    1.8586698  -1.8416443   1.0318137\n",
      "    0.6065836   0.23877016 -1.839584   -1.0531623  -1.4387249\n",
      "   -1.6352221   0.02334455  0.08119404  0.05074626 -0.9356867\n",
      "   -0.25688142 -0.05659648  0.03545976 -0.20317401 -0.5322845\n",
      "   -2.801433   -2.9918756  -2.6958568  -2.0972655  -2.9967024\n",
      "   -2.6115808  -2.39658    -2.3386972  -2.484138  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466502   6.8062015   1.8586832  -1.8416669   1.0318738\n",
      "    0.6065621   0.23877573 -1.8395514  -1.0531422  -1.4387369\n",
      "   -1.635229    0.0233436   0.08119943  0.05074297 -0.9356979\n",
      "   -0.25685403 -0.05660184  0.03544052 -0.20317845 -0.532271\n",
      "   -2.801415   -2.991858   -2.6958811  -2.0972726  -2.9966953\n",
      "   -2.6115627  -2.3966103  -2.3387017  -2.4841375 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466552   6.806205    1.8587035  -1.8417001   1.0319641\n",
      "    0.60653013  0.23878422 -1.839503   -1.0531121  -1.4387548\n",
      "   -1.6352392   0.02334219  0.0812076   0.05073782 -0.9357149\n",
      "   -0.2568126  -0.05661027  0.03541174 -0.20318455 -0.5322508\n",
      "   -2.8013868  -2.9918327  -2.6959186  -2.0972831  -2.9966838\n",
      "   -2.6115358  -2.3966563  -2.3387089  -2.4841359 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.546663    6.8062077   1.858734   -1.8417506   1.0320985\n",
      "    0.6064825   0.2387971  -1.8394308  -1.0530673  -1.4387821\n",
      "   -1.6352545   0.02334024  0.08121993  0.05073107 -0.9357402\n",
      "   -0.25675127 -0.05662254  0.03536855 -0.20319389 -0.53222096\n",
      "   -2.8013458  -2.9917932  -2.6959739  -2.097299   -2.9966676\n",
      "   -2.6114955  -2.3967247  -2.3387198  -2.484135  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466745   6.806212    1.858778   -1.8418243   1.032296\n",
      "    0.6064132   0.23881575 -1.839325   -1.0530018  -1.4388214\n",
      "   -1.6352767   0.02333735  0.0812384   0.05072097 -0.93577695\n",
      "   -0.25666076 -0.05664075  0.03530594 -0.20320736 -0.5321767\n",
      "   -2.8012846  -2.9917362  -2.696055   -2.097322   -2.996643\n",
      "   -2.6114352  -2.3968246  -2.3387353  -2.484133  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5466905   6.806221    1.8588411  -1.8419306   1.0325824\n",
      "    0.6063129   0.2388438  -1.8391721  -1.0529075  -1.4388788\n",
      "   -1.6353098   0.0233337   0.0812658   0.05070744 -0.9358309\n",
      "   -0.2565298  -0.05666699  0.03521499 -0.2032264  -0.5321127\n",
      "   -2.801196   -2.9916532  -2.6961732  -2.0973554  -2.996609\n",
      "   -2.6113489  -2.3969696  -2.3387578  -2.4841304 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.546713    6.806235    1.8589302  -1.8420835   1.0329928\n",
      "    0.6061701   0.23888418 -1.8389542  -1.0527728  -1.438961\n",
      "   -1.6353583   0.0233285   0.08130603  0.05068886 -0.93590754\n",
      "   -0.2563419  -0.05670483  0.035085   -0.20325346 -0.5320207\n",
      "   -2.8010702  -2.991533   -2.696342   -2.0974028  -2.99656\n",
      "   -2.6112244  -2.3971767  -2.33879    -2.4841256 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5467465   6.8062563   1.8590546  -1.8422995   1.0335741\n",
      "    0.6059685   0.23894256 -1.8386464  -1.0525835  -1.4390781\n",
      "   -1.6354274   0.02332167  0.08136395  0.05066317 -0.93601644\n",
      "   -0.25607616 -0.05675781  0.03490211 -0.2032908  -0.53189045\n",
      "   -2.8008916  -2.9913657  -2.69658    -2.0974689  -2.9964895\n",
      "   -2.6110485  -2.3974693  -2.3388355  -2.48412   ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5467918   6.806286    1.8592267  -1.8426018   1.0343864\n",
      "    0.6056884   0.23902518 -1.8382174  -1.0523192  -1.439242\n",
      "   -1.6355256   0.02331306  0.08144644  0.05062882 -0.9361697\n",
      "   -0.25570434 -0.05683154  0.03464684 -0.20334199 -0.5317078\n",
      "   -2.8006425  -2.9911299  -2.6969137  -2.0975616  -2.9963913\n",
      "   -2.6108027  -2.3978775  -2.3388987  -2.48411   ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.546855    6.80633     1.8594608  -1.8430185   1.0355097\n",
      "    0.6053028   0.23914087 -1.8376263  -1.0519564  -1.4394691\n",
      "   -1.6356626   0.02330196  0.08156238  0.05058365 -0.936382\n",
      "   -0.25518984 -0.05693272  0.03429548 -0.20341104 -0.53145456\n",
      "   -2.8002975  -2.9908044  -2.6973739  -2.0976887  -2.9962578\n",
      "   -2.6104624  -2.3984408  -2.3389854  -2.484096  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.54694     6.806394    1.8597758  -1.8435874   1.037044\n",
      "    0.6047786   0.23930156 -1.8368231  -1.0514632  -1.4397807\n",
      "   -1.6358528   0.02328845  0.08172419  0.05052452 -0.9366732\n",
      "   -0.25448734 -0.05707023  0.03381708 -0.20350364 -0.5311079\n",
      "   -2.799828   -2.99036    -2.6980011  -2.0978625  -2.9960742\n",
      "   -2.609995   -2.399208   -2.3391032  -2.484078  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5470564   6.8064837   1.8601936  -1.8443546   1.0391147\n",
      "    0.60407436  0.23952222 -1.8357419  -1.0508013  -1.4402025\n",
      "   -1.6361132   0.02327231  0.08194642  0.05044863 -0.9370676\n",
      "   -0.25353858 -0.05725452  0.03317408 -0.2036259  -0.530639\n",
      "   -2.7991939  -2.9897592  -2.6988463  -2.0980954  -2.9958284\n",
      "   -2.6093647  -2.4002416  -2.339261   -2.4840505 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5472095   6.8066125   1.8607415  -1.8453758   1.0418764\n",
      "    0.60314     0.23982108 -1.8343059  -1.049923   -1.4407679\n",
      "   -1.6364653   0.0232534   0.08224863  0.05035254 -0.93759423\n",
      "   -0.25227273 -0.05749828  0.03231942 -0.20378463 -0.53001153\n",
      "   -2.7983494  -2.9889605  -2.6999714  -2.0984046  -2.9955008\n",
      "   -2.6085215  -2.4016166  -2.339471   -2.4840124 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5474114   6.806785    1.8614498  -1.84672     1.0455143\n",
      "    0.6019153   0.24022087 -1.8324218  -1.0487729  -1.4415146\n",
      "   -1.6369363   0.02323247  0.08265494  0.05023344 -0.9382913\n",
      "   -0.25060487 -0.05781737  0.03119854 -0.20398845 -0.5291833\n",
      "   -2.797238   -2.9879076  -2.7014515  -2.0988102  -2.9950726\n",
      "   -2.6074083  -2.4034224  -2.339745   -2.4839609 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.547673    6.807025    1.8623538  -1.8484652   1.0502447\n",
      "    0.60033184  0.24075001 -1.8299829  -1.0472862  -1.4424901\n",
      "   -1.6375585   0.02321053  0.08319362  0.05008811 -0.93920034\n",
      "   -0.24843562 -0.0582286   0.02974724 -0.20424648 -0.528103\n",
      "   -2.7957938  -2.9865391  -2.703373   -2.0993338  -2.9945168\n",
      "   -2.605957   -2.4057643  -2.3400989  -2.4838905 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.548007    6.807348    1.8634896  -1.850702    1.0563145\n",
      "    0.5983115   0.24144053 -1.8268667  -1.0453905  -1.4437467\n",
      "   -1.6383692   0.02318945  0.08389966  0.0499154  -0.9403711\n",
      "   -0.2456512  -0.05875201  0.02789314 -0.20456775 -0.5267128\n",
      "   -2.7939432  -2.9847867  -2.7058332  -2.100003   -2.9938073\n",
      "   -2.604091   -2.408762   -2.3405502  -2.4837961 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5484293   6.807779    1.8648932  -1.8535266   1.0639924\n",
      "    0.59577113  0.24233001 -1.8229443  -1.0430088  -1.4453436\n",
      "   -1.6394128   0.02317306  0.08481249  0.04971433 -0.941858\n",
      "   -0.24212752 -0.05940764  0.02555918 -0.20496047 -0.5249479\n",
      "   -2.7916043  -2.982566   -2.7089374  -2.1008444  -2.9929137\n",
      "   -2.6017244  -2.4125412  -2.341116   -2.4836717 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5489538   6.8083425   1.8665993  -1.8570404   1.0735599\n",
      "    0.5926262   0.24345985 -1.818081   -1.040063   -1.4473435\n",
      "   -1.6407357   0.02316536  0.08597635  0.0494875  -0.9437178\n",
      "   -0.23773569 -0.06021667  0.02266528 -0.20543222 -0.5227416\n",
      "   -2.7886925  -2.9798038  -2.7127986  -2.1018858  -2.991805\n",
      "   -2.5987673  -2.4172354  -2.3418157  -2.4835076 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5495934   6.809068    1.8686323  -1.8613408   1.0852898\n",
      "    0.5887975   0.2448729  -1.8121512  -1.0364798  -1.4498091\n",
      "   -1.642389    0.0231737   0.08743875  0.04924097 -0.9460081\n",
      "   -0.23234878 -0.06119753  0.01913701 -0.2059871  -0.52002573\n",
      "   -2.7851255  -2.9764194  -2.7175202  -2.1031535  -2.9904542\n",
      "   -2.5951297  -2.4229705  -2.3426657  -2.483296  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.550363    6.809993    1.8710066  -1.8665125   1.0994236\n",
      "    0.58421886  0.24661219 -1.8050483  -1.0321997  -1.4527969\n",
      "   -1.6444222   0.02320714  0.0892472   0.04898532 -0.94878036\n",
      "   -0.22585583 -0.06236456  0.01491073 -0.20662461 -0.51673985\n",
      "   -2.780832   -2.9723415  -2.7231934  -2.1046698  -2.9888375\n",
      "   -2.590732   -2.4298544  -2.3436804  -2.483026  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5512705   6.811148    1.8737164  -1.872616    1.1161398\n",
      "    0.57884806  0.24871683 -1.7967025  -1.0271853  -1.4563553\n",
      "   -1.6468798   0.02327692  0.09144647  0.04873557 -0.9520754\n",
      "   -0.21817313 -0.06372564  0.00994436 -0.20733848 -0.51283526\n",
      "   -2.7757585  -2.9675236  -2.729884   -2.1064477  -2.9869387\n",
      "   -2.5855105  -2.4379623  -2.3448677  -2.4826872 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5523190e+00  6.8125629e+00  1.8767318e+00 -1.8796759e+00\n",
      "    1.1355215e+00  5.7267618e-01  2.5121671e-01 -1.7870938e+00\n",
      "   -1.0214319e+00 -1.4605114e+00 -1.6497960e+00  2.3396492e-02\n",
      "    9.4073601e-02  4.8513375e-02 -9.5591599e-01 -2.0926248e-01\n",
      "   -6.5278657e-02  4.2264238e-03 -2.0811482e-01 -5.0828457e-01\n",
      "   -2.7698812e+00 -2.9619405e+00 -2.7376158e+00 -2.1084898e+00\n",
      "   -2.9847541e+00 -2.5794308e+00 -2.4473212e+00 -2.3462305e+00\n",
      "   -2.4822683e+00]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5535061e+00  6.8142667e+00  1.8800004e+00 -1.8876698e+00\n",
      "    1.1575253e+00  5.6573671e-01  2.5412837e-01 -1.7762687e+00\n",
      "   -1.0149748e+00 -1.4652692e+00 -1.6531907e+00  2.3580939e-02\n",
      "    9.7151808e-02  4.8343077e-02 -9.6030086e-01 -1.9914170e-01\n",
      "   -6.7010388e-02 -2.2155009e-03 -2.0893304e-01 -5.0308883e-01\n",
      "   -2.7632141e+00 -2.9556053e+00 -2.7463632e+00 -2.1107850e+00\n",
      "   -2.9822972e+00 -2.5724955e+00 -2.4578931e+00 -2.3477585e+00\n",
      "   -2.4817593e+00]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.554821    6.81627     1.8834397  -1.8965209   1.1819589\n",
      "    0.5581111   0.25744972 -1.7643473  -1.0078933  -1.4706006\n",
      "   -1.6570615   0.02384431  0.1006865   0.04825266 -0.9651992\n",
      "   -0.18789901 -0.06889358 -0.00931002 -0.20976399 -0.49728197\n",
      "   -2.755816   -2.9485765  -2.7560375  -2.1133041  -2.9795964\n",
      "   -2.564755   -2.4695692  -2.3494337  -2.481151  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.556245    6.8185725   1.8869498  -1.9060979   1.2084785\n",
      "    0.54992616  0.26115662 -1.7515229  -1.0003107  -1.4764478\n",
      "   -1.6613809   0.0241995   0.10466034  0.04826863 -0.97054994\n",
      "   -0.17569165 -0.07089011 -0.01694183 -0.21057533 -0.49093482\n",
      "   -2.7477913  -2.9409533  -2.7664948  -2.116004   -2.9766986\n",
      "   -2.5563047  -2.482168   -2.3512292  -2.4804406 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5577524   6.821161    1.8904176  -1.916218    1.2366002\n",
      "    0.54134905  0.2652025  -1.7380522  -0.9923854  -1.4827178\n",
      "   -1.6660966   0.02465561  0.1090313   0.04841328 -0.97626334\n",
      "   -0.16274251 -0.07295115 -0.02495807 -0.21133165 -0.48415217\n",
      "   -2.739285   -2.932876   -2.7775316  -2.1188273  -2.9736662\n",
      "   -2.5472898  -2.495443   -2.353106   -2.4796274 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5593128   6.8240023   1.8937285  -1.9266651   1.265735\n",
      "    0.5325711   0.26951832 -1.7242334  -0.9842998  -1.4892942\n",
      "   -1.671131    0.02521527  0.1137339   0.04870094 -0.9822249\n",
      "   -0.14932285 -0.0750227  -0.03318044 -0.21200015 -0.47706535\n",
      "   -2.7304718  -2.924515   -2.7889097  -2.1217093  -2.9705684\n",
      "   -2.5378883  -2.5091033  -2.355024   -2.478715  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-2.5608914   6.8270416   1.8967817  -1.9372046   1.2952417\n",
      "    0.5237946   0.27401862 -1.7103833  -0.9762418  -1.4960442\n",
      "   -1.6763877   0.02587484  0.11868192  0.04913533 -0.9883078\n",
      "   -0.13572918 -0.07704945 -0.04142021 -0.21255417 -0.4698229\n",
      "   -2.7215464  -2.916057   -2.8003736  -2.1245806  -2.9674814\n",
      "   -2.5283015  -2.5228367  -2.3569405  -2.477714  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.562458    6.830221    1.8994986  -1.9476056   1.324478\n",
      "    0.51520956  0.2786074  -1.6968033  -0.96838754 -1.5028279\n",
      "   -1.6817579   0.02662364  0.12377562  0.04970759 -0.9943811\n",
      "   -0.12225948 -0.07898106 -0.04949706 -0.21297634 -0.4625769\n",
      "   -2.7126992  -2.9076862  -2.811672   -2.1273777  -2.964475\n",
      "   -2.5187342  -2.5363412  -2.358814   -2.476641  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.563979    6.8334665   1.9018301  -1.9576623   1.3528595\n",
      "    0.50698173  0.28318688 -1.6837593  -0.96088916 -1.5095133\n",
      "   -1.6871334   0.02744434  0.12891105  0.05039903 -1.0003237\n",
      "   -0.10918424 -0.08077744 -0.05725231 -0.21325986 -0.45547187\n",
      "   -2.704105   -2.8995693  -2.822581   -2.130044   -2.9616103\n",
      "   -2.509379   -2.5493462  -2.3606102  -2.475514  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5654318   6.8367066   1.903757   -1.9672036   1.3798964\n",
      "    0.49924093  0.28766543 -1.6714622  -0.95386183 -1.5159818\n",
      "   -1.6924098   0.02831533  0.13398638  0.05118295 -1.00603\n",
      "   -0.09673239 -0.08240876 -0.06455995 -0.21340823 -0.44863296\n",
      "   -2.6959095  -2.8918502  -2.8329167  -2.1325374  -2.9589367\n",
      "   -2.5004041  -2.5616333  -2.3623035  -2.4743562 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5667956   6.839881    1.9052908  -1.9761057   1.4052197\n",
      "    0.49207664  0.29196438 -1.6600599  -0.9473833  -1.5221376\n",
      "   -1.6974971   0.0292134   0.13891101  0.05202684 -1.0114172\n",
      "   -0.08507513 -0.08385866 -0.0713319  -0.2134337  -0.4421598\n",
      "   -2.6882238  -2.8846333  -2.8425453  -2.134828   -2.9564848\n",
      "   -2.4919403  -2.573046   -2.3638747  -2.4731889 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5680583   6.8429255   1.9064623  -1.9842908   1.4285872\n",
      "    0.4855379   0.29602078 -1.6496389  -0.94149303 -1.5279108\n",
      "   -1.7023237   0.03011523  0.14361012  0.05289887 -1.0164284\n",
      "   -0.07432596 -0.08512256 -0.07751702 -0.21335472 -0.43612406\n",
      "   -2.68112    -2.8779848  -2.851387   -2.1369023  -2.9542716\n",
      "   -2.4840782  -2.583488   -2.3653164  -2.4720333 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.569211    6.8458023   1.9073173  -1.9917226   1.4498745\n",
      "    0.47964036  0.29979062 -1.6402287  -0.9361992  -1.5332553\n",
      "   -1.7068386   0.0309999   0.14802733  0.05376955 -1.0210286\n",
      "   -0.06454334 -0.08620515 -0.08309774 -0.21319269 -0.43056914\n",
      "   -2.6746366  -2.8719442  -2.859405   -2.1387568  -2.9522996\n",
      "   -2.4768724  -2.5929217  -2.3666239  -2.4709077 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5702527   6.8484764   1.9079084  -1.9984014   1.4690572\n",
      "    0.47437155  0.30324844 -1.6318161  -0.9314853  -1.5381471\n",
      "   -1.7110099   0.03184997  0.15212512  0.05461261 -1.0252063\n",
      "   -0.05573863 -0.08711828 -0.08808242 -0.21296951 -0.42551348\n",
      "   -2.6687818  -2.866514   -2.8666012  -2.1403978  -2.950561\n",
      "   -2.4703422  -2.6013525  -2.3678014  -2.4698293 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5711842   6.8509326   1.9082887  -2.0043526   1.4861892\n",
      "    0.46969983  0.3063838  -1.6243547  -0.9273173  -1.5425837\n",
      "   -1.7148234   0.03265246  0.15588325  0.05541014 -1.0289652\n",
      "   -0.04788595 -0.08787803 -0.09249939 -0.21270527 -0.4209556\n",
      "   -2.6635413  -2.8616762  -2.8730066  -2.1418393  -2.9490447\n",
      "   -2.46448    -2.6088214  -2.3688548  -2.4688077 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.572012    6.8531647   1.9085065  -2.009621    1.5013804\n",
      "    0.46558118  0.30919978 -1.6177789  -0.92365146 -1.5465761\n",
      "   -1.7182784   0.03339812  0.15929681  0.05614772 -1.0323217\n",
      "   -0.04093476 -0.08850279 -0.09638888 -0.2124178  -0.41687804\n",
      "   -2.658882   -2.8574007  -2.8786705  -2.1430974  -2.947727\n",
      "   -2.4592605  -2.6153927  -2.369794   -2.4678526 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5727406   6.855172    1.9086049  -2.014261    1.5147743\n",
      "    0.46196514  0.31170908 -1.6120094  -0.9204384  -1.5501455\n",
      "   -1.7213866   0.03408212  0.16237214  0.05681887 -1.0353013\n",
      "   -0.03481677 -0.08901149 -0.09979855 -0.21212159 -0.4132534\n",
      "   -2.6547627  -2.853643   -2.883654   -2.1441913  -2.9465919\n",
      "   -2.454641   -2.6211445  -2.3706286  -2.4669669 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5733795   6.8569684   1.9086183  -2.0183322   1.5265335\n",
      "    0.45879862  0.31393093 -1.6069636  -0.9176288  -1.5533205\n",
      "   -1.7241659   0.03470308  0.16512474  0.05741972 -1.0379349\n",
      "   -0.02945645 -0.08942186 -0.10277766 -0.21182759 -0.4100466\n",
      "   -2.6511357  -2.8503544  -2.8880236  -2.1451397  -2.9456155\n",
      "   -2.450571   -2.6261578  -2.3713694  -2.4661522 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5739362   6.8585606   1.908575   -2.021896    1.5368257\n",
      "    0.45603132  0.31588885 -1.6025609  -0.9151744  -1.5561345\n",
      "   -1.7266399   0.03526168  0.16757527  0.05795176 -1.0402544\n",
      "   -0.02477381 -0.08975022 -0.10537565 -0.21154378 -0.40722016\n",
      "   -2.647951   -2.8474855  -2.8918457  -2.145962   -2.9447765\n",
      "   -2.4470003  -2.6305158  -2.372026   -2.4654078 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5744197   6.859971    1.9084965  -2.0250103   1.5458146\n",
      "    0.45361432  0.31760803 -1.5987228  -0.91303074 -1.5586199\n",
      "   -1.728834    0.03576056  0.16974774  0.0584181  -1.0422919\n",
      "   -0.02069216 -0.09001069 -0.10763873 -0.21127515 -0.4047358\n",
      "   -2.6451602  -2.8449876  -2.895183   -2.1466746  -2.944058\n",
      "   -2.4438734  -2.6342988  -2.3726072  -2.4647326 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5748389   6.861213    1.9083972  -2.0277297   1.5536565\n",
      "    0.45150343  0.3191132  -1.5953777  -0.9111578  -1.560812\n",
      "   -1.7307755   0.03620367  0.17166758  0.0588228  -1.0440801\n",
      "   -0.0171384  -0.09021607 -0.10960957 -0.21102509 -0.40255564\n",
      "   -2.642717   -2.8428166  -2.8980966  -2.1472921  -2.9434404\n",
      "   -2.4411414  -2.6375785  -2.3731236  -2.464121  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5752013   6.8623056   1.9082884  -2.030104    1.5604935\n",
      "    0.44965863  0.3204293  -1.5924627  -0.90952    -1.562742\n",
      "   -1.73249     0.03659556  0.1733605   0.05917235 -1.0456471\n",
      "   -0.01404602 -0.09037648 -0.11132652 -0.21079488 -0.40064466\n",
      "   -2.6405792  -2.840929   -2.9006398  -2.1478271  -2.9429114\n",
      "   -2.4387558  -2.640423   -2.3735807  -2.46357   ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5755131   6.863266    1.9081777  -2.0321777   1.5664557\n",
      "    0.4480453   0.32157934 -1.5899204  -0.90808564 -1.5644405\n",
      "   -1.7340028   0.03694133  0.17485106  0.05947271 -1.0470206\n",
      "   -0.01135381 -0.09050121 -0.11282331 -0.2105851  -0.3989696\n",
      "   -2.6387088  -2.8392873  -2.9028609  -2.1482937  -2.9424558\n",
      "   -2.4366715  -2.6428905  -2.3739865  -2.4630754 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5757828   6.864108    1.90807    -2.033991    1.5716575\n",
      "    0.44663218  0.32258356 -1.5877     -0.9068276  -1.5659354\n",
      "   -1.7353365   0.03724529  0.17616192  0.05972992 -1.048225\n",
      "   -0.00900882 -0.09059715 -0.11413023 -0.21039517 -0.39750174\n",
      "   -2.6370707  -2.8378599  -2.9048016  -2.1487     -2.9420624\n",
      "   -2.4348516  -2.645033   -2.374347   -2.4626317 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5760152   6.864846    1.907968   -2.0355773   1.5762006\n",
      "    0.44539303  0.32346177 -1.5857583  -0.90572244 -1.5672507\n",
      "   -1.7365131   0.03751297  0.17731482  0.05994931 -1.0492812\n",
      "   -0.00696329 -0.09067008 -0.1152727  -0.2102246  -0.39621434\n",
      "   -2.635635   -2.836616   -2.9065006  -2.1490548  -2.941724\n",
      "   -2.4332604  -2.646897   -2.3746667  -2.4622343 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5762157e+00  6.8654957e+00  1.9078737e+00 -2.0369673e+00\n",
      "    1.5801734e+00  4.4430402e-01  3.2422948e-01 -1.5840578e+00\n",
      "   -9.0474987e-01 -1.5684102e+00 -1.7375506e+00  3.7748124e-02\n",
      "    1.7832869e-01  6.0136057e-02 -1.0502096e+00 -5.1763710e-03\n",
      "   -9.0724893e-02 -1.1627327e-01 -2.1007153e-01 -3.9508381e-01\n",
      "   -2.6343744e+00 -2.8355298e+00 -2.9079888e+00 -2.1493652e+00\n",
      "   -2.9414310e+00 -2.4318671e+00 -2.6485188e+00 -2.3749523e+00\n",
      "   -2.4618795e+00]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5763896e+00  6.8660669e+00  1.9077871e+00 -2.0381877e+00\n",
      "    1.5836535e+00  4.4334549e-01  3.2490203e-01 -1.5825661e+00\n",
      "   -9.0389198e-01 -1.5694324e+00 -1.7384669e+00  3.7954990e-02\n",
      "    1.7922065e-01  6.0294844e-02 -1.0510254e+00 -3.6130678e-03\n",
      "   -9.0765953e-02 -1.1715157e-01 -2.0993511e-01 -3.9409056e-01\n",
      "   -2.6332667e+00 -2.8345811e+00 -2.9092963e+00 -2.1496387e+00\n",
      "   -2.9411757e+00 -2.4306471e+00 -2.6499355e+00 -2.3752062e+00\n",
      "   -2.4615617e+00]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5765388e+00  6.8665686e+00  1.9077083e+00 -2.0392604e+00\n",
      "    1.5867070e+00  4.4250005e-01  3.2549226e-01 -1.5812541e+00\n",
      "   -9.0313405e-01 -1.5703346e+00 -1.7392761e+00  3.8136762e-02\n",
      "    1.8000618e-01  6.0430691e-02 -1.0517439e+00 -2.2419449e-03\n",
      "   -9.0795532e-02 -1.1792344e-01 -2.0981352e-01 -3.9321542e-01\n",
      "   -2.6322918e+00 -2.8337500e+00 -2.9104462e+00 -2.1498790e+00\n",
      "   -2.9409533e+00 -2.4295747e+00 -2.6511736e+00 -2.3754320e+00\n",
      "   -2.4612780e+00]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.57666826e+00  6.86701059e+00  1.90763819e+00 -2.04020548e+00\n",
      "    1.58939147e+00  4.41753030e-01  3.26010704e-01 -1.58009887e+00\n",
      "   -9.02462959e-01 -1.57113254e+00 -1.73999226e+00  3.82970013e-02\n",
      "    1.80698484e-01  6.05461523e-02 -1.05237818e+00 -1.03690289e-03\n",
      "   -9.08171609e-02 -1.18603855e-01 -2.09705427e-01 -3.92444164e-01\n",
      "   -2.63143229e+00 -2.83301973e+00 -2.91145873e+00 -2.15009165e+00\n",
      "   -2.94075847e+00 -2.42863059e+00 -2.65225959e+00 -2.37563348e+00\n",
      "   -2.46102452e+00]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.57678199e+00  6.86740112e+00  1.90757489e+00 -2.04103899e+00\n",
      "    1.59175611e+00  4.41091537e-01  3.26467782e-01 -1.57907867e+00\n",
      "   -9.01867926e-01 -1.57183921e+00 -1.74062645e+00  3.84381674e-02\n",
      "    1.81309134e-01  6.06447533e-02 -1.05293858e+00  2.44472176e-05\n",
      "   -9.08320397e-02 -1.19204625e-01 -2.09609374e-01 -3.91762525e-01\n",
      "   -2.63067222e+00 -2.83237815e+00 -2.91235304e+00 -2.15027928e+00\n",
      "   -2.94058847e+00 -2.42779827e+00 -2.65321374e+00 -2.37581396e+00\n",
      "   -2.46079874e+00]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5768797e+00  6.8677464e+00  1.9075191e+00 -2.0417764e+00\n",
      "    1.5938438e+00  4.4050437e-01  3.2687086e-01 -1.5781757e+00\n",
      "   -9.0133917e-01 -1.5724661e+00 -1.7411886e+00  3.8562860e-02\n",
      "    1.8184897e-01  6.0729004e-02 -1.0534343e+00  9.6172281e-04\n",
      "   -9.0841964e-02 -1.1973648e-01 -2.0952426e-01 -3.9115915e-01\n",
      "   -2.6299996e+00 -2.8318105e+00 -2.9131444e+00 -2.1504464e+00\n",
      "   -2.9404373e+00 -2.4270635e+00 -2.6540544e+00 -2.3759751e+00\n",
      "   -2.4605961e+00]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5769656e+00  6.8680530e+00  1.9074695e+00 -2.0424297e+00\n",
      "    1.5956906e+00  4.3998253e-01  3.2722741e-01 -1.5773752e+00\n",
      "   -9.0086824e-01 -1.5730230e+00 -1.7416879e+00  3.8673412e-02\n",
      "    1.8232650e-01  6.0801432e-02 -1.0538741e+00  1.7909873e-03\n",
      "   -9.0848505e-02 -1.2020816e-01 -2.0944878e-01 -3.9062405e-01\n",
      "   -2.6294024e+00 -2.8313098e+00 -2.9138460e+00 -2.1505942e+00\n",
      "   -2.9403048e+00 -2.4264123e+00 -2.6547976e+00 -2.3761187e+00\n",
      "   -2.4604154e+00]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.57704043e+00  6.86832333e+00  1.90742600e+00 -2.04300952e+00\n",
      "    1.59732938e+00  4.39517200e-01  3.27543199e-01 -1.57666373e+00\n",
      "   -9.00447905e-01 -1.57351863e+00 -1.74213231e+00  3.87711413e-02\n",
      "    1.82749927e-01  6.08633682e-02 -1.05426538e+00  2.52712704e-03\n",
      "   -9.08522010e-02 -1.20627746e-01 -2.09382072e-01 -3.90148580e-01\n",
      "   -2.62887168e+00 -2.83086562e+00 -2.91446924e+00 -2.15072703e+00\n",
      "   -2.94018626e+00 -2.42583513e+00 -2.65545487e+00 -2.37624836e+00\n",
      "   -2.46025419e+00]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.57710648e+00  6.86856365e+00  1.90738797e+00 -2.04352522e+00\n",
      "    1.59878564e+00  4.39101905e-01  3.27823937e-01 -1.57603025e+00\n",
      "   -9.00072217e-01 -1.57396054e+00 -1.74252820e+00  3.88578810e-02\n",
      "    1.83125705e-01  6.09166697e-02 -1.05461311e+00  3.18163075e-03\n",
      "   -9.08542275e-02 -1.21001676e-01 -2.09323019e-01 -3.89725238e-01\n",
      "   -2.62839937e+00 -2.83047152e+00 -2.91502452e+00 -2.15084505e+00\n",
      "   -2.94008231e+00 -2.42532063e+00 -2.65603852e+00 -2.37636375e+00\n",
      "   -2.46010995e+00]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.57716465e+00  6.86877966e+00  1.90735483e+00 -2.04398537e+00\n",
      "    1.60008287e+00  4.38730210e-01  3.28073949e-01 -1.57546437e+00\n",
      "   -8.99735749e-01 -1.57435524e+00 -1.74288130e+00  3.89352851e-02\n",
      "    1.83459699e-01  6.09627143e-02 -1.05492365e+00  3.76510806e-03\n",
      "   -9.08548087e-02 -1.21335626e-01 -2.09270716e-01 -3.89347523e-01\n",
      "   -2.62797737e+00 -2.83011961e+00 -2.91551995e+00 -2.15095186e+00\n",
      "   -2.93998742e+00 -2.42486310e+00 -2.65655875e+00 -2.37646770e+00\n",
      "   -2.45998025e+00]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5772164e+00  6.8689709e+00  1.9073251e+00 -2.0443966e+00\n",
      "    1.6012417e+00  4.3839684e-01  3.2829663e-01 -1.5749581e+00\n",
      "   -8.9943385e-01 -1.5747085e+00 -1.7431967e+00  3.9004136e-02\n",
      "    1.8375725e-01  6.1002456e-02 -1.0552008e+00  4.2869467e-03\n",
      "   -9.0854816e-02 -1.2163469e-01 -2.0922439e-01 -3.8900974e-01\n",
      "   -2.6276004e+00 -2.8298054e+00 -2.9159629e+00 -2.1510470e+00\n",
      "   -2.9399040e+00 -2.4244542e+00 -2.6570230e+00 -2.3765612e+00\n",
      "   -2.4598637e+00]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5772619e+00  6.8691463e+00  1.9073005e+00 -2.0447650e+00\n",
      "    1.6022784e+00  4.3809733e-01  3.2849610e-01 -1.5745039e+00\n",
      "   -8.9916229e-01 -1.5750252e+00 -1.7434797e+00  3.9065693e-02\n",
      "    1.8402284e-01  6.1036915e-02 -1.0554498e+00  4.7543216e-03\n",
      "   -9.0854257e-02 -1.2190296e-01 -2.0918344e-01 -3.8870746e-01\n",
      "   -2.6272621e+00 -2.8295238e+00 -2.9163597e+00 -2.1511335e+00\n",
      "   -2.9398284e+00 -2.4240875e+00 -2.6574390e+00 -2.3766446e+00\n",
      "   -2.4597600e+00]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5773029e+00  6.8692985e+00  1.9072788e+00 -2.0450957e+00\n",
      "    1.6032089e+00  4.3782765e-01  3.2867470e-01 -1.5740962e+00\n",
      "   -8.9891738e-01 -1.5753095e+00 -1.7437327e+00  3.9120656e-02\n",
      "    1.8425986e-01  6.1067522e-02 -1.0556725e+00  5.1737893e-03\n",
      "   -9.0853639e-02 -1.2214404e-01 -2.0914726e-01 -3.8843593e-01\n",
      "   -2.6269586e+00 -2.8292708e+00 -2.9167163e+00 -2.1512110e+00\n",
      "   -2.9397600e+00 -2.4237587e+00 -2.6578121e+00 -2.3767204e+00\n",
      "   -2.4596665e+00]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5773399e+00  6.8694363e+00  1.9072598e+00 -2.0453930e+00\n",
      "    1.6040447e+00  4.3758440e-01  3.2883471e-01 -1.5737282e+00\n",
      "   -8.9869696e-01 -1.5755657e+00 -1.7439601e+00  3.9169889e-02\n",
      "    1.8447241e-01  6.1094031e-02 -1.0558730e+00  5.5513699e-03\n",
      "   -9.0852693e-02 -1.2236175e-01 -2.0911507e-01 -3.8819188e-01\n",
      "   -2.6266847e+00 -2.8290429e+00 -2.9170372e+00 -2.1512806e+00\n",
      "   -2.9396994e+00 -2.4234633e+00 -2.6581481e+00 -2.3767886e+00\n",
      "   -2.4595833e+00]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5773723e+00  6.8695607e+00  1.9072442e+00 -2.0456603e+00\n",
      "    1.6047978e+00  4.3736464e-01  3.2897913e-01 -1.5733968e+00\n",
      "   -8.9849734e-01 -1.5757962e+00 -1.7441651e+00  3.9214235e-02\n",
      "    1.8466309e-01  6.1117038e-02 -1.0560538e+00  5.8925021e-03\n",
      "   -9.0851977e-02 -1.2255788e-01 -2.0908676e-01 -3.8797179e-01\n",
      "   -2.6264379e+00 -2.8288388e+00 -2.9173257e+00 -2.1513448e+00\n",
      "   -2.9396431e+00 -2.4231973e+00 -2.6584511e+00 -2.3768501e+00\n",
      "   -2.4595072e+00]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5774019e+00  6.8696718e+00  1.9072305e+00 -2.0459023e+00\n",
      "    1.6054780e+00  4.3716532e-01  3.2910922e-01 -1.5730963e+00\n",
      "   -8.9831650e-01 -1.5760044e+00 -1.7443491e+00  3.9254267e-02\n",
      "    1.8483397e-01  6.1137564e-02 -1.0562168e+00  6.2005538e-03\n",
      "   -9.0851329e-02 -1.2273575e-01 -2.0906170e-01 -3.8777331e-01\n",
      "   -2.6262157e+00 -2.8286533e+00 -2.9175878e+00 -2.1514030e+00\n",
      "   -2.9395919e+00 -2.4229560e+00 -2.6587245e+00 -2.3769054e+00\n",
      "   -2.4594395e+00]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5774288e+00  6.8697705e+00  1.9072195e+00 -2.0461209e+00\n",
      "    1.6060936e+00  4.3698454e-01  3.2922643e-01 -1.5728236e+00\n",
      "   -8.9815235e-01 -1.5761931e+00 -1.7445157e+00  3.9290134e-02\n",
      "    1.8498811e-01  6.1155424e-02 -1.0563641e+00  6.4794589e-03\n",
      "   -9.0851277e-02 -1.2289703e-01 -2.0903952e-01 -3.8759381e-01\n",
      "   -2.6260145e+00 -2.8284853e+00 -2.9178243e+00 -2.1514552e+00\n",
      "   -2.9395459e+00 -2.4227381e+00 -2.6589727e+00 -2.3769565e+00\n",
      "   -2.4593778e+00]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5774529e+00  6.8698611e+00  1.9072102e+00 -2.0463195e+00\n",
      "    1.6066514e+00  4.3682024e-01  3.2933265e-01 -1.5725768e+00\n",
      "   -8.9800292e-01 -1.5763632e+00 -1.7446657e+00  3.9322350e-02\n",
      "    1.8512693e-01  6.1171569e-02 -1.0564973e+00  6.7327116e-03\n",
      "   -9.0851270e-02 -1.2304345e-01 -2.0902000e-01 -3.8743109e-01\n",
      "   -2.6258318e+00 -2.8283334e+00 -2.9180388e+00 -2.1515028e+00\n",
      "   -2.9395037e+00 -2.4225416e+00 -2.6591983e+00 -2.3770020e+00\n",
      "   -2.4593229e+00]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577475    6.869945    1.907202   -2.0464997   1.6071589\n",
      "    0.43667054  0.32942918 -1.5723516  -0.89786714 -1.5765183\n",
      "   -1.7448022   0.03935182  0.18525243  0.06118562 -1.0566185\n",
      "    0.00696275 -0.09085143 -0.12317692 -0.20900257 -0.38728344\n",
      "   -2.6256654  -2.8281944  -2.9182339  -2.1515472  -2.939466\n",
      "   -2.4223623  -2.6594036  -2.3770435  -2.4592717 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5774946   6.87002     1.9071963  -2.0466638   1.6076204\n",
      "    0.43653405  0.32951656 -1.5721463  -0.89774317 -1.5766588\n",
      "   -1.7449253   0.03937813  0.18536577  0.06119832 -1.0567287\n",
      "    0.00717291 -0.09085215 -0.12329854 -0.2089871  -0.38714913\n",
      "   -2.6255145  -2.8280678  -2.9184113  -2.1515875  -2.9394293\n",
      "   -2.4221992  -2.6595914  -2.377081   -2.4592268 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5775132   6.8700852   1.9071918  -2.0468132   1.6080412\n",
      "    0.436409    0.3295961  -1.5719588  -0.89762974 -1.5767868\n",
      "   -1.745037    0.03940208  0.18546876  0.06120931 -1.0568285\n",
      "    0.00736457 -0.09085298 -0.12340982 -0.20897348 -0.38702703\n",
      "   -2.6253767  -2.8279524  -2.9185734  -2.1516242  -2.9393966\n",
      "   -2.4220512  -2.6597621  -2.377116   -2.4591866 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5775297   6.870147    1.907188   -2.0469496   1.6084255\n",
      "    0.43629503  0.32966852 -1.5717869  -0.897526   -1.5769033\n",
      "   -1.7451389   0.03942397  0.18556216  0.0612194  -1.05692\n",
      "    0.00754008 -0.09085408 -0.12351172 -0.20896156 -0.38691553\n",
      "   -2.6252513  -2.8278468  -2.9187222  -2.1516578  -2.9393663\n",
      "   -2.421915   -2.6599193  -2.3771467  -2.459149  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5775456   6.870202    1.9071851  -2.0470753   1.6087779\n",
      "    0.4361899   0.32973456 -1.5716296  -0.8974311  -1.57701\n",
      "   -1.7452317   0.03944387  0.18564707  0.06122853 -1.0570036\n",
      "    0.00770088 -0.09085529 -0.12360509 -0.20895071 -0.3868135\n",
      "   -2.6251352  -2.8277502  -2.9188576  -2.1516888  -2.9393396\n",
      "   -2.4217906  -2.6600633  -2.377176   -2.459115  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.57756     6.8702536   1.9071832  -2.0471892   1.6091003\n",
      "    0.43609375  0.32979536 -1.5714853  -0.8973437  -1.5771074\n",
      "   -1.7453164   0.03946188  0.18572444  0.06123696 -1.0570796\n",
      "    0.00784845 -0.09085675 -0.12369096 -0.20894133 -0.3867202\n",
      "   -2.62503    -2.827661   -2.9189823  -2.1517172  -2.939314\n",
      "   -2.4216776  -2.6601956  -2.377202   -2.4590845 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5775733   6.8702993   1.9071826  -2.0472949   1.6093969\n",
      "    0.43600506  0.32985038 -1.5713522  -0.8972632  -1.5771965\n",
      "   -1.7453936   0.03947815  0.18579474  0.06124392 -1.0571493\n",
      "    0.007984   -0.09085836 -0.12376998 -0.2089331  -0.38663468\n",
      "   -2.6249332  -2.8275797  -2.9190967  -2.1517441  -2.9392898\n",
      "   -2.4215734  -2.6603186  -2.3772256  -2.4590561 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5775847   6.870342    1.9071822  -2.0473917   1.6096696\n",
      "    0.43592352  0.32990134 -1.5712297  -0.89718914 -1.5772783\n",
      "   -1.7454644   0.03949336  0.18585935  0.06125084 -1.0572137\n",
      "    0.00810876 -0.09086017 -0.12384282 -0.2089255  -0.38655612\n",
      "   -2.6248438  -2.8275037  -2.9192011  -2.1517684  -2.9392676\n",
      "   -2.421477   -2.6604307  -2.3772473  -2.459031  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5775962   6.8703794   1.9071825  -2.0474806   1.609921\n",
      "    0.435848    0.32994798 -1.5711166  -0.8971205  -1.5773534\n",
      "   -1.7455288   0.03950692  0.18591839  0.06125705 -1.0572723\n",
      "    0.00822408 -0.09086224 -0.12391019 -0.20891906 -0.386484\n",
      "   -2.624762   -2.8274343  -2.919298   -2.151791   -2.9392467\n",
      "   -2.4213884  -2.6605344  -2.3772678  -2.4590075 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5776064   6.870417    1.9071832  -2.0475633   1.6101534\n",
      "    0.43577844  0.32999104 -1.5710119  -0.8970577  -1.5774223\n",
      "   -1.7455883   0.03951968  0.18597251  0.06126235 -1.0573264\n",
      "    0.00833064 -0.09086429 -0.12397228 -0.20891307 -0.3864176\n",
      "   -2.6246865  -2.82737    -2.919388   -2.1518116  -2.9392276\n",
      "   -2.4213073  -2.6606317  -2.3772862  -2.4589865 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5776162   6.870448    1.9071839  -2.0476396   1.6103678\n",
      "    0.43571404  0.33003026 -1.5709151  -0.89699936 -1.577486\n",
      "   -1.7456434   0.03953106  0.18602234  0.06126737 -1.0573767\n",
      "    0.00842923 -0.09086674 -0.12402993 -0.20890778 -0.38635632\n",
      "   -2.6246164  -2.8273103  -2.9194708  -2.1518312  -2.93921\n",
      "   -2.4212327  -2.6607206  -2.3773031  -2.4589674 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5776253   6.8704796   1.9071856  -2.0477097   1.6105661\n",
      "    0.43565416  0.33006707 -1.5708252  -0.8969452  -1.5775449\n",
      "   -1.7456933   0.03954174  0.18606782  0.06127191 -1.0574228\n",
      "    0.0085198  -0.09086853 -0.12408333 -0.20890324 -0.38629943\n",
      "   -2.624552   -2.8272552  -2.919547   -2.1518493  -2.939193\n",
      "   -2.4211626  -2.6608033  -2.3773189  -2.4589493 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-2.5776331   6.870507    1.9071872  -2.0477748   1.61075\n",
      "    0.4355988   0.33010074 -1.5707421  -0.89689493 -1.5775987\n",
      "   -1.7457396   0.03955138  0.18610999  0.06127588 -1.0574657\n",
      "    0.00860472 -0.09087085 -0.12413292 -0.20889919 -0.38624725\n",
      "   -2.624492   -2.8272033  -2.9196181  -2.151866   -2.939177\n",
      "   -2.4210975  -2.6608803  -2.3773339  -2.4589326 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577641    6.8705325   1.9071897  -2.0478358   1.6109209\n",
      "    0.43554717  0.33013195 -1.5706642  -0.89684826 -1.577649\n",
      "   -1.7457821   0.03956043  0.18614885  0.06127988 -1.0575051\n",
      "    0.00868328 -0.09087312 -0.12417893 -0.20889565 -0.38619864\n",
      "   -2.6244369  -2.8271558  -2.9196846  -2.1518815  -2.939163\n",
      "   -2.4210382  -2.6609528  -2.377347   -2.4589176 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5776486   6.870555    1.9071913  -2.0478919   1.6110795\n",
      "    0.43549913  0.330161   -1.5705922  -0.8968047  -1.5776957\n",
      "   -1.7458218   0.03956863  0.18618435  0.06128326 -1.0575418\n",
      "    0.00875658 -0.09087551 -0.12422179 -0.20889269 -0.38615382\n",
      "   -2.6243846  -2.8271117  -2.9197454  -2.151896   -2.9391491\n",
      "   -2.4209824  -2.6610188  -2.37736    -2.4589038 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5776556   6.870578    1.9071938  -2.0479448   1.6112269\n",
      "    0.43545455  0.33018753 -1.570525   -0.89676434 -1.5777388\n",
      "   -1.7458584   0.03957611  0.18621758  0.06128698 -1.0575758\n",
      "    0.00882461 -0.0908775  -0.12426169 -0.20888959 -0.38611194\n",
      "   -2.624337   -2.827071   -2.9198024  -2.1519096  -2.939137\n",
      "   -2.4209306  -2.6610813  -2.3773713  -2.4588907 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577662    6.8705964   1.9071964  -2.047993    1.6113646\n",
      "    0.43541303  0.33021247 -1.5704627  -0.8967266  -1.5777785\n",
      "   -1.7458917   0.03958337  0.18624842  0.06128966 -1.0576075\n",
      "    0.00888785 -0.09088004 -0.12429915 -0.20888717 -0.3860732\n",
      "   -2.6242924  -2.8270316  -2.9198558  -2.1519225  -2.939125\n",
      "   -2.420883   -2.6611402  -2.377382   -2.4588792 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5776677   6.8706155   1.9071985  -2.0480385   1.6114932\n",
      "    0.43537402  0.3302357  -1.5704039  -0.8966914  -1.5778157\n",
      "   -1.7459233   0.03958983  0.18627673  0.06129209 -1.0576365\n",
      "    0.00894707 -0.09088228 -0.12433405 -0.20888476 -0.38603702\n",
      "   -2.6242504  -2.8269966  -2.9199052  -2.151934   -2.9391136\n",
      "   -2.4208388  -2.6611948  -2.3773923  -2.4588687 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5776734   6.8706326   1.9072014  -2.0480812   1.6116134\n",
      "    0.4353377   0.3302571  -1.5703489  -0.8966586  -1.5778502\n",
      "   -1.7459528   0.03959594  0.1863032   0.06129468 -1.057664\n",
      "    0.00900267 -0.09088466 -0.12436672 -0.20888282 -0.38600346\n",
      "   -2.6242118  -2.826962   -2.9199517  -2.1519454  -2.9391036\n",
      "   -2.4207964  -2.6612463  -2.3774009  -2.4588583 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5776787   6.870649    1.907204   -2.048121    1.6117257\n",
      "    0.43530363  0.33027738 -1.5702976  -0.89662766 -1.5778826\n",
      "   -1.7459797   0.03960137  0.18632796  0.06129731 -1.0576895\n",
      "    0.00905449 -0.09088661 -0.12439722 -0.2088811  -0.38597193\n",
      "   -2.6241758  -2.8269305  -2.9199948  -2.151956   -2.9390936\n",
      "   -2.4207568  -2.661294   -2.37741    -2.4588494 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5776832   6.870664    1.9072064  -2.048158    1.6118305\n",
      "    0.43527174  0.330296   -1.5702496  -0.8965989  -1.577913\n",
      "   -1.746005    0.0396067   0.18635091  0.06129972 -1.0577134\n",
      "    0.00910285 -0.09088894 -0.12442592 -0.20887937 -0.38594258\n",
      "   -2.6241412  -2.8269005  -2.9200358  -2.1519651  -2.9390838\n",
      "   -2.4207206  -2.661338   -2.3774178  -2.4588397 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5776885   6.8706775   1.9072092  -2.0481932   1.6119292\n",
      "    0.4352421   0.33031347 -1.5702041  -0.89657176 -1.5779406\n",
      "   -1.7460288   0.03961147  0.18637234  0.0613015  -1.0577358\n",
      "    0.00914833 -0.09089107 -0.12445262 -0.20887789 -0.38591513\n",
      "   -2.6241102  -2.8268728  -2.9200735  -2.1519747  -2.939075\n",
      "   -2.420686   -2.6613812  -2.377426   -2.4588318 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5776927   6.8706913   1.9072118  -2.0482256   1.6120214\n",
      "    0.43521398  0.33032978 -1.570162   -0.89654636 -1.5779668\n",
      "   -1.7460505   0.03961593  0.18639201  0.06130313 -1.0577567\n",
      "    0.00919135 -0.09089326 -0.12447794 -0.20887671 -0.38588947\n",
      "   -2.6240795  -2.8268473  -2.9201088  -2.1519833  -2.9390671\n",
      "   -2.4206548  -2.6614206  -2.3774326  -2.458825  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577697    6.8707027   1.9072148  -2.048257    1.6121082\n",
      "    0.43518737  0.33034515 -1.5701221  -0.8965224  -1.5779915\n",
      "   -1.7460707   0.03962009  0.18641064  0.0613051  -1.057776\n",
      "    0.00923118 -0.09089525 -0.12450163 -0.20887564 -0.3858655\n",
      "   -2.6240518  -2.8268216  -2.9201427  -2.1519914  -2.9390585\n",
      "   -2.420625   -2.6614585  -2.3774395  -2.4588177 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777004   6.8707137   1.9072171  -2.0482857   1.6121893\n",
      "    0.4351624   0.33035958 -1.5700849  -0.89650005 -1.5780145\n",
      "   -1.7460902   0.03962394  0.18642804  0.06130689 -1.0577947\n",
      "    0.00926875 -0.09089703 -0.12452409 -0.20887473 -0.3858427\n",
      "   -2.6240253  -2.8267994  -2.9201744  -2.151999   -2.939052\n",
      "   -2.4205956  -2.6614933  -2.3774455  -2.4588118 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577704    6.870725    1.9072196  -2.0483131   1.6122662\n",
      "    0.4351394   0.33037296 -1.5700496  -0.89647925 -1.5780362\n",
      "   -1.7461083   0.03962769  0.1864444   0.06130802 -1.0578116\n",
      "    0.00930429 -0.09089913 -0.12454508 -0.20887361 -0.38582167\n",
      "   -2.6240008  -2.826778   -2.9202044  -2.1520061  -2.9390447\n",
      "   -2.42057    -2.6615264  -2.3774514  -2.458805  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777082   6.870734    1.9072222  -2.0483384   1.6123384\n",
      "    0.43511724  0.3303857  -1.5700161  -0.8964592  -1.5780565\n",
      "   -1.7461253   0.03963108  0.18645957  0.06130965 -1.0578276\n",
      "    0.00933745 -0.09090079 -0.12456493 -0.20887296 -0.3858015\n",
      "   -2.6239774  -2.8267577  -2.9202318  -2.152013   -2.9390378\n",
      "   -2.4205446  -2.661558   -2.3774571  -2.4587996 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577711    6.870743    1.9072247  -2.0483618   1.6124063\n",
      "    0.43509656  0.33039778 -1.5699848  -0.89644015 -1.5780752\n",
      "   -1.746141    0.03963431  0.18647414  0.06131089 -1.0578431\n",
      "    0.00936902 -0.09090273 -0.12458356 -0.20887221 -0.38578284\n",
      "   -2.6239555  -2.8267384  -2.920258   -2.1520195  -2.9390316\n",
      "   -2.420521   -2.661587   -2.3774621  -2.4587946 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777142   6.870752    1.9072272  -2.0483851   1.6124705\n",
      "    0.43507677  0.3304088  -1.5699551  -0.8964226  -1.5780934\n",
      "   -1.7461555   0.03963726  0.18648744  0.06131216 -1.0578572\n",
      "    0.00939878 -0.09090447 -0.12460122 -0.20887172 -0.38576522\n",
      "   -2.6239347  -2.8267207  -2.920283   -2.1520257  -2.939026\n",
      "   -2.4204988  -2.6616151  -2.3774672  -2.4587903 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577717    6.87076     1.9072295  -2.0484068   1.612531\n",
      "    0.4350583   0.33041948 -1.5699271  -0.8964056  -1.5781105\n",
      "   -1.7461698   0.03964001  0.18650007  0.06131327 -1.0578706\n",
      "    0.00942704 -0.09090605 -0.12461782 -0.20887108 -0.38574854\n",
      "   -2.6239154  -2.8267028  -2.9203064  -2.152031   -2.9390206\n",
      "   -2.420478   -2.661642   -2.3774722  -2.4587846 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777202   6.870767    1.9072319  -2.0484273   1.6125884\n",
      "    0.4350409   0.33042946 -1.5699005  -0.8963898  -1.5781263\n",
      "   -1.7461827   0.03964263  0.18651208  0.06131437 -1.0578834\n",
      "    0.00945348 -0.0909078  -0.12463367 -0.20887046 -0.38573274\n",
      "   -2.6238968  -2.8266866  -2.9203284  -2.1520367  -2.9390152\n",
      "   -2.4204586  -2.661667   -2.3774765  -2.458781  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777225   6.8707724   1.9072338  -2.0484462   1.6126422\n",
      "    0.43502447  0.33043867 -1.5698754  -0.8963748  -1.5781412\n",
      "   -1.7461952   0.03964501  0.18652329  0.06131557 -1.0578955\n",
      "    0.00947833 -0.09090951 -0.12464859 -0.20887017 -0.38571793\n",
      "   -2.6238794  -2.8266704  -2.9203498  -2.152042   -2.9390101\n",
      "   -2.4204395  -2.6616905  -2.3774803  -2.4587765 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777252   6.8707805   1.9072362  -2.0484648   1.6126938\n",
      "    0.43500882  0.3304476  -1.5698518  -0.8963609  -1.578155\n",
      "   -1.7462068   0.03964749  0.18653396  0.06131613 -1.0579069\n",
      "    0.00950254 -0.09091093 -0.12466279 -0.20886971 -0.38570392\n",
      "   -2.623863   -2.8266559  -2.9203703  -2.152047   -2.9390063\n",
      "   -2.4204223  -2.6617134  -2.3774843  -2.4587731 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777276   6.870787    1.9072386  -2.0484817   1.6127423\n",
      "    0.43499386  0.33045602 -1.5698296  -0.8963474  -1.5781687\n",
      "   -1.7462178   0.03964951  0.18654397  0.06131718 -1.0579175\n",
      "    0.00952468 -0.09091244 -0.12467626 -0.20886932 -0.38569066\n",
      "   -2.6238472  -2.8266425  -2.9203885  -2.1520512  -2.939001\n",
      "   -2.4204054  -2.661734   -2.3774881  -2.458769  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777302   6.870794    1.9072409  -2.0484982   1.6127881\n",
      "    0.43497986  0.3304638  -1.5698079  -0.89633447 -1.5781814\n",
      "   -1.7462283   0.0396516   0.18655324  0.06131805 -1.0579277\n",
      "    0.00954619 -0.0909141  -0.12468904 -0.20886923 -0.3856781\n",
      "   -2.6238327  -2.8266294  -2.9204054  -2.1520555  -2.9389968\n",
      "   -2.4203887  -2.6617546  -2.3774908  -2.4587653 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777318   6.8707995   1.9072424  -2.048514    1.612832\n",
      "    0.43496618  0.3304713  -1.5697874  -0.8963228  -1.5781934\n",
      "   -1.746238    0.03965357  0.18656233  0.06131897 -1.0579375\n",
      "    0.00956632 -0.09091542 -0.12470119 -0.20886894 -0.3856665\n",
      "   -2.6238189  -2.826617   -2.9204233  -2.1520596  -2.9389923\n",
      "   -2.4203746  -2.6617737  -2.3774943  -2.4587622 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777342   6.8708034   1.9072448  -2.0485287   1.6128731\n",
      "    0.43495372  0.33047846 -1.5697681  -0.896311   -1.5782049\n",
      "   -1.7462476   0.03965546  0.18657064  0.06131962 -1.0579467\n",
      "    0.00958549 -0.09091677 -0.1247125  -0.20886849 -0.38565513\n",
      "   -2.6238048  -2.8266056  -2.920439   -2.1520634  -2.9389892\n",
      "   -2.4203606  -2.661792   -2.3774977  -2.4587593 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777364   6.8708076   1.9072466  -2.0485423   1.6129128\n",
      "    0.43494156  0.33048505 -1.56975    -0.8963003  -1.5782156\n",
      "   -1.7462562   0.03965719  0.18657878  0.0613204  -1.057955\n",
      "    0.00960355 -0.09091794 -0.12472342 -0.20886834 -0.38564444\n",
      "   -2.623793   -2.826594   -2.9204545  -2.1520677  -2.9389853\n",
      "   -2.4203467  -2.6618094  -2.3775008  -2.458757  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777376   6.8708134   1.9072487  -2.0485556   1.6129498\n",
      "    0.43493018  0.3304915  -1.5697324  -0.89629    -1.5782256\n",
      "   -1.7462648   0.03965865  0.18658629  0.06132096 -1.0579633\n",
      "    0.00962095 -0.09091914 -0.12473392 -0.2088681  -0.3856343\n",
      "   -2.623781   -2.8265831  -2.9204693  -2.1520708  -2.9389815\n",
      "   -2.4203343  -2.6618257  -2.3775034  -2.4587536 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777395   6.8708177   1.9072502  -2.0485685   1.6129854\n",
      "    0.43491936  0.3304977  -1.5697162  -0.89628    -1.5782354\n",
      "   -1.7462729   0.03966023  0.18659371  0.06132188 -1.057971\n",
      "    0.00963742 -0.09092028 -0.12474349 -0.20886807 -0.3856248\n",
      "   -2.6237693  -2.8265731  -2.9204824  -2.1520746  -2.9389782\n",
      "   -2.4203222  -2.6618414  -2.3775058  -2.4587514 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777404   6.870822    1.9072518  -2.0485802   1.6130188\n",
      "    0.43490896  0.33050328 -1.5697004  -0.8962707  -1.5782447\n",
      "   -1.7462802   0.03966171  0.18660024  0.06132236 -1.0579785\n",
      "    0.00965314 -0.09092152 -0.1247531  -0.20886783 -0.38561538\n",
      "   -2.6237586  -2.8265643  -2.9204957  -2.1520774  -2.9389756\n",
      "   -2.4203098  -2.6618564  -2.3775082  -2.458749  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777426   6.8708253   1.9072533  -2.0485914   1.6130509\n",
      "    0.43489903  0.33050868 -1.5696853  -0.8962617  -1.578253\n",
      "   -1.7462872   0.03966286  0.18660673  0.06132305 -1.0579853\n",
      "    0.00966773 -0.09092264 -0.12476186 -0.20886771 -0.3856069\n",
      "   -2.6237478  -2.8265555  -2.9205081  -2.1520803  -2.9389727\n",
      "   -2.4202993  -2.6618702  -2.377511   -2.4587467 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-2.5777445   6.870831    1.9072552  -2.0486026   1.6130816\n",
      "    0.4348896   0.3305139  -1.5696714  -0.8962531  -1.5782615\n",
      "   -1.746294    0.03966455  0.18661278  0.0613231  -1.057992\n",
      "    0.00968225 -0.09092385 -0.1247704  -0.20886765 -0.3855986\n",
      "   -2.6237385  -2.8265455  -2.92052    -2.1520836  -2.9389694\n",
      "   -2.4202888  -2.6618845  -2.3775134  -2.4587445 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777454   6.8708344   1.9072567  -2.0486126   1.6131109\n",
      "    0.43488055  0.33051908 -1.5696574  -0.89624506 -1.5782694\n",
      "   -1.7463007   0.03966555  0.18661878  0.06132375 -1.0579987\n",
      "    0.00969568 -0.09092477 -0.12477855 -0.2088676  -0.38559058\n",
      "   -2.6237292  -2.8265376  -2.9205313  -2.1520863  -2.9389658\n",
      "   -2.4202785  -2.661897   -2.3775153  -2.4587426 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577747    6.870836    1.907258   -2.0486226   1.6131386\n",
      "    0.43487224  0.33052346 -1.5696446  -0.89623743 -1.5782772\n",
      "   -1.7463067   0.03966676  0.18662426  0.06132457 -1.0580044\n",
      "    0.00970836 -0.09092566 -0.12478632 -0.2088673  -0.38558304\n",
      "   -2.6237202  -2.826529   -2.9205422  -2.152089   -2.9389634\n",
      "   -2.4202702  -2.6619093  -2.3775172  -2.4587407 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777488   6.8708386   1.9072593  -2.0486324   1.6131651\n",
      "    0.43486425  0.33052808 -1.5696323  -0.89622974 -1.5782841\n",
      "   -1.7463123   0.03966786  0.1866296   0.06132456 -1.0580102\n",
      "    0.00972101 -0.09092665 -0.12479383 -0.20886736 -0.3855761\n",
      "   -2.623712   -2.8265212  -2.9205527  -2.152092   -2.9389613\n",
      "   -2.420261   -2.661921   -2.3775198  -2.4587388 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777502   6.8708434   1.9072614  -2.0486414   1.6131907\n",
      "    0.43485618  0.33053252 -1.5696205  -0.8962228  -1.5782909\n",
      "   -1.7463182   0.03966896  0.18663457  0.06132537 -1.0580158\n",
      "    0.00973249 -0.09092762 -0.12480068 -0.20886733 -0.3855694\n",
      "   -2.6237037  -2.8265145  -2.9205623  -2.1520941  -2.9389591\n",
      "   -2.4202516  -2.661933   -2.377522   -2.458737  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777514   6.870848    1.9072627  -2.0486498   1.6132146\n",
      "    0.43484882  0.3305363  -1.5696088  -0.896216   -1.5782975\n",
      "   -1.746323    0.03966998  0.1866391   0.06132552 -1.0580208\n",
      "    0.00974383 -0.09092844 -0.12480743 -0.20886712 -0.3855628\n",
      "   -2.6236956  -2.8265069  -2.9205723  -2.152096   -2.9389565\n",
      "   -2.4202437  -2.6619434  -2.3775234  -2.4587352 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777526   6.8708506   1.9072639  -2.0486581   1.6132373\n",
      "    0.43484172  0.33054024 -1.5695986  -0.8962097  -1.5783035\n",
      "   -1.746328    0.03967092  0.18664387  0.06132595 -1.058026\n",
      "    0.00975435 -0.09092931 -0.12481388 -0.20886733 -0.38555652\n",
      "   -2.623688   -2.826501   -2.9205806  -2.152099   -2.9389544\n",
      "   -2.4202354  -2.661954   -2.377525   -2.4587336 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777533   6.8708534   1.9072653  -2.0486658   1.6132596\n",
      "    0.4348349   0.33054408 -1.5695881  -0.8962036  -1.5783098\n",
      "   -1.7463328   0.03967172  0.18664816  0.06132647 -1.0580311\n",
      "    0.0097644  -0.0909301  -0.12482002 -0.20886728 -0.38555053\n",
      "   -2.6236813  -2.8264945  -2.9205894  -2.1521006  -2.9389517\n",
      "   -2.420228   -2.661963   -2.3775263  -2.4587324 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777547   6.8708553   1.9072663  -2.0486732   1.6132807\n",
      "    0.43482846  0.33054757 -1.5695782  -0.8961977  -1.578315\n",
      "   -1.7463375   0.03967271  0.18665242  0.06132673 -1.058035\n",
      "    0.0097744  -0.09093081 -0.12482592 -0.20886724 -0.3855448\n",
      "   -2.6236746  -2.8264885  -2.9205973  -2.1521027  -2.9389498\n",
      "   -2.4202213  -2.661973   -2.3775282  -2.4587302 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777557   6.870858    1.9072672  -2.04868     1.6133009\n",
      "    0.4348222   0.33055094 -1.5695685  -0.8961921  -1.5783206\n",
      "   -1.746342    0.0396736   0.1866565   0.06132691 -1.0580397\n",
      "    0.0097838  -0.0909318  -0.12483171 -0.2088672  -0.38553962\n",
      "   -2.6236684  -2.8264828  -2.920606   -2.1521046  -2.9389482\n",
      "   -2.4202142  -2.6619818  -2.3775299  -2.458729  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777564   6.870859    1.9072689  -2.0486875   1.6133199\n",
      "    0.43481636  0.33055392 -1.5695596  -0.89618665 -1.5783256\n",
      "   -1.7463459   0.0396741   0.18666008  0.06132752 -1.0580438\n",
      "    0.00979249 -0.0909323  -0.12483712 -0.20886728 -0.38553426\n",
      "   -2.6236622  -2.8264773  -2.9206126  -2.1521065  -2.938946\n",
      "   -2.4202077  -2.661991   -2.3775308  -2.4587283 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777576   6.8708625   1.9072697  -2.0486941   1.6133384\n",
      "    0.4348107   0.33055723 -1.5695509  -0.8961816  -1.5783308\n",
      "   -1.7463502   0.03967504  0.18666363  0.0613279  -1.058048\n",
      "    0.0098014  -0.09093316 -0.12484203 -0.20886712 -0.3855293\n",
      "   -2.623656   -2.8264713  -2.9206197  -2.1521084  -2.9389453\n",
      "   -2.4202015  -2.6619987  -2.3775325  -2.4587264 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577758    6.8708625   1.9072707  -2.0487003   1.613356\n",
      "    0.4348051   0.33056003 -1.5695426  -0.8961766  -1.5783354\n",
      "   -1.7463542   0.03967596  0.18666723  0.06132795 -1.0580516\n",
      "    0.00980957 -0.09093375 -0.12484714 -0.2088673  -0.3855246\n",
      "   -2.6236508  -2.8264668  -2.9206269  -2.15211    -2.9389422\n",
      "   -2.4201944  -2.6620064  -2.377534   -2.4587252 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777588   6.870868    1.9072716  -2.048706    1.6133729\n",
      "    0.4347999   0.33056268 -1.5695344  -0.8961718  -1.5783402\n",
      "   -1.7463573   0.03967649  0.18667045  0.06132812 -1.0580553\n",
      "    0.00981745 -0.09093446 -0.12485191 -0.20886731 -0.38552013\n",
      "   -2.6236448  -2.8264618  -2.9206338  -2.1521113  -2.938941\n",
      "   -2.4201894  -2.6620138  -2.377535   -2.458724  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.57776     6.870869    1.9072726  -2.0487118   1.6133891\n",
      "    0.4347949   0.33056545 -1.5695273  -0.89616704 -1.5783447\n",
      "   -1.7463607   0.03967713  0.18667376  0.06132825 -1.0580587\n",
      "    0.00982472 -0.09093505 -0.12485646 -0.20886715 -0.3855158\n",
      "   -2.6236398  -2.8264573  -2.9206395  -2.1521127  -2.938939\n",
      "   -2.4201834  -2.662021   -2.377536   -2.4587228 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777612   6.8708706   1.907274   -2.0487175   1.6134045\n",
      "    0.43479005  0.33056825 -1.5695198  -0.896163   -1.5783484\n",
      "   -1.7463642   0.03967773  0.18667677  0.0613286  -1.0580621\n",
      "    0.00983188 -0.09093571 -0.1248607  -0.20886715 -0.3855118\n",
      "   -2.6236348  -2.8264527  -2.9206452  -2.1521146  -2.9389377\n",
      "   -2.4201791  -2.6620283  -2.377537   -2.4587224 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777614   6.8708715   1.9072746  -2.0487227   1.6134195\n",
      "    0.43478543  0.33057058 -1.5695128  -0.89615893 -1.5783523\n",
      "   -1.7463676   0.03967835  0.18667966  0.06132908 -1.0580657\n",
      "    0.00983875 -0.09093626 -0.12486488 -0.20886725 -0.38550773\n",
      "   -2.6236303  -2.8264484  -2.9206517  -2.152116   -2.9389362\n",
      "   -2.4201741  -2.6620352  -2.3775392  -2.4587212 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577762    6.870874    1.907276   -2.048728    1.6134338\n",
      "    0.43478113  0.33057314 -1.569506   -0.8961549  -1.5783561\n",
      "   -1.7463703   0.03967908  0.18668246  0.06132921 -1.0580686\n",
      "    0.0098457  -0.09093688 -0.12486874 -0.2088671  -0.3855038\n",
      "   -2.623626   -2.826444   -2.9206572  -2.1521175  -2.9389346\n",
      "   -2.4201686  -2.6620424  -2.3775396  -2.4587204 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777624   6.870875    1.9072769  -2.0487328   1.6134472\n",
      "    0.43477708  0.33057535 -1.5694999  -0.896151   -1.5783598\n",
      "   -1.7463733   0.03967959  0.1866852   0.06132932 -1.0580715\n",
      "    0.00985179 -0.0909375  -0.12487283 -0.2088673  -0.3855004\n",
      "   -2.6236215  -2.82644    -2.9206622  -2.1521192  -2.9389336\n",
      "   -2.4201636  -2.6620483  -2.37754    -2.45872   ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777636   6.870877    1.907277   -2.0487375   1.6134604\n",
      "    0.43477285  0.33057758 -1.5694938  -0.89614725 -1.5783633\n",
      "   -1.7463763   0.03967993  0.18668777  0.06132951 -1.0580741\n",
      "    0.00985803 -0.09093804 -0.12487648 -0.20886733 -0.38549665\n",
      "   -2.6236172  -2.8264368  -2.9206672  -2.15212    -2.938933\n",
      "   -2.42016    -2.6620538  -2.3775415  -2.4587183 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777643   6.8708773   1.9072784  -2.0487418   1.613473\n",
      "    0.43476894  0.33057982 -1.5694877  -0.8961438  -1.5783666\n",
      "   -1.746379    0.03968043  0.18669027  0.06132969 -1.0580769\n",
      "    0.00986365 -0.09093858 -0.12488006 -0.20886733 -0.38549337\n",
      "   -2.6236129  -2.8264325  -2.9206727  -2.1521215  -2.9389303\n",
      "   -2.4201553  -2.662059   -2.3775425  -2.4587178 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577765    6.870879    1.9072788  -2.0487466   1.613485\n",
      "    0.4347652   0.33058184 -1.569482   -0.8961402  -1.5783699\n",
      "   -1.7463816   0.03968083  0.18669254  0.06133    -1.0580794\n",
      "    0.00986938 -0.09093909 -0.12488349 -0.20886725 -0.38549024\n",
      "   -2.623609   -2.8264296  -2.9206767  -2.1521227  -2.93893\n",
      "   -2.420151   -2.6620643  -2.377544   -2.4587166 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577765    6.8708797   1.9072802  -2.0487504   1.6134968\n",
      "    0.43476158  0.33058345 -1.5694768  -0.8961368  -1.5783726\n",
      "   -1.7463838   0.03968131  0.18669477  0.06133008 -1.058082\n",
      "    0.00987473 -0.09093943 -0.12488669 -0.2088674  -0.38548717\n",
      "   -2.6236053  -2.8264263  -2.9206817  -2.1521235  -2.938929\n",
      "   -2.4201477  -2.66207    -2.3775444  -2.4587164 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577766    6.8708825   1.9072808  -2.0487545   1.6135081\n",
      "    0.43475813  0.33058554 -1.569471   -0.896134   -1.5783758\n",
      "   -1.7463866   0.0396819   0.186697    0.06133027 -1.0580848\n",
      "    0.00988012 -0.09094001 -0.12488984 -0.20886727 -0.385484\n",
      "   -2.623602   -2.8264234  -2.9206858  -2.152125   -2.9389272\n",
      "   -2.4201427  -2.6620753  -2.3775454  -2.4587152 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577767    6.8708844   1.9072809  -2.0487578   1.613519\n",
      "    0.43475473  0.33058736 -1.5694661  -0.8961309  -1.5783786\n",
      "   -1.7463887   0.03968214  0.18669894  0.06133053 -1.0580866\n",
      "    0.00988511 -0.09094023 -0.12489283 -0.20886737 -0.38548115\n",
      "   -2.6235983  -2.8264203  -2.92069    -2.1521258  -2.9389267\n",
      "   -2.4201398  -2.66208    -2.3775458  -2.4587145 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777671   6.870885    1.9072814  -2.048762    1.6135291\n",
      "    0.4347515   0.330589   -1.5694611  -0.8961282  -1.5783818\n",
      "   -1.7463909   0.03968274  0.18670112  0.06133077 -1.0580889\n",
      "    0.00988998 -0.09094069 -0.12489577 -0.20886742 -0.38547853\n",
      "   -2.6235948  -2.826417   -2.920694   -2.152127   -2.9389262\n",
      "   -2.4201357  -2.6620848  -2.3775473  -2.4587135 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777674   6.870887    1.9072825  -2.0487652   1.6135391\n",
      "    0.43474862  0.33059052 -1.5694569  -0.89612526 -1.5783839\n",
      "   -1.746393    0.03968305  0.1867029   0.06133089 -1.0580909\n",
      "    0.00989453 -0.0909413  -0.1248987  -0.20886737 -0.38547578\n",
      "   -2.6235924  -2.826414   -2.9206984  -2.1521275  -2.938925\n",
      "   -2.420132   -2.6620889  -2.377548   -2.4587138 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777678   6.8708878   1.9072834  -2.0487688   1.6135486\n",
      "    0.43474546  0.3305923  -1.5694523  -0.89612275 -1.5783869\n",
      "   -1.746395    0.03968352  0.18670478  0.06133083 -1.058093\n",
      "    0.00989907 -0.09094159 -0.12490128 -0.2088673  -0.38547313\n",
      "   -2.6235888  -2.8264115  -2.9207015  -2.1521285  -2.9389234\n",
      "   -2.4201293  -2.6620934  -2.377548   -2.4587123 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777683   6.8708887   1.9072835  -2.0487719   1.6135577\n",
      "    0.43474287  0.33059353 -1.569448   -0.89612013 -1.5783888\n",
      "   -1.746397    0.03968391  0.18670651  0.06133123 -1.058095\n",
      "    0.00990334 -0.09094185 -0.12490381 -0.2088673  -0.38547084\n",
      "   -2.6235855  -2.8264089  -2.920705   -2.1521294  -2.9389224\n",
      "   -2.4201262  -2.662098   -2.3775487  -2.458712  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777688   6.8708897   1.9072841  -2.048775    1.6135669\n",
      "    0.43474013  0.33059514 -1.5694436  -0.8961176  -1.5783911\n",
      "   -1.7463989   0.03968408  0.18670824  0.06133136 -1.058097\n",
      "    0.00990761 -0.09094221 -0.12490626 -0.20886736 -0.38546842\n",
      "   -2.6235828  -2.8264072  -2.9207087  -2.1521301  -2.9389224\n",
      "   -2.420123   -2.6621013  -2.3775492  -2.458712  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777693   6.8708897   1.9072851  -2.0487783   1.6135751\n",
      "    0.43473747  0.33059654 -1.5694398  -0.8961152  -1.5783936\n",
      "   -1.7464005   0.03968445  0.18670985  0.06133131 -1.0580988\n",
      "    0.00991105 -0.09094264 -0.1249088  -0.2088675  -0.38546613\n",
      "   -2.6235805  -2.826404   -2.920712   -2.152131   -2.9389207\n",
      "   -2.4201207  -2.6621048  -2.3775504  -2.4587114 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-2.57777     6.87089     1.9072857  -2.0487812   1.613583\n",
      "    0.43473482  0.3305978  -1.5694363  -0.8961128  -1.5783958\n",
      "   -1.7464023   0.03968464  0.18671131  0.06133126 -1.0581003\n",
      "    0.00991503 -0.09094304 -0.12491091 -0.2088676  -0.38546413\n",
      "   -2.623578   -2.8264017  -2.9207158  -2.152132   -2.9389193\n",
      "   -2.4201179  -2.6621094  -2.377551   -2.4587104 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777705   6.870891    1.907286   -2.0487843   1.6135912\n",
      "    0.43473235  0.33059937 -1.5694321  -0.8961107  -1.5783981\n",
      "   -1.746404    0.03968523  0.18671304  0.06133151 -1.0581021\n",
      "    0.00991882 -0.09094337 -0.1249132  -0.20886734 -0.38546205\n",
      "   -2.6235757  -2.8263988  -2.9207177  -2.1521327  -2.9389193\n",
      "   -2.4201152  -2.6621125  -2.3775508  -2.4587097 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577771    6.8708925   1.9072865  -2.0487866   1.613599\n",
      "    0.4347301   0.33060065 -1.5694283  -0.8961086  -1.5783998\n",
      "   -1.7464056   0.03968548  0.18671441  0.06133153 -1.0581039\n",
      "    0.00992207 -0.09094387 -0.12491541 -0.20886756 -0.38546005\n",
      "   -2.623573   -2.8263965  -2.9207213  -2.1521335  -2.9389186\n",
      "   -2.420113   -2.6621158  -2.377552   -2.4587092 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777705   6.8708935   1.9072871  -2.048789    1.613606\n",
      "    0.4347278   0.33060166 -1.5694247  -0.89610654 -1.5784017\n",
      "   -1.746407    0.03968579  0.18671587  0.06133177 -1.0581051\n",
      "    0.00992568 -0.09094372 -0.12491721 -0.20886733 -0.38545787\n",
      "   -2.6235707  -2.8263946  -2.920724   -2.1521344  -2.938918\n",
      "   -2.4201097  -2.6621196  -2.3775523  -2.458709  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777712   6.870894    1.9072876  -2.048792    1.6136131\n",
      "    0.43472558  0.33060282 -1.5694218  -0.8961044  -1.5784037\n",
      "   -1.7464086   0.03968599  0.18671703  0.061332   -1.0581063\n",
      "    0.00992889 -0.09094415 -0.12491925 -0.20886748 -0.38545597\n",
      "   -2.6235683  -2.826393   -2.9207265  -2.1521351  -2.9389179\n",
      "   -2.4201074  -2.6621227  -2.377553   -2.4587085 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577772    6.8708954   1.907288   -2.048794    1.6136198\n",
      "    0.43472368  0.33060402 -1.5694187  -0.89610255 -1.5784053\n",
      "   -1.7464104   0.03968611  0.1867185   0.061332   -1.0581081\n",
      "    0.00993223 -0.09094446 -0.12492117 -0.20886748 -0.38545436\n",
      "   -2.6235662  -2.826391   -2.9207294  -2.1521356  -2.9389167\n",
      "   -2.4201052  -2.662126   -2.3775535  -2.458708  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577772    6.8708963   1.9072882  -2.0487967   1.6136262\n",
      "    0.43472156  0.33060503 -1.5694152  -0.89610094 -1.5784073\n",
      "   -1.7464118   0.03968639  0.18671975  0.06133185 -1.0581095\n",
      "    0.00993514 -0.09094474 -0.12492301 -0.2088675  -0.38545254\n",
      "   -2.623564   -2.826389   -2.9207315  -2.1521363  -2.9389162\n",
      "   -2.4201028  -2.6621282  -2.3775544  -2.458707  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777726   6.8708963   1.9072886  -2.0487988   1.6136328\n",
      "    0.43471944  0.330606   -1.5694125  -0.89609915 -1.578409\n",
      "   -1.7464128   0.03968666  0.18672088  0.06133198 -1.0581108\n",
      "    0.00993807 -0.09094505 -0.1249249  -0.20886752 -0.3854508\n",
      "   -2.6235623  -2.826387   -2.9207344  -2.1521368  -2.9389155\n",
      "   -2.4201002  -2.6621315  -2.3775547  -2.4587064 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777729   6.8708973   1.9072891  -2.0488012   1.6136388\n",
      "    0.43471757  0.33060703 -1.5694094  -0.89609706 -1.5784107\n",
      "   -1.7464141   0.03968687  0.18672207  0.06133183 -1.0581123\n",
      "    0.0099409  -0.09094521 -0.12492666 -0.20886753 -0.38544947\n",
      "   -2.6235602  -2.826386   -2.920736   -2.1521373  -2.9389148\n",
      "   -2.4200985  -2.6621337  -2.3775551  -2.4587066 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777733   6.870898    1.9072895  -2.048803    1.6136448\n",
      "    0.43471575  0.33060792 -1.5694067  -0.8960957  -1.578412\n",
      "   -1.7464154   0.03968721  0.18672323  0.06133235 -1.0581131\n",
      "    0.0099434  -0.09094569 -0.12492836 -0.20886756 -0.38544795\n",
      "   -2.6235585  -2.8263838  -2.9207387  -2.152138   -2.9389143\n",
      "   -2.4200964  -2.6621366  -2.3775556  -2.4587069 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777733   6.870898    1.9072896  -2.0488045   1.6136506\n",
      "    0.434714    0.33060873 -1.5694042  -0.89609396 -1.5784136\n",
      "   -1.7464163   0.03968737  0.1867241   0.06133233 -1.0581146\n",
      "    0.00994631 -0.09094591 -0.12492977 -0.20886771 -0.3854464\n",
      "   -2.6235566  -2.8263817  -2.920741   -2.1521385  -2.9389133\n",
      "   -2.4200945  -2.662139   -2.3775558  -2.4587064 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777738   6.8708997   1.9072905  -2.048807    1.6136558\n",
      "    0.4347124   0.33061004 -1.5694017  -0.8960926  -1.578415\n",
      "   -1.7464176   0.0396875   0.18672529  0.06133238 -1.0581158\n",
      "    0.00994873 -0.09094609 -0.12493147 -0.20886768 -0.3854449\n",
      "   -2.6235545  -2.8263803  -2.9207437  -2.152139   -2.9389138\n",
      "   -2.4200933  -2.6621416  -2.3775563  -2.458706  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777738   6.8708997   1.9072912  -2.048809    1.613661\n",
      "    0.43471074  0.33061072 -1.569399   -0.8960909  -1.578416\n",
      "   -1.7464188   0.03968777  0.18672627  0.06133232 -1.0581172\n",
      "    0.00995111 -0.09094648 -0.12493286 -0.20886777 -0.38544372\n",
      "   -2.623553   -2.8263788  -2.920746   -2.1521397  -2.9389126\n",
      "   -2.4200912  -2.6621442  -2.3775563  -2.4587054 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777743   6.8709      1.9072915  -2.048811    1.613666\n",
      "    0.43470904  0.33061126 -1.5693969  -0.8960897  -1.5784177\n",
      "   -1.7464199   0.03968801  0.18672723  0.06133248 -1.0581183\n",
      "    0.0099534  -0.09094647 -0.1249343  -0.2088676  -0.3854421\n",
      "   -2.6235511  -2.8263774  -2.9207482  -2.15214    -2.938912\n",
      "   -2.42009    -2.6621468  -2.377557   -2.458705  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777748   6.8709016   1.9072913  -2.0488124   1.6136711\n",
      "    0.4347077   0.33061224 -1.5693947  -0.89608824 -1.5784189\n",
      "   -1.7464211   0.03968833  0.18672812  0.06133261 -1.0581194\n",
      "    0.00995586 -0.09094685 -0.12493578 -0.20886756 -0.38544086\n",
      "   -2.6235497  -2.8263757  -2.9207497  -2.1521406  -2.9389117\n",
      "   -2.420088   -2.6621485  -2.3775573  -2.458705  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777745   6.8709035   1.9072922  -2.0488145   1.6136758\n",
      "    0.43470615  0.33061296 -1.5693922  -0.89608693 -1.5784203\n",
      "   -1.746422    0.0396885   0.18672913  0.06133258 -1.0581205\n",
      "    0.00995807 -0.09094694 -0.12493701 -0.20886753 -0.38543952\n",
      "   -2.6235483  -2.8263745  -2.9207516  -2.1521409  -2.9389112\n",
      "   -2.4200861  -2.6621506  -2.3775578  -2.4587045 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577775    6.8709035   1.9072922  -2.0488157   1.6136801\n",
      "    0.4347048   0.3306137  -1.56939    -0.8960854  -1.5784214\n",
      "   -1.7464229   0.03968853  0.18672979  0.06133261 -1.0581213\n",
      "    0.00995997 -0.09094705 -0.12493831 -0.20886779 -0.3854384\n",
      "   -2.6235466  -2.8263733  -2.9207535  -2.1521416  -2.9389107\n",
      "   -2.420085   -2.6621528  -2.3775582  -2.4587042 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777752   6.8709035   1.907293   -2.0488174   1.6136845\n",
      "    0.43470353  0.33061445 -1.5693877  -0.8960844  -1.5784224\n",
      "   -1.7464236   0.03968882  0.18673074  0.06133283 -1.0581223\n",
      "    0.00996196 -0.09094711 -0.12493955 -0.20886771 -0.38543728\n",
      "   -2.6235452  -2.8263721  -2.9207551  -2.152142   -2.9389105\n",
      "   -2.4200833  -2.662155   -2.3775582  -2.4587042 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777757   6.8709035   1.9072926  -2.0488188   1.6136888\n",
      "    0.4347021   0.3306152  -1.5693858  -0.89608324 -1.5784237\n",
      "   -1.7464247   0.03968902  0.1867317   0.06133293 -1.058123\n",
      "    0.00996403 -0.09094743 -0.12494063 -0.20886774 -0.38543603\n",
      "   -2.623544   -2.826371   -2.9207573  -2.152142   -2.9389102\n",
      "   -2.4200819  -2.6621566  -2.3775587  -2.4587042 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777757   6.870904    1.9072928  -2.04882     1.613693\n",
      "    0.4347007   0.33061597 -1.5693836  -0.89608204 -1.5784249\n",
      "   -1.7464255   0.03968909  0.18673241  0.06133304 -1.058124\n",
      "    0.00996587 -0.09094761 -0.12494193 -0.20886782 -0.38543513\n",
      "   -2.6235425  -2.82637    -2.9207585  -2.1521428  -2.93891\n",
      "   -2.4200807  -2.6621587  -2.377559   -2.4587038 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577776    6.8709035   1.9072933  -2.0488214   1.6136968\n",
      "    0.43469957  0.33061644 -1.5693818  -0.89608115 -1.578426\n",
      "   -1.7464263   0.03968921  0.18673304  0.06133305 -1.0581247\n",
      "    0.00996787 -0.09094777 -0.12494294 -0.20886767 -0.38543382\n",
      "   -2.623541   -2.8263688  -2.9207602  -2.152143   -2.938909\n",
      "   -2.420079   -2.6621606  -2.3775587  -2.4587033 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777757   6.8709035   1.9072933  -2.048823    1.6137006\n",
      "    0.43469852  0.33061722 -1.5693803  -0.8960799  -1.578427\n",
      "   -1.7464272   0.03968937  0.18673381  0.06133322 -1.0581257\n",
      "    0.00996963 -0.09094787 -0.12494408 -0.20886773 -0.38543296\n",
      "   -2.62354    -2.8263674  -2.920761   -2.1521435  -2.9389083\n",
      "   -2.4200778  -2.6621623  -2.3775592  -2.4587028 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777757   6.870904    1.9072934  -2.0488245   1.6137042\n",
      "    0.43469745  0.33061773 -1.5693786  -0.8960789  -1.5784276\n",
      "   -1.746428    0.03968942  0.1867345   0.06133318 -1.058126\n",
      "    0.00997125 -0.09094812 -0.12494501 -0.20886783 -0.38543212\n",
      "   -2.6235387  -2.8263662  -2.9207623  -2.1521437  -2.9389079\n",
      "   -2.4200764  -2.6621637  -2.3775597  -2.4587023 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777757   6.8709044   1.9072939  -2.0488257   1.6137079\n",
      "    0.43469635  0.33061838 -1.5693768  -0.8960778  -1.5784284\n",
      "   -1.7464285   0.03968968  0.18673512  0.06133352 -1.0581273\n",
      "    0.00997304 -0.09094834 -0.124946   -0.2088677  -0.38543117\n",
      "   -2.623538   -2.8263652  -2.9207637  -2.152144   -2.9389076\n",
      "   -2.4200752  -2.6621654  -2.3775601  -2.458702  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777762   6.8709054   1.9072944  -2.0488272   1.6137114\n",
      "    0.43469527  0.33061898 -1.5693756  -0.89607704 -1.5784296\n",
      "   -1.7464297   0.03968974  0.18673593  0.06133352 -1.0581278\n",
      "    0.0099745  -0.09094857 -0.124947   -0.20886777 -0.38543016\n",
      "   -2.6235366  -2.8263643  -2.9207647  -2.1521442  -2.9389076\n",
      "   -2.4200745  -2.6621668  -2.3775601  -2.4587018 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777764   6.8709064   1.9072949  -2.0488281   1.6137146\n",
      "    0.43469405  0.33061945 -1.5693737  -0.89607584 -1.5784303\n",
      "   -1.7464299   0.03968983  0.18673626  0.0613334  -1.0581285\n",
      "    0.0099761  -0.0909487  -0.12494805 -0.20886798 -0.3854293\n",
      "   -2.6235354  -2.8263633  -2.9207664  -2.1521447  -2.9389079\n",
      "   -2.4200735  -2.6621685  -2.3775606  -2.458702  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777767   6.870906    1.9072949  -2.048829    1.6137179\n",
      "    0.43469328  0.33062008 -1.5693723  -0.89607507 -1.5784312\n",
      "   -1.7464309   0.03968997  0.18673697  0.06133332 -1.0581293\n",
      "    0.00997754 -0.09094864 -0.12494893 -0.2088679  -0.38542843\n",
      "   -2.6235342  -2.8263624  -2.9207673  -2.152145   -2.9389076\n",
      "   -2.4200714  -2.6621702  -2.377561   -2.4587018 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577777    6.870908    1.9072948  -2.0488303   1.6137211\n",
      "    0.43469214  0.33062044 -1.5693711  -0.8960744  -1.5784322\n",
      "   -1.7464316   0.03969021  0.18673772  0.06133329 -1.0581298\n",
      "    0.00997889 -0.090949   -0.12494969 -0.2088678  -0.38542742\n",
      "   -2.6235337  -2.826362   -2.9207687  -2.1521454  -2.938908\n",
      "   -2.4200706  -2.6621714  -2.3775613  -2.458702  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777771   6.8709073   1.907295   -2.0488312   1.6137239\n",
      "    0.4346914   0.3306211  -1.5693696  -0.89607334 -1.5784329\n",
      "   -1.7464318   0.03969018  0.18673828  0.0613332  -1.0581303\n",
      "    0.00998032 -0.09094903 -0.12495047 -0.20886798 -0.38542664\n",
      "   -2.6235328  -2.8263612  -2.92077    -2.1521459  -2.9389076\n",
      "   -2.4200697  -2.6621728  -2.377561   -2.4587014 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777771   6.8709073   1.9072952  -2.0488322   1.6137269\n",
      "    0.4346903   0.33062148 -1.5693679  -0.89607257 -1.5784338\n",
      "   -1.7464325   0.03969024  0.18673882  0.06133333 -1.058131\n",
      "    0.00998147 -0.09094915 -0.12495154 -0.20886795 -0.38542616\n",
      "   -2.6235318  -2.8263597  -2.9207711  -2.152146   -2.938907\n",
      "   -2.420069   -2.6621745  -2.3775613  -2.4587011 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777771   6.870907    1.9072957  -2.0488334   1.6137298\n",
      "    0.4346895   0.3306219  -1.5693666  -0.8960715  -1.5784345\n",
      "   -1.7464333   0.03969051  0.18673933  0.0613333  -1.0581318\n",
      "    0.00998295 -0.0909495  -0.12495227 -0.20886804 -0.3854253\n",
      "   -2.6235309  -2.826359   -2.9207723  -2.1521463  -2.9389062\n",
      "   -2.4200685  -2.6621752  -2.3775616  -2.4587011 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777771   6.870908    1.9072958  -2.048834    1.6137325\n",
      "    0.43468872  0.33062235 -1.5693655  -0.8960709  -1.5784351\n",
      "   -1.746434    0.03969058  0.18673989  0.06133349 -1.0581325\n",
      "    0.00998439 -0.09094952 -0.12495294 -0.20886786 -0.3854245\n",
      "   -2.6235297  -2.8263578  -2.9207737  -2.1521468  -2.9389055\n",
      "   -2.420067   -2.6621766  -2.3775618  -2.4587011 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777771   6.8709083   1.9072961  -2.0488353   1.6137348\n",
      "    0.4346877   0.3306225  -1.569364   -0.8960702  -1.5784355\n",
      "   -1.7464346   0.03969057  0.18674034  0.0613336  -1.0581331\n",
      "    0.00998539 -0.09094951 -0.12495379 -0.20886804 -0.38542387\n",
      "   -2.6235292  -2.8263574  -2.920775   -2.1521463  -2.9389052\n",
      "   -2.4200659  -2.6621778  -2.377562   -2.4587007 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777776   6.8709083   1.9072963  -2.0488362   1.6137372\n",
      "    0.43468717  0.33062333 -1.5693626  -0.8960697  -1.5784361\n",
      "   -1.7464349   0.03969063  0.18674079  0.06133364 -1.0581331\n",
      "    0.00998668 -0.09094957 -0.12495436 -0.20886795 -0.38542312\n",
      "   -2.6235282  -2.826357   -2.9207752  -2.1521466  -2.9389052\n",
      "   -2.4200652  -2.6621785  -2.377562   -2.4587    ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777771   6.870909    1.9072964  -2.048837    1.6137397\n",
      "    0.43468636  0.3306235  -1.5693614  -0.89606875 -1.5784369\n",
      "   -1.7464354   0.0396908   0.18674114  0.06133349 -1.058134\n",
      "    0.00998785 -0.09094983 -0.12495521 -0.20886801 -0.38542256\n",
      "   -2.6235278  -2.826356   -2.9207761  -2.152147   -2.9389048\n",
      "   -2.4200647  -2.6621804  -2.377562   -2.4587007 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777776   6.870909    1.9072968  -2.048838    1.613742\n",
      "    0.43468565  0.33062387 -1.5693606  -0.8960681  -1.5784376\n",
      "   -1.7464359   0.03969091  0.18674168  0.06133349 -1.0581343\n",
      "    0.00998886 -0.09094986 -0.12495579 -0.20886795 -0.38542196\n",
      "   -2.6235268  -2.8263555  -2.920777   -2.1521478  -2.9389045\n",
      "   -2.4200642  -2.6621814  -2.3775623  -2.4587004 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577778    6.870911    1.9072967  -2.048839    1.6137446\n",
      "    0.4346849   0.33062425 -1.5693595  -0.8960677  -1.5784385\n",
      "   -1.7464362   0.03969094  0.18674225  0.06133353 -1.0581347\n",
      "    0.00999008 -0.09094989 -0.12495646 -0.20886791 -0.38542116\n",
      "   -2.6235266  -2.8263545  -2.920778   -2.152148   -2.938904\n",
      "   -2.420063   -2.6621823  -2.3775625  -2.4587002 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777786   6.870911    1.9072973  -2.0488396   1.6137468\n",
      "    0.4346842   0.33062473 -1.5693585  -0.8960671  -1.5784392\n",
      "   -1.7464367   0.03969114  0.18674263  0.06133389 -1.0581354\n",
      "    0.00999096 -0.09095    -0.12495719 -0.20886795 -0.38542095\n",
      "   -2.6235256  -2.8263538  -2.9207792  -2.152148   -2.9389048\n",
      "   -2.4200625  -2.6621833  -2.3775625  -2.4586997 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777786   6.870911    1.907297   -2.0488405   1.6137489\n",
      "    0.43468356  0.3306251  -1.5693575  -0.89606625 -1.5784395\n",
      "   -1.746437    0.03969121  0.18674305  0.06133395 -1.0581359\n",
      "    0.00999209 -0.09095004 -0.12495764 -0.20886798 -0.38542032\n",
      "   -2.6235244  -2.8263538  -2.9207797  -2.1521485  -2.938904\n",
      "   -2.4200616  -2.6621845  -2.3775628  -2.4586997 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777786   6.870911    1.9072971  -2.048841    1.6137508\n",
      "    0.4346829   0.33062544 -1.5693566  -0.8960657  -1.57844\n",
      "   -1.7464379   0.03969121  0.18674332  0.06133401 -1.0581359\n",
      "    0.009993   -0.0909501  -0.12495823 -0.20886792 -0.38541958\n",
      "   -2.6235235  -2.8263533  -2.9207804  -2.1521485  -2.9389043\n",
      "   -2.4200616  -2.6621852  -2.3775635  -2.4586997 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777786   6.870911    1.9072973  -2.0488415   1.6137527\n",
      "    0.43468225  0.33062562 -1.5693558  -0.8960649  -1.5784404\n",
      "   -1.7464379   0.03969119  0.18674386  0.06133392 -1.0581363\n",
      "    0.00999356 -0.0909501  -0.12495878 -0.20886798 -0.38541916\n",
      "   -2.623523   -2.8263528  -2.9207811  -2.1521487  -2.9389036\n",
      "   -2.4200606  -2.6621854  -2.377564   -2.4586995 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777788   6.870911    1.9072975  -2.048842    1.6137551\n",
      "    0.4346816   0.33062586 -1.5693549  -0.8960645  -1.5784405\n",
      "   -1.7464385   0.03969132  0.1867441   0.06133408 -1.0581369\n",
      "    0.00999478 -0.09095032 -0.12495935 -0.2088681  -0.38541868\n",
      "   -2.623523   -2.8263521  -2.9207816  -2.1521485  -2.9389036\n",
      "   -2.42006    -2.6621861  -2.377564   -2.458699  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777788   6.8709106   1.9072978  -2.048843    1.6137568\n",
      "    0.43468112  0.3306262  -1.5693539  -0.89606386 -1.5784415\n",
      "   -1.7464387   0.03969143  0.18674445  0.06133401 -1.0581373\n",
      "    0.00999584 -0.09095053 -0.12495981 -0.20886801 -0.38541824\n",
      "   -2.6235225  -2.8263514  -2.9207826  -2.152149   -2.9389033\n",
      "   -2.4200594  -2.662187   -2.377564   -2.4586992 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-2.5777788   6.8709116   1.9072978  -2.0488439   1.6137583\n",
      "    0.43468046  0.3306266  -1.5693531  -0.8960635  -1.578442\n",
      "   -1.7464393   0.03969149  0.18674481  0.06133372 -1.0581373\n",
      "    0.00999631 -0.09095059 -0.12496042 -0.20886791 -0.38541773\n",
      "   -2.6235223  -2.8263505  -2.9207833  -2.1521492  -2.9389026\n",
      "   -2.4200585  -2.6621883  -2.377564   -2.4586992 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777795   6.870912    1.907298   -2.0488443   1.61376\n",
      "    0.43468004  0.33062673 -1.5693523  -0.8960631  -1.5784423\n",
      "   -1.7464395   0.03969165  0.1867451   0.06133386 -1.058138\n",
      "    0.00999723 -0.09095074 -0.12496093 -0.20886825 -0.3854172\n",
      "   -2.6235223  -2.8263502  -2.920784   -2.1521492  -2.9389026\n",
      "   -2.420058   -2.662189   -2.3775642  -2.4586992 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777793   6.8709126   1.9072977  -2.0488448   1.6137618\n",
      "    0.43467933  0.33062702 -1.5693516  -0.89606273 -1.5784428\n",
      "   -1.74644     0.03969165  0.18674529  0.06133401 -1.0581383\n",
      "    0.009998   -0.09095073 -0.12496133 -0.20886813 -0.38541675\n",
      "   -2.6235216  -2.8263495  -2.920785   -2.1521494  -2.9389026\n",
      "   -2.4200578  -2.6621895  -2.3775642  -2.4586983 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777793   6.870913    1.907298   -2.0488455   1.6137635\n",
      "    0.4346789   0.33062726 -1.5693507  -0.89606214 -1.5784434\n",
      "   -1.7464403   0.03969176  0.18674582  0.06133425 -1.0581385\n",
      "    0.00999867 -0.09095076 -0.12496181 -0.20886818 -0.38541627\n",
      "   -2.6235209  -2.826349   -2.9207852  -2.1521494  -2.9389021\n",
      "   -2.4200568  -2.6621907  -2.3775642  -2.4586987 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777793   6.870913    1.907298   -2.048846    1.6137649\n",
      "    0.43467838  0.33062756 -1.56935    -0.8960618  -1.5784436\n",
      "   -1.7464406   0.03969178  0.18674618  0.06133431 -1.0581387\n",
      "    0.0099995  -0.09095071 -0.1249623  -0.20886804 -0.38541588\n",
      "   -2.6235197  -2.8263485  -2.9207854  -2.1521494  -2.9389017\n",
      "   -2.4200563  -2.6621914  -2.3775642  -2.4586985 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777798   6.8709135   1.907298   -2.0488462   1.6137668\n",
      "    0.43467802  0.33062807 -1.5693492  -0.89606124 -1.5784441\n",
      "   -1.7464409   0.03969198  0.18674642  0.06133418 -1.0581393\n",
      "    0.0100004  -0.0909509  -0.1249626  -0.20886813 -0.38541546\n",
      "   -2.6235192  -2.8263483  -2.920786   -2.15215    -2.9389021\n",
      "   -2.4200559  -2.6621919  -2.3775647  -2.4586985 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777798   6.8709135   1.9072978  -2.0488467   1.6137679\n",
      "    0.43467763  0.33062845 -1.5693488  -0.8960608  -1.5784445\n",
      "   -1.7464416   0.03969205  0.18674669  0.06133428 -1.0581394\n",
      "    0.01000092 -0.09095077 -0.12496315 -0.20886803 -0.385415\n",
      "   -2.623519   -2.826348   -2.9207866  -2.15215    -2.9389017\n",
      "   -2.420055   -2.6621923  -2.3775644  -2.4586985 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.57778     6.870914    1.9072981  -2.0488472   1.6137692\n",
      "    0.4346771   0.3306285  -1.569348   -0.8960605  -1.5784448\n",
      "   -1.7464417   0.03969211  0.1867471   0.06133434 -1.0581397\n",
      "    0.01000162 -0.09095088 -0.12496348 -0.20886801 -0.38541457\n",
      "   -2.6235187  -2.826347   -2.920787   -2.1521502  -2.938902\n",
      "   -2.4200542  -2.6621928  -2.3775644  -2.4586985 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.57778     6.870914    1.9072986  -2.048848    1.6137705\n",
      "    0.43467653  0.3306286  -1.569347   -0.8960602  -1.5784454\n",
      "   -1.7464418   0.0396921   0.18674728  0.06133442 -1.0581402\n",
      "    0.01000213 -0.09095109 -0.12496386 -0.20886798 -0.3854144\n",
      "   -2.6235182  -2.826347   -2.9207885  -2.1521506  -2.9389021\n",
      "   -2.4200537  -2.6621935  -2.377565   -2.458698  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777798   6.870914    1.9072988  -2.0488482   1.6137719\n",
      "    0.43467614  0.33062887 -1.5693465  -0.8960597  -1.5784456\n",
      "   -1.7464422   0.0396921   0.18674752  0.06133444 -1.0581404\n",
      "    0.01000286 -0.09095108 -0.12496436 -0.208868   -0.38541394\n",
      "   -2.623518   -2.8263464  -2.920789   -2.1521504  -2.9389021\n",
      "   -2.4200535  -2.6621943  -2.377565   -2.458698  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.57778     6.8709135   1.9072983  -2.0488486   1.6137731\n",
      "    0.4346758   0.33062914 -1.5693461  -0.8960593  -1.5784458\n",
      "   -1.7464423   0.03969206  0.18674773  0.06133427 -1.0581408\n",
      "    0.01000352 -0.09095103 -0.12496458 -0.20886804 -0.38541362\n",
      "   -2.623517   -2.8263464  -2.9207892  -2.1521506  -2.9389021\n",
      "   -2.4200532  -2.6621943  -2.3775654  -2.4586978 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.57778     6.8709145   1.9072987  -2.048849    1.6137745\n",
      "    0.43467546  0.3306292  -1.5693451  -0.896059   -1.578446\n",
      "   -1.7464428   0.03969224  0.18674785  0.0613341  -1.0581409\n",
      "    0.01000412 -0.0909512  -0.12496494 -0.20886798 -0.3854132\n",
      "   -2.623517   -2.826346   -2.9207895  -2.1521506  -2.9389017\n",
      "   -2.4200528  -2.662195   -2.3775654  -2.4586978 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777802   6.870915    1.9072988  -2.0488498   1.6137756\n",
      "    0.4346751   0.33062932 -1.5693448  -0.89605874 -1.5784467\n",
      "   -1.746443    0.03969244  0.18674815  0.06133429 -1.0581411\n",
      "    0.01000454 -0.09095127 -0.1249654  -0.20886809 -0.385413\n",
      "   -2.6235168  -2.8263457  -2.9207902  -2.1521506  -2.938902\n",
      "   -2.4200523  -2.662196   -2.3775651  -2.4586983 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777802   6.870915    1.9072993  -2.0488503   1.6137768\n",
      "    0.43467462  0.33062956 -1.5693442  -0.8960584  -1.5784471\n",
      "   -1.7464433   0.03969234  0.1867482   0.06133433 -1.0581414\n",
      "    0.0100051  -0.09095141 -0.12496565 -0.20886812 -0.38541263\n",
      "   -2.623516   -2.8263454  -2.9207907  -2.1521509  -2.9389017\n",
      "   -2.4200518  -2.6621966  -2.3775654  -2.4586978 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777805   6.870915    1.9072993  -2.0488505   1.613778\n",
      "    0.43467438  0.3306298  -1.5693438  -0.8960581  -1.5784475\n",
      "   -1.7464432   0.03969239  0.18674868  0.06133436 -1.0581421\n",
      "    0.01000568 -0.09095131 -0.12496594 -0.20886813 -0.3854123\n",
      "   -2.6235158  -2.8263447  -2.9207911  -2.1521506  -2.938902\n",
      "   -2.4200513  -2.6621974  -2.3775656  -2.4586983 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577781    6.870915    1.9072995  -2.048851    1.613779\n",
      "    0.43467408  0.3306301  -1.5693431  -0.89605784 -1.5784478\n",
      "   -1.7464439   0.03969244  0.1867488   0.06133432 -1.0581421\n",
      "    0.01000603 -0.0909515  -0.12496635 -0.20886819 -0.38541213\n",
      "   -2.6235156  -2.826344   -2.9207916  -2.152151   -2.9389014\n",
      "   -2.4200513  -2.662198   -2.3775656  -2.458698  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777807   6.8709154   1.9072996  -2.0488513   1.6137799\n",
      "    0.43467355  0.33063015 -1.5693426  -0.8960576  -1.5784478\n",
      "   -1.7464441   0.03969242  0.18674904  0.06133416 -1.0581423\n",
      "    0.01000646 -0.09095138 -0.12496659 -0.2088681  -0.38541168\n",
      "   -2.6235151  -2.826344   -2.9207919  -2.152151   -2.9389012\n",
      "   -2.4200509  -2.6621983  -2.3775656  -2.4586978 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777807   6.870915    1.9072995  -2.0488515   1.6137811\n",
      "    0.4346733   0.33063015 -1.5693421  -0.8960571  -1.578448\n",
      "   -1.7464441   0.03969242  0.18674916  0.06133436 -1.0581423\n",
      "    0.01000699 -0.09095131 -0.12496684 -0.20886816 -0.3854115\n",
      "   -2.6235147  -2.8263435  -2.9207923  -2.152151   -2.9389014\n",
      "   -2.4200504  -2.6621985  -2.3775659  -2.4586978 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777807   6.870916    1.9072994  -2.0488517   1.6137822\n",
      "    0.4346732   0.3306306  -1.5693417  -0.8960569  -1.5784484\n",
      "   -1.7464445   0.03969245  0.1867494   0.06133424 -1.0581425\n",
      "    0.01000771 -0.09095146 -0.12496702 -0.20886813 -0.3854113\n",
      "   -2.6235144  -2.8263435  -2.9207923  -2.152151   -2.9389012\n",
      "   -2.4200504  -2.6621993  -2.377566   -2.4586976 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777805   6.8709145   1.9072994  -2.0488524   1.6137831\n",
      "    0.43467286  0.3306308  -1.5693412  -0.89605653 -1.5784488\n",
      "   -1.7464447   0.03969249  0.1867496   0.06133438 -1.058143\n",
      "    0.01000813 -0.09095147 -0.12496734 -0.20886822 -0.38541102\n",
      "   -2.6235142  -2.8263426  -2.9207928  -2.152151   -2.9389012\n",
      "   -2.4200497  -2.6621995  -2.3775659  -2.4586976 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777807   6.870914    1.9072994  -2.0488527   1.6137837\n",
      "    0.43467242  0.33063102 -1.5693402  -0.8960562  -1.5784488\n",
      "   -1.7464447   0.03969256  0.18674964  0.06133448 -1.0581431\n",
      "    0.01000834 -0.09095147 -0.12496769 -0.2088683  -0.38541082\n",
      "   -2.6235137  -2.826343   -2.920793   -2.1521513  -2.9389012\n",
      "   -2.4200494  -2.6621997  -2.3775659  -2.4586976 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577781    6.8709145   1.9072996  -2.048853    1.6137849\n",
      "    0.4346723   0.33063084 -1.5693403  -0.89605606 -1.578449\n",
      "   -1.746445    0.03969258  0.18674988  0.06133445 -1.0581433\n",
      "    0.01000876 -0.09095164 -0.1249679  -0.20886827 -0.38541055\n",
      "   -2.6235135  -2.8263428  -2.9207933  -2.1521513  -2.9389012\n",
      "   -2.420049   -2.6622005  -2.3775654  -2.4586973 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777807   6.8709154   1.9072995  -2.0488534   1.6137856\n",
      "    0.43467182  0.33063114 -1.5693396  -0.89605576 -1.5784494\n",
      "   -1.7464451   0.0396927   0.18675011  0.06133442 -1.0581434\n",
      "    0.01000938 -0.09095176 -0.12496822 -0.20886804 -0.38541034\n",
      "   -2.623513   -2.8263426  -2.920794   -2.1521513  -2.9389014\n",
      "   -2.4200485  -2.662201   -2.3775659  -2.4586976 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777807   6.8709145   1.9072995  -2.0488536   1.6137867\n",
      "    0.43467158  0.3306312  -1.5693394  -0.8960556  -1.5784496\n",
      "   -1.7464454   0.03969261  0.18675017  0.06133416 -1.0581437\n",
      "    0.01000969 -0.09095187 -0.12496844 -0.20886816 -0.3854101\n",
      "   -2.6235125  -2.8263419  -2.9207942  -2.1521516  -2.9389007\n",
      "   -2.420048   -2.6622005  -2.377566   -2.4586973 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777807   6.8709145   1.9072995  -2.0488539   1.6137874\n",
      "    0.4346714   0.33063138 -1.5693389  -0.89605546 -1.5784496\n",
      "   -1.7464454   0.03969271  0.18675017  0.06133443 -1.0581437\n",
      "    0.01001023 -0.09095169 -0.12496859 -0.20886822 -0.38540986\n",
      "   -2.6235127  -2.8263419  -2.920794   -2.1521518  -2.9389007\n",
      "   -2.420048   -2.6622014  -2.3775656  -2.4586973 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577781    6.870915    1.9072999  -2.048854    1.6137881\n",
      "    0.43467104  0.33063155 -1.5693386  -0.89605504 -1.5784498\n",
      "   -1.7464454   0.03969258  0.18675041  0.06133419 -1.0581443\n",
      "    0.01001043 -0.09095174 -0.12496898 -0.2088681  -0.3854097\n",
      "   -2.6235125  -2.8263416  -2.9207947  -2.152152   -2.9389007\n",
      "   -2.4200478  -2.662202   -2.3775659  -2.4586966 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777807   6.870915    1.9072998  -2.0488546   1.6137891\n",
      "    0.43467093  0.33063167 -1.5693382  -0.8960549  -1.5784498\n",
      "   -1.7464457   0.03969285  0.18675056  0.06133413 -1.0581443\n",
      "    0.01001081 -0.09095187 -0.12496901 -0.20886803 -0.38540936\n",
      "   -2.6235123  -2.8263416  -2.9207954  -2.1521518  -2.9389005\n",
      "   -2.4200473  -2.6622021  -2.3775659  -2.4586968 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777805   6.8709145   1.9072995  -2.0488548   1.6137899\n",
      "    0.43467078  0.3306316  -1.5693381  -0.89605486 -1.5784503\n",
      "   -1.7464458   0.0396927   0.1867508   0.06133443 -1.0581442\n",
      "    0.01001127 -0.09095185 -0.12496935 -0.20886813 -0.38540927\n",
      "   -2.6235123  -2.8263416  -2.9207952  -2.152152   -2.9389\n",
      "   -2.4200473  -2.6622026  -2.3775659  -2.458697  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777807   6.870915    1.9072998  -2.048855    1.6137906\n",
      "    0.43467045  0.3306318  -1.5693375  -0.8960545  -1.5784504\n",
      "   -1.7464459   0.03969289  0.18675098  0.06133418 -1.0581445\n",
      "    0.01001127 -0.09095199 -0.12496947 -0.20886815 -0.38540888\n",
      "   -2.623512   -2.8263412  -2.920796   -2.1521523  -2.9389005\n",
      "   -2.4200473  -2.662203   -2.377566   -2.4586966 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777805   6.870915    1.9072999  -2.048855    1.6137911\n",
      "    0.43467033  0.3306319  -1.5693371  -0.8960544  -1.5784504\n",
      "   -1.7464463   0.03969292  0.1867511   0.0613346  -1.0581447\n",
      "    0.01001174 -0.09095192 -0.12496954 -0.20886813 -0.38540873\n",
      "   -2.6235116  -2.8263412  -2.920796   -2.1521523  -2.9389002\n",
      "   -2.4200468  -2.662203   -2.377566   -2.458697  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777805   6.870915    1.9072998  -2.0488555   1.6137916\n",
      "    0.4346702   0.33063197 -1.5693372  -0.896054   -1.5784507\n",
      "   -1.7464464   0.0396928   0.18675119  0.0613348  -1.0581448\n",
      "    0.01001194 -0.09095199 -0.1249699  -0.20886813 -0.3854085\n",
      "   -2.6235113  -2.8263412  -2.9207964  -2.1521525  -2.9388998\n",
      "   -2.4200468  -2.6622036  -2.377566   -2.4586966 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777805   6.8709154   1.9072999  -2.0488563   1.6137925\n",
      "    0.43467018  0.33063203 -1.5693369  -0.8960541  -1.5784504\n",
      "   -1.7464465   0.03969292  0.1867514   0.06133477 -1.058145\n",
      "    0.01001239 -0.09095208 -0.12497011 -0.20886825 -0.3854084\n",
      "   -2.6235113  -2.826341   -2.9207969  -2.1521523  -2.9388993\n",
      "   -2.420046   -2.662204   -2.377566   -2.4586966 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777805   6.870916    1.9073     -2.0488563   1.613793\n",
      "    0.4346696   0.33063224 -1.5693367  -0.89605373 -1.578451\n",
      "   -1.7464465   0.03969304  0.18675143  0.06133476 -1.0581452\n",
      "    0.01001275 -0.0909521  -0.12497033 -0.2088681  -0.3854083\n",
      "   -2.623511   -2.8263407  -2.9207973  -2.1521525  -2.938899\n",
      "   -2.4200459  -2.6622045  -2.377566   -2.4586968 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577781    6.8709164   1.9073002  -2.0488563   1.6137938\n",
      "    0.4346695   0.33063233 -1.5693364  -0.89605373 -1.578451\n",
      "   -1.7464468   0.0396929   0.18675146  0.06133454 -1.0581454\n",
      "    0.01001293 -0.090952   -0.12497035 -0.20886832 -0.38540822\n",
      "   -2.6235106  -2.8263404  -2.9207973  -2.1521523  -2.938899\n",
      "   -2.420046   -2.6622043  -2.3775659  -2.4586968 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577781    6.8709154   1.9073001  -2.0488565   1.6137942\n",
      "    0.43466938  0.3306324  -1.5693359  -0.89605343 -1.5784512\n",
      "   -1.7464468   0.03969293  0.18675157  0.06133468 -1.0581453\n",
      "    0.01001316 -0.09095205 -0.12497051 -0.20886822 -0.38540813\n",
      "   -2.6235104  -2.8263404  -2.9207976  -2.1521523  -2.9388988\n",
      "   -2.4200454  -2.6622047  -2.3775663  -2.4586968 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577781    6.8709154   1.9073001  -2.0488567   1.6137947\n",
      "    0.43466908  0.33063263 -1.5693359  -0.8960533  -1.5784513\n",
      "   -1.7464467   0.03969292  0.18675166  0.06133482 -1.0581455\n",
      "    0.01001334 -0.09095197 -0.12497079 -0.20886834 -0.3854079\n",
      "   -2.6235106  -2.8263402  -2.9207978  -2.1521525  -2.938899\n",
      "   -2.4200459  -2.662205   -2.3775663  -2.458697  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577781    6.870915    1.9073004  -2.048857    1.6137954\n",
      "    0.4346689   0.33063257 -1.5693355  -0.8960531  -1.5784514\n",
      "   -1.7464468   0.03969293  0.18675184  0.06133482 -1.0581456\n",
      "    0.01001375 -0.09095206 -0.12497105 -0.20886813 -0.38540772\n",
      "   -2.6235101  -2.8263402  -2.920798   -2.1521525  -2.9388988\n",
      "   -2.4200456  -2.6622052  -2.3775663  -2.4586973 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777807   6.8709154   1.9073006  -2.048857    1.6137962\n",
      "    0.43466872  0.33063263 -1.5693353  -0.89605296 -1.5784518\n",
      "   -1.7464473   0.03969299  0.18675196  0.06133468 -1.0581459\n",
      "    0.01001388 -0.09095219 -0.12497109 -0.20886819 -0.38540763\n",
      "   -2.62351    -2.8263397  -2.9207985  -2.1521528  -2.9388986\n",
      "   -2.4200454  -2.6622057  -2.3775663  -2.4586968 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777807   6.870915    1.9073007  -2.0488575   1.6137964\n",
      "    0.43466848  0.33063275 -1.569335   -0.8960527  -1.5784516\n",
      "   -1.7464472   0.03969302  0.1867519   0.06133465 -1.0581456\n",
      "    0.01001424 -0.09095222 -0.12497136 -0.20886819 -0.38540748\n",
      "   -2.62351    -2.8263395  -2.9207983  -2.1521528  -2.9388986\n",
      "   -2.4200451  -2.6622057  -2.3775663  -2.4586968 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577781    6.8709154   1.9073005  -2.0488575   1.6137968\n",
      "    0.43466854  0.3306327  -1.5693347  -0.89605254 -1.5784518\n",
      "   -1.7464473   0.03969288  0.18675196  0.0613348  -1.058146\n",
      "    0.01001433 -0.09095232 -0.12497135 -0.20886837 -0.38540715\n",
      "   -2.62351    -2.8263395  -2.9207985  -2.152153   -2.9388986\n",
      "   -2.4200451  -2.6622057  -2.3775663  -2.458697  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577781    6.870915    1.9073008  -2.0488577   1.6137973\n",
      "    0.43466842  0.33063287 -1.569334   -0.8960524  -1.578452\n",
      "   -1.7464473   0.0396928   0.18675214  0.06133473 -1.0581461\n",
      "    0.01001485 -0.09095234 -0.12497152 -0.20886843 -0.38540724\n",
      "   -2.6235096  -2.8263395  -2.9207995  -2.152153   -2.9388986\n",
      "   -2.4200451  -2.6622062  -2.3775668  -2.4586966 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577781    6.8709164   1.9073007  -2.048858    1.613798\n",
      "    0.43466818  0.3306331  -1.5693343  -0.89605236 -1.5784523\n",
      "   -1.7464471   0.03969298  0.18675232  0.06133467 -1.0581462\n",
      "    0.01001497 -0.09095217 -0.12497166 -0.20886828 -0.38540718\n",
      "   -2.6235092  -2.826339   -2.9207995  -2.152153   -2.9388986\n",
      "   -2.420045   -2.6622064  -2.3775663  -2.458697  ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.5777807   6.870916    1.9073007  -2.048858    1.6137986\n",
      "    0.43466818  0.3306331  -1.5693341  -0.89605236 -1.5784525\n",
      "   -1.7464474   0.03969305  0.18675256  0.06133474 -1.0581462\n",
      "    0.01001504 -0.09095229 -0.12497184 -0.20886813 -0.38540685\n",
      "   -2.623509   -2.826339   -2.9207995  -2.152153   -2.9388986\n",
      "   -2.4200444  -2.6622066  -2.3775668  -2.4586968 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577781    6.870916    1.9073007  -2.0488582   1.613799\n",
      "    0.434668    0.33063328 -1.5693339  -0.8960522  -1.5784525\n",
      "   -1.7464476   0.03969293  0.18675256  0.06133461 -1.0581461\n",
      "    0.01001526 -0.09095238 -0.12497193 -0.20886825 -0.38540685\n",
      "   -2.623509   -2.8263388  -2.9207995  -2.152153   -2.938899\n",
      "   -2.4200442  -2.6622071  -2.3775668  -2.4586968 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-2.577781    6.8709154   1.907301   -2.0488582   1.6137995\n",
      "    0.4346677   0.33063322 -1.5693339  -0.8960519  -1.5784526\n",
      "   -1.7464476   0.039693    0.18675268  0.06133464 -1.0581464\n",
      "    0.01001542 -0.09095233 -0.12497208 -0.20886828 -0.3854066\n",
      "   -2.6235087  -2.826339   -2.9208     -2.152153   -2.9388986\n",
      "   -2.4200444  -2.6622071  -2.3775668  -2.4586968 ]]], shape=(1, 1, 29), dtype=float32)\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int64)\n",
      "GAATCA AGAAAT ACTCTA TTTCAC CAGAGG AATCCT TGCAAA TACATT TTACTC CACTAT GCAAAA TCCTGT GGAACC AGTTTT TTATAC ATATTT TTAGCT GAAAGA TCAAGG AAATGT GTCACA GTTGGG GACCTG TATCAT AATTAT CTCTGT AGGTTC TACAGC ATCCAG CATGAT GTCCAA AGTAGC GAGATT GGTCAG TAAATG CTTTTA AATGAA CTCAAA TCTTAA AATTTC AATTAA TATTTT TCTTAC ATATAA TGTATA TTAAAA ATAAGA CATCTT CTGATG TCTCTA CAGTTA TAAACC TTAATT TAGATG CTTCCC ATGGAC CACTGC TTCTAA TGCAAC AAAGTA AGAATA AACACT GGAGTG GAAGGG ACAATG TGTTAG TATTCT TGAAAA AGAGCC TAGTTG TATAAC ATTTGT TAAGGA AAACAA GCAAAC CTGTAT TTTTTG AGAAGA AAGAAC AGAATT TTCATG TTATAT TAACCA CTAGAG GGAACC ACATGA ATAGAA TAGATA TTGACA TTGCAA AGGAAA GCTAAT TAAAAG ATTTTT ATTAGC ATGTTA GAATTC AAAGAA AATCAA TTTTAT AGTTAA AGTAAA AACCCA ATTCAT GCAAAA TCTAAC AAAGAT GCCTTC AAACAA CTAGTG TGTTAG AGGGAG GCAGTG GGAGAA TAATTG GGTTGA TTTTTA AAACCA GTAACA TTATTA CAATGG TAGATC TCATAT ATGCAT TAAGAA ACAATA AAAGTA AGTTAG GGTGAT GTAGCA CTTCTT CTTTGA AAGAGA TCGAGT TCCTTC CAGAGA GAGTGG AAACTT ACCACT TCCGTA AGTCTA TTTAAG AAAAAT TATTAG AGGCTA GAAGAC ATACTA TTACTA ATTTCT ATATAA CTCAAG CTACAT CTTAAA TTAGTT TTAATT AAAATA AACTTC AGTTTA GGGTCA AAATAA ACTTTT ATGTTT TAGAAT TCTTAA TTCTTT ATGCTC TGTAAC TTAAAA TGTAAT GTTAGG AGCTAC AACAAG CCTGCT GGAGTC TAGAGT GACTCA GATTGC CTTAGT CTAAAT AAAGAG CACTAA TTACAA AGGAAG CCAGAA TACAGG TTTTAA AAAGCT GACCCT TCAAAA GCAGCA TTGGTC TCTTGT TCTCTT TATCTT TGCTAC ATTTTC CCCTAG TTATTT CTATAG TTCTTA TACTTT CATTAT CTGTCT CAACAA TAAATG TCTTTT GCTCTG AGTAAA ACACCC TACTGA AAGTAC AGCATC CAGTAG TATTTC ACACCG GTTACA CTAGAC CCAATT CACTTT AGTCAT CATTTA ATTTAA TTTACC ACTTTT TACTTT GTTCTT TATTGA TGCTCT AGATCT AATGAC TATCAA TCTTGT ATTTTC TTCTTG GTTTCT CCTGAT AGGAAA ATGCCA AAGCAA TTGGGG AAAAAA ATACTG TTTTCT CTGAAA TGAAGA CTCCTC AAGATC CTGTTG CTGGAA TGAGTA TTGGAC TCTTCG GTCTAC TTCTAC AGTCAC CAGTAC ATCTGG CATACA CTATGA TGCCCA ACAGTA GGAAGA TGAAAG AAATGT AGATGT TGGCAT TTCTAA AAGAGA TGTTGT ATCTTT TTTCCT ACTTAA TAGACT ATTAGG CTATAA ATCTCA ATCTTG GCCAGC AAAXXX\n",
      "eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee\n"
     ]
    }
   ],
   "source": [
    "predict();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop is identical to last time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4645238\n",
      "2.774197\n",
      "2.4677558\n",
      "2.6867454\n",
      "2.4005113\n",
      "2.766795\n",
      "2.233971\n",
      "2.4498527\n",
      "2.4274797\n",
      "2.2721703\n",
      "2.184862\n",
      "2.076224\n",
      "2.4115314\n",
      "1.5510119\n",
      "1.7422825\n",
      "1.4034323\n",
      "1.0161092\n",
      "0.83225596\n",
      "1.223419\n",
      "0.70701957\n",
      "0.77638066\n",
      "0.6722054\n",
      "0.74572945\n",
      "0.51279306\n",
      "0.671731\n",
      "0.6543724\n",
      "0.51148003\n",
      "0.75509495\n",
      "0.46665543\n",
      "0.59829813\n",
      "0.6931491\n",
      "0.565956\n",
      "0.5389929\n",
      "0.5323079\n",
      "0.51939636\n",
      "0.48574576\n",
      "0.40161788\n",
      "0.5814586\n",
      "0.5035317\n",
      "0.53511804\n",
      "0.42420238\n",
      "0.42524326\n",
      "0.41056192\n",
      "0.4704584\n",
      "0.32415998\n",
      "0.3598993\n",
      "0.49445322\n",
      "0.40878522\n",
      "0.44159743\n",
      "0.38372555\n",
      "0.3689026\n",
      "0.38204968\n",
      "0.32122275\n",
      "0.37622017\n",
      "0.2843718\n",
      "0.4223533\n",
      "0.4231938\n",
      "0.36303195\n",
      "0.3272795\n",
      "0.33933383\n",
      "0.2599574\n",
      "0.3409711\n",
      "0.33878064\n",
      "0.27223638\n",
      "0.33211365\n",
      "0.281956\n",
      "0.31207627\n",
      "0.2378956\n",
      "0.25973788\n",
      "0.22408067\n",
      "0.262797\n",
      "0.28183392\n",
      "0.25120753\n",
      "0.2455067\n",
      "0.23269475\n",
      "0.25271592\n",
      "0.24856798\n",
      "0.27491966\n",
      "0.25013393\n",
      "0.3153869\n",
      "0.24736913\n",
      "0.19662927\n",
      "0.23461172\n",
      "0.27705455\n",
      "0.268171\n",
      "0.20236824\n",
      "0.22950126\n",
      "0.22087939\n",
      "0.24431936\n",
      "0.20857495\n",
      "0.23563123\n",
      "0.20701542\n",
      "0.2176206\n",
      "0.19716962\n",
      "0.23799141\n",
      "0.19083874\n",
      "0.19202551\n",
      "0.17292558\n",
      "0.20214036\n",
      "0.21505748\n",
      "0.1612255\n",
      "0.28839463\n",
      "0.22279155\n",
      "0.21039785\n",
      "0.2066873\n",
      "0.17351393\n",
      "0.21189284\n",
      "0.18698902\n",
      "0.19548461\n",
      "0.17953223\n",
      "0.19426014\n",
      "0.18295693\n",
      "0.17695017\n",
      "0.17920028\n",
      "0.18628673\n",
      "0.18607967\n",
      "0.15774542\n",
      "0.16565925\n",
      "0.16870256\n",
      "0.19740875\n",
      "0.18382426\n",
      "0.18584755\n",
      "0.16260138\n",
      "0.18302223\n",
      "0.18541907\n",
      "0.19393979\n",
      "0.1470668\n",
      "0.1496112\n",
      "0.19725522\n",
      "0.1655485\n",
      "0.15447924\n",
      "0.15584038\n",
      "0.1487631\n",
      "0.13520505\n",
      "0.13797934\n",
      "0.12418312\n",
      "0.18743065\n",
      "0.18063805\n",
      "0.16785224\n",
      "0.14755258\n",
      "0.15546674\n",
      "0.17932366\n",
      "0.16454664\n",
      "0.14526862\n",
      "0.17120217\n",
      "0.13753565\n",
      "0.1476836\n",
      "0.13744631\n",
      "0.15260617\n",
      "0.14501318\n",
      "0.17034104\n",
      "0.13181807\n",
      "0.13580841\n",
      "0.15487377\n",
      "0.12905943\n",
      "0.124373615\n",
      "0.16333191\n",
      "0.14136375\n",
      "Epoch 1 Loss 0.1414\n",
      "TGCTTA CTGTTT ACATGC CCAGGT CCCCCA CTACAC AGGAAG AAACCC TTTCTA GCTCAT CTGTTT CCTTAA GACCGA GAATCA GCCTGG GATGCT CTGAGT GAGTAA CAGCAG GAATGA GAGACT TAGAAG AGAACG TCTCTC TAATTG GTATTT CCCAGC AGCCAA AACAGA GCTGGC CAGCAA ACCCTG TGGGAT AGTGTG AAATAC ATATTT GGTCTT CATCCC CATAAC CTGGCA TACAAC TCCTAA AATCCT TGTAAT CTCCAA AGTGCT GCCTTT TCATAG ACTTAT GTTGAC TGACAG CTTTAG GATGAA GCTGGT CACTGG AAAGGC CAAGGC ACGATT ACAGGG TTGGGA TTCTCA GCTCCA ATGCCC CAAACT CAAGAG AGGGGA AAGGAG CTAAAG GTTAAG TTTATC ACCAAT GGCCAA TGGTTT AATCAA TCATAC CTACAT AATAAA GCCTCT ATACAA ACCTAA GAGGGC AGGGTT CAGAGA GCTGCT GGATAG CTAAGT GGACAG GATCCT AGAGGG TGATGC ACCCAG GAAGGG CATGAA AACTCT GCACCC CTTCCC CCATAC CTCAGC TTACAC ATTTCT TCATCT TTATCC TTTATA ATAAAT TGGTAA ATCTTT CTTTTT CTTTTC TGAGAC AGGGTC TCACTC TGCCAC CCAGGC TGGAGT GCAGTG GCATGA TCTCAG CTCACT GCAACC TCTGCC TCCTGG GTTCAA GTGATT CTCATG CCTCAT CCTCCC AAGTAA CTGAGA CTACAG ATGCAC ACCACC ATGCCT GGCTAA TTTTTG TATCTT TTGTAG AGACGG GGTTTC ACTATA TTGGCC ACGTTG GTCTCG AACTCC TGACCT CAAGTG ATCTGC CCACCT CGGCCT CCCAAA TTGCTG GGATTA CAGGCA TGAGCC ACTGCG CCCAGC CTAAAC TTGTAA ATCTAA GTGTTT CCCTGA GTTCTG TGAGAT GCTCCA GCAAAT TAATAG AACCCA AAGTGA GGGTCA TGGGAA CCCCAA CTTGAA TCCTTT TGGTCT CAAGTT TGGAAA CCCCGA ACTTAC AACTAG TGCCTT GAGTGG ACAGTC TCAGAG ACTGAG CCCTCA GCCTGT GGGATC TGAGGC TATCTC CAAGAG AGCACC AGAATT GAATTG AATTAG AGCTGC TTGGAA CATGGG AAAAAC CCTCCA TACATT TGGTCA CGAAGT CTTTGT TGATTG TTGTTG TGGTGT CAGAGC AGAGGA AAAATG TAATTA GCATTT TTCCCA AACAGC CTAAGG AGTGGA TGACAT AGAAGT GAAGGG ACTGGG AGCCAG CTGCCT GGGAAG GACACT TGAACT ATTTTT TGTGGC TGAAAT AGCATT TTTCTA GGGTAA ATAAAA CACAAA CCTACT TATGGG CAGATA ACAGGG GCAAAT AACAGC AAGGAA AGAGGA CAAGAT AGAAAA AGGAGG AGGAAA GCAAAG GCCTGA GGGTAA CAAGAG ATTTGT CTGGGG CTTGTA GAGAAG GGATTC GTGAGT GAAGCT GCAGCA CCTACC ACAGAA GCAGAG AGTGGG GGCAGA CTCACC TTCTCT CTTGTG CCTCCA GCTCCA GCTCCC CTGAGT TCTCAG GATGTG AGGGGT CTATGG TTCGTC CCCCCG CTCCAG CCTGGA GATGAC ATCAGG TTTGGA AGCTTG AAGTCC TGCTCC AGAGAA AGGAAG CAAGAC CTGAAA AGTCAT CCCAGG TAGAGG GCAGGA TGGACC TGTGGT CTGAGT CTTTGT GCTGGT TGTGTC CTTCCC TGCCAC CTGGTC TCTAAC CGTGGA GAAAGA CACAGG CCTCTG CCTAAG CTGAGG AAAGGT CAAAAC TAGCTT TTCAGG AGGACG GGGAGC ATAGAT AGGACA GTGTTG GGGCCT GAACAC ATCATG GTAGAG GACTCA TAGTAG TGGGXX\n",
      "eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee\n",
      "0.12850966\n",
      "0.1763236\n",
      "0.15583274\n",
      "0.16565903\n",
      "0.1647926\n",
      "0.16191764\n",
      "0.13455576\n",
      "0.16608931\n",
      "0.174231\n",
      "0.15896241\n",
      "0.12500839\n",
      "0.115905546\n",
      "0.13719088\n",
      "0.15942091\n",
      "0.14077896\n",
      "0.13858777\n",
      "0.12531714\n",
      "0.14475846\n",
      "0.1308952\n",
      "0.1548913\n",
      "0.12137494\n",
      "0.12745504\n",
      "0.1454844\n",
      "0.11429924\n",
      "0.15881252\n",
      "0.115610786\n",
      "0.18011948\n",
      "0.13288786\n",
      "0.15751632\n",
      "0.13499469\n",
      "0.1281249\n",
      "0.12414098\n",
      "0.13274615\n",
      "0.11472556\n",
      "0.11640575\n",
      "0.14560653\n",
      "0.15802705\n",
      "0.12642007\n",
      "0.12584892\n",
      "0.16867813\n",
      "0.12279738\n",
      "0.13265435\n",
      "0.14241065\n",
      "0.11666196\n",
      "0.12235301\n",
      "0.1255905\n",
      "0.13391596\n",
      "0.13484661\n",
      "0.132062\n",
      "0.12105693\n",
      "0.13724214\n",
      "0.14702891\n",
      "0.1076818\n",
      "0.15550563\n",
      "0.1679567\n",
      "0.10927783\n",
      "0.09782147\n",
      "0.1312505\n",
      "0.12836047\n",
      "0.120609395\n",
      "0.098300666\n",
      "0.10323483\n",
      "0.13477214\n",
      "0.13776934\n",
      "0.10568034\n",
      "0.10779849\n",
      "0.12255072\n",
      "0.15509859\n",
      "0.1368994\n",
      "0.13105245\n",
      "0.13057998\n",
      "0.12314135\n",
      "0.1257861\n",
      "0.12152966\n",
      "0.12598746\n",
      "0.13719806\n",
      "0.12967493\n",
      "0.11258945\n",
      "0.12848096\n",
      "0.1591113\n",
      "0.114341564\n",
      "0.12121775\n",
      "0.17578398\n",
      "0.10390509\n",
      "0.11575592\n",
      "0.121755116\n",
      "0.09117731\n",
      "0.15773037\n",
      "0.11752977\n",
      "0.1130982\n",
      "0.14749312\n",
      "0.12698907\n",
      "0.12793791\n",
      "0.11488662\n",
      "0.11975699\n",
      "0.11080799\n",
      "0.11076834\n",
      "0.12539634\n",
      "0.14382344\n",
      "0.10405069\n",
      "0.1438599\n",
      "0.11301863\n",
      "0.12000897\n",
      "0.10746863\n",
      "0.12166397\n",
      "0.099759735\n",
      "0.10750219\n",
      "0.11400923\n",
      "0.11665596\n",
      "0.12667651\n",
      "0.10105012\n",
      "0.11521649\n",
      "0.1554314\n",
      "0.102026656\n",
      "0.09594758\n",
      "0.13653207\n",
      "0.10825332\n",
      "0.10561896\n",
      "0.1028243\n",
      "0.113481335\n",
      "0.11217567\n",
      "0.09553276\n",
      "0.09651464\n",
      "0.093695104\n",
      "0.10898944\n",
      "0.09417078\n",
      "0.1025429\n",
      "0.09513007\n",
      "0.13878204\n",
      "0.120568804\n",
      "0.11054954\n",
      "0.11726495\n",
      "0.10124416\n",
      "0.10558675\n",
      "0.08913187\n",
      "0.096748784\n",
      "0.10640533\n",
      "0.09745946\n",
      "0.10415007\n",
      "0.112719364\n",
      "0.09659329\n",
      "0.093253694\n",
      "0.105142325\n",
      "0.10300907\n",
      "0.0904113\n",
      "0.09555146\n",
      "0.09258366\n",
      "0.10080416\n",
      "0.1315598\n",
      "0.10635264\n",
      "0.118643075\n",
      "0.11414865\n",
      "0.122671515\n",
      "0.08974847\n",
      "0.0903421\n",
      "0.12742491\n",
      "0.1309221\n",
      "0.109817155\n",
      "Epoch 2 Loss 0.1098\n",
      "ATTAAT CCCTTA ATCTTT TCTACC ATCCCA TCTACT CTGTTC ATAGGA ACCATA ATCACT TATTCA GCTCAC AGTGAT TAATAA TCTGAA TAGGAC TAGAAA TAAATA TATATC ATTACC CCCATT TTAATC AAATAA GCAAAC CCATGA TCCACA GAAGTA GCTACA TATTAA CACAAG CACCTC TATCTA TACTCC TAACAA TGCTCA TTATCA TTATAT ATTGTA CTCTGG ACAATG AAGAGT TGTAAA AATTTC CAGCCA AACAGC ATCCCT AATAAT TATTAT AGCACT AGTTAT GAGATT TGGATT ATCACC CTTCCA TTTTGA AGTGCC AGTAGT TACACA AGAAAT CTCAGT AACATC AGTTGT AATTCT ACTAAC ATGATG ACAATG TGAAAG GAAAAT AAATCT TGGGAC CCCAAG CTCATT AAGCCA AAGGGA AAAGTT AAGCCG GGAACT GGGTCA CTCAAA ACTGTC TCCCCC TTTTGA TTCCTA AATAAG ATGACT ACAAGA TGAAAA GCTACA TGCTTC CCCCAT ATTTTG CCCACA AGGAAA TTCCTA GTGAGC TCCAAG ATCTTT ACCCTA AGGTGT TTCTGT TAAAAT TTCACC ATGACA ATGTAA CTCCAT AGCTCA TTGACA GGTGCA ATCACT CCCCTG CCCACG TGACAC AAATGC ATATCT GATTGT TCCCCT GCCCCA TTTTGC CTATGT TATCTT ATGTAA AAATAC AGATTC CCTGCA TTTTTC CTCTGC CCCATT TGTCTG TGTCAT CCTAAG TAAAAA TGCAGA TTCACT GAGCCA GACAAA GACATG AATCAC TATTTT TCCTTA TCCCCC TCTTAC ATGAAA ATTGTG TACTTC TCAATA CCCTGC CCTTTT CCCTTT AAATTT GGAGCC CTCAAA ATCATC TTAGGA GAAAGG CATAGA CCTGTT TCCTGG GTGCAC ATCCTT AACTTT GGCAAA TAAACC TCCTAA AATAAT TGAGAC TTGTCT CCTCAT TTTTCT TGATTG ACAACA ACTAGC ACCAAT TTCAAT TATGTT TCAGGT ATCATC ATCAGT TGATCT AAATAT AATGCT AAAAAT TGCTAT GTTGTC TGTTCT AGTAAG AGGGTG AGGAGG ACTTAA TCAGAC AAAACT TTGAAA AATCTT AGCCTA CACATC AATTGC ACACAT AGGCTG AAAAAC AACTAC CTTCTT TTATAG CCCTTC CACAAT AATTCT AAATTT ACTAAT TTATGT AATCCT AATACT CACCAT ATTCAT AATATT TAGCTT AAATAC AAACAC CACAAC CCTATC ACTATC ACACAT ATGGAA TAAGTT ACCATT AATAAT TTCCAT AATCCT TATTAC CCTTTT ATCCTT AGGTCT ACCCCC ACTTAC AGGATT TCTTCT CAAATG AATTAT TATTCA AGAACT AACAAA AACCAC ACCATC ATCATG GCAACA TTTAAA GCTATT ATAGTG TTACTC AACCCA TACTTT TATATA CGATTA ATCTAT CCTACA TCATTA ACCGTG TTTCCA ACAAAC ATTAAC ATAAAA ACAAAA TGACAG CTCACA AATTTA AAAXXX\n",
      "eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 2\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for batch, (source_seq, target_seq_in, target_seq_out) in enumerate(dataset.take(-1)):\n",
    "        enc_initial_states = enc_dec.init_states(source_seq.shape[0])\n",
    "        loss = train_step(source_seq, target_seq_in, target_seq_out, enc_initial_states)\n",
    "        print(loss.numpy())\n",
    "    print(f'Epoch {epoch+1} Loss {loss.numpy():.4f}')\n",
    "    \n",
    "    try:\n",
    "        predict();\n",
    "    except Exception:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TGCAGG TTGTCC ACCCGG CCGGAG GTGGCC AGCATC GAGTCG CTGGGC CTGGAC GAGCAG CAGTGC TCCCAG AAGGCG GTGGTG CAGGCC CACCTG ACCCAG CCTGCC CGACTC ACCAGC ATCATC TTTGCA GAGGAC ATCAGT AAGGGC TGACTG CCCTTA CAGGCA TAAGCC ACCTCG CTCAGC CTATTT GTAAGG CTTTTG ATACAT GGGACT TATTGC TTTCCA ACAAAA CAATCT TAACAA TGCATA AGTACC TGGAGA AGAGTC AGAAAA ATGTTG TATCCT GCTGCT ATCCTT ACATTT GAGAAT TCCCCG GGTAAT GCCATT CATGTA CCTTTT TTATGG AGCAAG TAAAAA CCATCT GTATGA GTGTCC ATGTGC CCCTTC TACATT ATACTT GATAAT CATATA AATACA CCATCA TAGGCC AGGCGC AATGTC TCACAC CTGTAA TCCTAG CACTTT GGGAGG CCAAGG CAGGAG GATTAC TTGAGC TTAGGA GTATAA GACCAG CCTATG CCACAA AGCAAG ACCTTA ACTCTA TAAAAA AGTTTT TAAAAA TTAGCC AGGCAT GGTGAT GTATGC ATGCTT GTGGTC CCAGAT ACTAGG GAGGCC AAGGCA GGAGAA TCAGTT GACTCC GGGAGC CACTGC ACTCCA GCCTGG GCAACA AATTGA GACCCT GTCGCA AAAGAA ACAAAA ATAAAC AAAATC ACCAGT GTAATT CCTAAT CTCAGT GGAGGG ACAGGG CTCTCA TCTTTG GGACGG GAACTC ATCCAT ATTGTA GCACTT GTCACT TCACTG AATGGT TACACC CTGAAC AAAATG AAGTTT TCCTGG AGTTTT CTTTGC CCACAG CTTTAA ATGCTG ATTCCC CGCTGG AAAAGC CAGACC AGGTGG TGACAA GGCCCC CACAGC CCTTCC TTTCTG GTAGTC CCTGTT AACTTT CAGTGG GGCCAC GTGCGA GGCAGC TGCTTG GCTTCT GAGGGT GAGGCT GGTGGT CGCTGT GGTCTT TGCCAA AGTGTA AGTCTG CAAGGC TTGGAG GTGGCG CCAGGG GCAGCT GCTGTC TTCAGT GCTGAC TTCTCC CTGGGG TTCCTC CAGCCA CAGACC AGGTCC TGCACT GTGACG CCACCG TGGACC TCATCC CCGGCA TCCAGA TCGTCT CCACCA CCCGCA AGCTCA ACCTGG AGGACT CCCCCC TGGAGC TGAAGA TCCAGG CCCTGG ACTCTG AGGGTX\n",
      "eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee eeeeee\n"
     ]
    }
   ],
   "source": [
    "predict();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh no! The loss looks good, but only because we've learned to just predict exon at every step. Why might that be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'E': 691505, 'I': 479703})\n"
     ]
    }
   ],
   "source": [
    "all_cls_data = ''.join(cls_data).replace(' ', '').replace('X', '')\n",
    "\n",
    "print(Counter(all_cls_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems to be fairly well balanced, so it's probably either not training long enough, or too much of a bottleneck in the LSTM.\n",
    "\n",
    "Does the full dataset (with longer transcripts) look better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'I': 30791692, 'E': 20226889})\n"
     ]
    }
   ],
   "source": [
    "all_cls_data = ''.join(raw_data_cls).replace(' ', '').replace('X', '')\n",
    "\n",
    "print(Counter(all_cls_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe a little, but still pretty even. Things to try:\n",
    "\n",
    "* Multiple restarts - Sometimes you get a bad seed and get trapped in a local minimum\n",
    "* Increase or DECREASE the number of epochs - Sometimes you fit too quickly or too slowly\n",
    "* Increase or decrease the gradient step - Adam tries to help you, but sometimes you need to fiddle with it manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Seq2Seq with Attention\n",
    "\n",
    "Seq2seq is cool because the decoder can use a partial answer to try and generate the rest of the sequence, but it only gets one piece of information (the hidden state at the first step) from the encoder now. The encoder knows a bunch about this sequence, but we're really biasing the decoder towards the state at the final few \"words\".\n",
    "\n",
    "What if we had a way for the encoder to pass information about which parts of the sequence seem important?\n",
    "\n",
    "This is called attention.  Attention models produce two new pieces of information:\n",
    "\n",
    "* Alignment vector: Probability of the word within the sequence. They tell the decoder what to focus on at each step\n",
    "* Context vector: Weighted average of the encoder output. Dot product of the alignment vector and the encoder output\n",
    "\n",
    "Reminder of the [Luong Attention Paper](https://arxiv.org/abs/1508.04025)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luong style general attention\n",
    "class LuongAttention(tf.keras.Model):\n",
    "    def __init__(self, rnn_size: int):\n",
    "        super(LuongAttention, self).__init__()\n",
    "        # h_t @ W @ h_s - aka a Dense layer\n",
    "        self.wa = tf.keras.layers.Dense(rnn_size)\n",
    "    \n",
    "    def call(self, decoder_output, encoder_output):\n",
    "        \"\"\" Dot product between encoder and decoder output \"\"\"\n",
    "        # h_t dot Wa dot h_s\n",
    "        score = tf.matmul(decoder_output, self.wa(encoder_output), transpose_b=True)\n",
    "        # Alignment vector\n",
    "        alignment = tf.nn.softmax(score, axis=2)\n",
    "        \n",
    "        # Context vector c_t average sum of encoder output\n",
    "        context = tf.matmul(alignment, encoder_output)\n",
    "        return context, alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder doesn't need to change at all, but we'll use the encoder output directly in the decoder. Which is nice because we were just throwing it away earlier..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to rework the decoder\n",
    "class SeqAttnDecoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_size, rnn_size):\n",
    "        super(SeqAttnDecoder, self).__init__()\n",
    "        \n",
    "        self.rnn_size = rnn_size\n",
    "        \n",
    "        # Attention\n",
    "        self.attention = LuongAttention(rnn_size)\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = tf.keras.layers.LSTM(\n",
    "            rnn_size, return_sequences=True, return_state=True)\n",
    "        \n",
    "        # Now we need to composite the attention with the LSTM output\n",
    "        self.wc = tf.keras.layers.Dense(rnn_size, activation='tanh')\n",
    "        \n",
    "        # Then one more to map back to vocab space\n",
    "        self.ws = tf.keras.layers.Dense(vocab_size)\n",
    "    \n",
    "    def call(self, sequence, state, encoder_output):\n",
    "        \"\"\" We now call the decoder one token at a time \"\"\"\n",
    "        # Output is (batch_size, 1)\n",
    "        embed = self.embedding(sequence)\n",
    "        \n",
    "        # So the lstm has output shape (batch_size, 1, rnn_size)\n",
    "        lstm_out, state_h, state_c = self.lstm(embed, initial_state=state)\n",
    "        \n",
    "        # Apply attention. Mix the encoder output with the decoder output\n",
    "        context, alignment = self.attention(lstm_out, encoder_output)\n",
    "        \n",
    "        # Now we stack the vectors together\n",
    "        lstm_out = tf.concat([tf.squeeze(context, 1), tf.squeeze(lstm_out, 1)], 1)\n",
    "        \n",
    "        # Map back into the target space\n",
    "        lstm_out = self.wc(lstm_out)\n",
    "        \n",
    "        # Map back into vocab space\n",
    "        logits = self.ws(lstm_out)\n",
    "        return logits, state_h, state_c, alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source vocab size 4374\n",
      "Source sequences (1, 8)\n",
      "Encoder outputs (1, 8, 64)\n",
      "Encoder state_h (1, 64)\n",
      "Encoder state_c (1, 64)\n",
      "\n",
      "Destination vocab size 29\n",
      "Destination sequences (1, 7)\n",
      "Decoder outputs (1, 29)\n",
      "Decoder state_h (1, 64)\n",
      "Decoder state_c (1, 64)\n",
      "Alignment (1, 1, 8)\n"
     ]
    }
   ],
   "source": [
    "# Generate a model and check for typos\n",
    "EMBEDDING_SIZE = 32\n",
    "LSTM_SIZE = 64\n",
    "\n",
    "encoder = SeqEncoder(seq_vocab_size, EMBEDDING_SIZE, LSTM_SIZE)\n",
    "\n",
    "decoder = SeqAttnDecoder(cls_vocab_size, EMBEDDING_SIZE, LSTM_SIZE)\n",
    "\n",
    "source_input = tf.constant([[1, 3, 5, 7, 2, 0, 0, 0]])\n",
    "initial_state = encoder.init_states(1)\n",
    "\n",
    "# Notice that now we feed the hidden states of the encoder into the hidden state of the decoder\n",
    "encoder_output, enc_state_h, enc_state_c = encoder(source_input, initial_state)\n",
    "\n",
    "print('Source vocab size', seq_vocab_size)\n",
    "print('Source sequences', source_input.shape)\n",
    "print('Encoder outputs', encoder_output.shape)\n",
    "print('Encoder state_h', enc_state_h.shape)\n",
    "print('Encoder state_c', enc_state_c.shape)\n",
    "\n",
    "# Tricky, we need to feed the sequence in one step at a time\n",
    "target_input = tf.constant([[1, 4, 6, 9, 2, 0, 0]])\n",
    "\n",
    "for i in range(target_input.shape[1]):\n",
    "    target = target_input[:, i:i+1]\n",
    "    decoder_output, dec_state_h, dec_state_c, alignment = decoder(target, (enc_state_h, enc_state_c), encoder_output)\n",
    "\n",
    "    if i == 0:\n",
    "        print('')\n",
    "\n",
    "        print('Destination vocab size', cls_vocab_size)\n",
    "        print('Destination sequences', target_input.shape)\n",
    "        print('Decoder outputs', decoder_output.shape)\n",
    "        print('Decoder state_h', dec_state_h.shape)\n",
    "        print('Decoder state_c', dec_state_c.shape)\n",
    "        print('Alignment', alignment.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training becomes a little more complicated, because we have to manually handle batches now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(source_seq, target_seq_in, target_seq_out, en_initial_states):\n",
    "    \"\"\" normal training with unrolled decoder \"\"\"\n",
    "    loss = 0.0\n",
    "    with tf.GradientTape() as tape:\n",
    "        en_outputs = encoder(source_seq, en_initial_states)\n",
    "        en_states = en_outputs[1:]\n",
    "        de_state_h, de_state_c = en_states\n",
    "        \n",
    "        # Loop through the target sequence\n",
    "        for i in range(target_seq_out.shape[1]):\n",
    "            print('Decode step: {} of {}'.format(i+1, target_seq_out.shape[1]))\n",
    "            # Need to expand to insert a batch\n",
    "            decoder_in = tf.expand_dims(target_seq_in[:, i], 1)\n",
    "            \n",
    "            # Now decode one step at a time, with the whole input as context\n",
    "            logit, de_state_h, de_state_c, _ = decoder(\n",
    "                decoder_in, (de_state_h, de_state_c), en_outputs[0])\n",
    "            \n",
    "            # Accumulate the loss\n",
    "            loss += loss_func(target_seq_out[:, i], logit)\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return loss / target_seq_out.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction also gets a lot more complicated because of all the bookkeeping..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_seq=None):\n",
    "    \"\"\" Predict on the source sequence only \"\"\"\n",
    "    if test_seq is None:\n",
    "        test_seq = seq_data[np.random.choice(len(seq_data))]\n",
    "    elif isinstance(test_seq, int):\n",
    "        test_seq = seq_data[test_seq]\n",
    "    test_seq_idx = seq_tokenizer.texts_to_sequences([test_seq])\n",
    "    \n",
    "    en_initial_states = encoder.init_states(1)\n",
    "    en_outputs = encoder(tf.constant(test_seq_idx), en_initial_states)\n",
    "    \n",
    "    # Initialize the decoder\n",
    "    de_input = tf.constant([[cls_tokenizer.word_index['<start>']]])\n",
    "    de_state_h, de_state_c = en_outputs[1:]\n",
    "    \n",
    "    max_len = len(test_seq.split(' ')) + 10\n",
    "    \n",
    "    out_kmers = []\n",
    "    alignments = []\n",
    "    while True:\n",
    "        de_output, de_state_h, de_state_c, alignment = decoder(\n",
    "            de_input, (de_state_h, de_state_c), en_outputs[0]\n",
    "        )\n",
    "        # Again, feed back in the single best prediction\n",
    "        de_input = tf.expand_dims(tf.argmax(de_output, -1), 0)\n",
    "        pred = de_input.numpy()[0][0]\n",
    "        \n",
    "        if pred in cls_tokenizer.index_word:\n",
    "            out_kmer = cls_tokenizer.index_word[pred]\n",
    "        else:\n",
    "            out_kmer = 'X'*NUM_K\n",
    "        out_kmers.append(out_kmer)\n",
    "        \n",
    "        alignments.append(alignment.numpy())\n",
    "        \n",
    "        if out_kmers[-1] == '<end>' or len(out_kmers) >= max_len:\n",
    "            break\n",
    "    print(test_seq)\n",
    "    print(' '.join(out_kmers))\n",
    "    return out_kmers, np.array(alignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGTTGA CAGCAA GTAGGA GGGCCC TATGGA AGGAGA AAAAAA GACAAC ACGAGA AAAATT AGTATT TTCTAC CTTCTG AAATTA ATGGTC ATGAGT TCGTAT ATGGTG AACTCC AAGTAT GTGGAC CCCAAG TTCCCT CCGTGC GAGGAG TATTTG CAGGGC GGCTAC CTAGGC GAGCAG GGCGCC GACTAC TACGGC GGCGGC GCGCAG GGCGCA GACTTC CAGCCC CCGGGG CTCTAC CCACGG CCCGAC TTCGGT GAGCAG CCTTTC GGAGGC AGCGGC CCCGGG CCTGGC TCGGCG CTGCCT GCGCGG GGTCAC GGACAA GAGCCA GGCGGC CCCGGC GGTCAC TACGCC GCTCCA GGAGAG CCTTGC CCAGCT CCCCCG GCGCCT CCGCCG GCGCCC CTGCCT GGCGCC CGGGCC TACAGT CAGTCC GACCCC AAGCAG CCGCCC TCCGGG ACGGCA CTCAAG CAGCCG GCCGTG GTCTAC CCCTGG ATGAAG AAGGTG CACGTG AATTCG GGTAAG GCTAGG GTCCAG TAACCT TTCTGT CCACAT CCCAGC CCGTTA GCCTGG GTCCTC TGGAAG GGGGTG CGAGTA GGTGGG GGCGTG TGGAGC TTCCAT GGGCGC CGCAAT TACTCT CCCCAT AAATTT TTATAG CTGAGG GAGCAG GTCAGG ACCATG TGGCTG GCTGCT CGGCTG TGGGCG CAAAAG GGGGTG GGGATG GGGGGG TGGGGG AGGACT CCATTT TCAGAG CAGGGG GAAGGC TGTGGA GGAGCG GGGGAT TTCCAA AATGCT TGAGGG TTCCGG ACCTGG TGGTGG GCCCAG AAGAAG GAGCAC ATTTGG GGATCC CGCAAG CCTGGG GTATGT GGGTGT GTTTGA GGAGGT GGGTGG GAGTGA GCGTGT GCGCCG GGGAGA GGGCGG GAGGGA GGAAGC AAGCGA GCTTGG GAGCGC GCGGGG AGGGCC GCGGGC CTCGGG GCGCGC CAGGAA GTGAGC GGCGGA GGCGAG GGGCCT AACTAG TGGCCG GGCGCT GACCTG CCTGTC CTGTCT GTTTTG TCTCGC AGTGAA CCCCAA CTACAC CGGTGG GGAACC CAAGCG GTCCCG AACGGC CTACAC CCGGCA GCAAGT CCTAGA ACTGGA AAAAGA ATTTCA TTTTAA CAGGTA TCTGAC AAGGCG CCGTCG GATTGA AATCGC TCACAC CCTGTG TCTGTC GGAGCG CCAGAT CAAGAT CTGGTT CCAGAA CCGGAG GATGAA GTGGAA AAAAGA TCATAA GCTGCC CAACAC TAAAGG CAGGTC ATCGTC CTCATC TTCCTC CTCATC TTGCTC CTCCTC AGTCGC CCCCAG CCAGCA TTTACA GCCGAT GGCCAA AGACCA CCACAC GGACCT GACGAC CTTATA GAAGTG GGGACC CTGGGC CCATCT CTCCCT GCGCAC CAGGCT GAGCCG AAGCTG CGGGGG CAGGCC GGGCCT GCTGTC ACCTCG CTGGGC TCTAAG GTACTG TGGGGT GGACCT GGGACA AGCAGG CCGCCC TCGGAC TAGGTT AGCATC CTGCCC GAGGGC AGCCCC CTCCCT AGAGCG GGATGG GGATGG GAGGGG GGGCGG GATTCT CTCTCT AAGTAT ATTATA TGGCAG GAGCTA CTGAGA ACATAA AATCTT GGCGAG TCATTA AACTTA TGAAAA TCAXXX\n",
      "eiiiii iiiiix iiiiix iiiiix iiiiix iiiiix iiiiix iiiiix iiiiix iiiiix iiiiix XXXXXX iiiiix XXXXXX iiiiix XXXXXX XXXXXX XXXXXX XXXXXX eeeexx eeeexx eeeexx eeeexx eeeexx eeeexx eeieee iixxxx eeieee iixxxx iixxxx ixxxxx eeeexx eeeexx eeeexx eeeexx iixxxx eeieee iixxxx iixxxx ixxxxx eeeexx eeeexx eeeexx eeeexx iiiiee eeeexx eeeexx eeeexx iixxxx eeieee iixxxx iixxxx ixxxxx eeeexx eeeexx eeeexx eeeexx iiiiee eeeexx eeeexx eeeexx iixxxx eeieee iixxxx iixxxx ixxxxx eeeexx eeeexx eeeexx eeeexx eeeexx iiiiee eeeexx eeeexx iixxxx eeieee iixxxx iixxxx ixxxxx eeeexx eeeexx eeeexx eeeexx eeeexx iiiiee eeeexx eeeexx iixxxx eeieee iixxxx iixxxx ixxxxx eeeexx eeeexx eeeexx eeeexx eeeexx iiiiee eeeexx eeeexx iixxxx eeieee iixxxx iixxxx ixxxxx eeeexx eeeexx eeeexx eeeexx eeeexx iiiiee eeeexx eeeexx iixxxx eeieee iixxxx iixxxx ixxxxx eeeexx eeeexx eeeexx eeeexx eeeexx iiiiee eeeexx eeeexx iixxxx eeieee iixxxx iixxxx ixxxxx eeeexx eeeexx eeeexx eeeexx eeeexx iiiiee eeeexx eeeexx iixxxx eeieee iixxxx iixxxx ixxxxx eeeexx eeeexx eeeexx eeeexx eeeexx iiiiee eeeexx eeeexx iixxxx eeieee iixxxx iixxxx ixxxxx eeeexx eeeexx eeeexx eeeexx eeeexx iiiiee eeeexx eeeexx iixxxx eeieee iixxxx iixxxx ixxxxx eeeexx eeeexx eeeexx eeeexx eeeexx iiiiee eeeexx eeeexx iixxxx eeieee iixxxx iixxxx ixxxxx eeeexx eeeexx eeeexx eeeexx eeeexx iiiiee eeeexx eeeexx iixxxx eeieee iixxxx iixxxx ixxxxx eeeexx eeeexx eeeexx eeeexx eeeexx iiiiee eeeexx eeeexx iixxxx eeieee iixxxx iixxxx ixxxxx eeeexx eeeexx eeeexx eeeexx eeeexx iiiiee eeeexx eeeexx iixxxx eeieee iixxxx iixxxx ixxxxx eeeexx eeeexx eeeexx eeeexx eeeexx iiiiee eeeexx eeeexx iixxxx eeieee iixxxx iixxxx ixxxxx eeeexx eeeexx eeeexx eeeexx eeeexx iiiiee eeeexx eeeexx iixxxx eeieee iixxxx iixxxx ixxxxx eeeexx eeeexx eeeexx eeeexx eeeexx iiiiee eeeexx eeeexx iixxxx eeieee iixxxx iixxxx ixxxxx eeeexx eeeexx eeeexx eeeexx eeeexx iiiiee eeeexx eeeexx iixxxx eeieee iixxxx iixxxx ixxxxx eeeexx eeeexx eeeexx eeeexx eeeexx iiiiee eeeexx eeeexx iixxxx eeieee iixxxx iixxxx ixxxxx eeeexx eeeexx eeeexx\n"
     ]
    }
   ],
   "source": [
    "predict();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identical training loop as last time, but notice how much slower even a single step is (probably works better on colab, or just run overnight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode step: 1 of 334\n",
      "Decode step: 2 of 334\n",
      "Decode step: 3 of 334\n",
      "Decode step: 4 of 334\n",
      "Decode step: 5 of 334\n",
      "Decode step: 6 of 334\n",
      "Decode step: 7 of 334\n",
      "Decode step: 8 of 334\n",
      "Decode step: 9 of 334\n",
      "Decode step: 10 of 334\n",
      "Decode step: 11 of 334\n",
      "Decode step: 12 of 334\n",
      "Decode step: 13 of 334\n",
      "Decode step: 14 of 334\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-183-81757162af73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msource_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_seq_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_seq_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0menc_initial_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_dec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_seq_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_seq_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_initial_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch+1} Loss {loss.numpy():.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    501\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m       \u001b[0minitializer_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    406\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    407\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 408\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m                 ), args, kwargs)\n\u001b[0m\u001b[1;32m    903\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, options, args, kwargs, caller_fn_scope)\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/xs/rjxwv2hx1jsftlhjvsqm7t7r0000gp/T/tmp_8ummtqv.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[0;34m(source_seq, target_seq_in, target_seq_out, en_initial_states)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget_seq_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mde_state_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mde_state_h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m           \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mde_state_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mde_state_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget_seq_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mde_state_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mde_state_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'de_state_c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'de_state_h'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36mfor_stmt\u001b[0;34m(iter_, extra_test, body, get_state, set_state, init_vars, basic_symbol_names, composite_symbol_names)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcustom_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_py_for_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36m_py_for_stmt\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mextra_test\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextra_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/xs/rjxwv2hx1jsftlhjvsqm7t7r0000gp/T/tmp_8ummtqv.py\u001b[0m in \u001b[0;36mloop_body\u001b[0;34m(iterates, loss, de_state_c, de_state_h)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Decode step: {} of {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_seq_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mdecoder_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget_seq_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mlogit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mde_state_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mde_state_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdecoder_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mde_state_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mde_state_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget_seq_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mde_state_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mde_state_h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, options, args, kwargs, caller_fn_scope)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_cached_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misbuiltin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0m_attach_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    845\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m           optional_features=optional_features)\n\u001b[1;32m    233\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, options, args, kwargs, caller_fn_scope)\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/xs/rjxwv2hx1jsftlhjvsqm7t7r0000gp/T/tmpfu2rhw5m.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, sequence, state, encoder_output)\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunctionScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'call'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'call_scope'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTD\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcall_scope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0membed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'initial_state'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malignment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mlstm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, options, args, kwargs, caller_fn_scope)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_cached_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misbuiltin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    328\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'constants'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m   def call(self,\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    845\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    965\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m         (last_output, outputs, new_h, new_c,\n\u001b[0;32m--> 967\u001b[0;31m          runtime) = lstm_with_backend_selection(**normal_lstm_kwargs)\n\u001b[0m\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m       \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mlstm_with_backend_selection\u001b[0;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, activation, recurrent_activation)\u001b[0m\n\u001b[1;32m   1287\u001b[0m   last_output, outputs, new_h, new_c, runtime = defun_standard_lstm(\n\u001b[1;32m   1288\u001b[0m       **params)\n\u001b[0;32m-> 1289\u001b[0;31m   \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_cudnn_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2176\u001b[0m   \u001b[0mconcrete_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2177\u001b[0m   \u001b[0mconcrete_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2178\u001b[0;31m   \u001b[0mconcrete_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_gradient_functions_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2179\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36madd_gradient_functions_to_graph\u001b[0;34m(self, g)\u001b[0m\n\u001b[1;32m   1339\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m     forward_function, backward_function = (\n\u001b[0;32m-> 1341\u001b[0;31m         self._delayed_rewrite_functions.forward_backward())\n\u001b[0m\u001b[1;32m   1342\u001b[0m     \u001b[0mforward_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0mbackward_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mforward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mforward_backward\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mforward_backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m     \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_forward_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_function_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_construct_forward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    627\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m           \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m           func_graph=backwards_graph)\n\u001b[0m\u001b[1;32m    630\u001b[0m       \u001b[0mbackwards_graph_captures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackwards_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternal_captures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m       captures_from_forward = [\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_backprop_function\u001b[0;34m(*grad_ys)\u001b[0m\n\u001b[1;32m    617\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m           \u001b[0mgrad_ys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m           src_graph=self._func_graph)\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    693\u001b[0m                       ignore_existing=True):\n\u001b[1;32m    694\u001b[0m                     \u001b[0min_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m           \u001b[0m_LogOpGradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m           \u001b[0;31m# If no grad_fn is defined or none of out_grads is available,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Stats/tf_env/lib/python3.7/site-packages/tensorflow_core/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_LogOpGradients\u001b[0;34m(op, out_grads, in_grads)\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m   logging.vlog(1, \"  in  --> %s\",\n\u001b[0;32m--> 847\u001b[0;31m                \", \".join([x.name for x in out_grads if _FilterGrad(x)]))\n\u001b[0m\u001b[1;32m    848\u001b[0m   logging.vlog(1, \"  out --> %s\",\n\u001b[1;32m    849\u001b[0m                \", \".join([x.name for x in in_grads if _FilterGrad(x)]))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 2\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for batch, (source_seq, target_seq_in, target_seq_out) in enumerate(dataset.take(-1)):\n",
    "        enc_initial_states = enc_dec.init_states(source_seq.shape[0])\n",
    "        loss = train_step(source_seq, target_seq_in, target_seq_out, enc_initial_states)\n",
    "        print(loss.numpy())\n",
    "    print(f'Epoch {epoch+1} Loss {loss.numpy():.4f}')\n",
    "    \n",
    "    try:\n",
    "        predict();\n",
    "    except Exception:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GGCCAG GCAGCT CCCCGG CAGCCA GGGGAC GGGCGG GGCAGG CAGGAT GGGCCA TGCCCT CCTCCT GGCCCA GGACTC ACTGCC CAGACC CCGCCT GCAGAA GATCAT GCACAC CCGGAA GCGGCA CCAAGA CATGTT CCAGGA CCTGAA CCGGAA GCTGCA GCACGC AGCGGA GAAGGA CAAGGA GGTGCT GGGGCC GGACAG CAAGGT CTGGAG GGCAGG GAGGGG CGGGGT GGGGAG AGCCCT TAGGTC AGGCCA CCGTCT CCCTTC TTCCCT GGATTT GTGCAC TTCATC CATCCA TCCATC CATCCA TCCATT CGTTCA TTCATT CATTCA TTCGCC CATCCC TGAGGG CTGGCC TGACCC TGCCAT GCCAGA CTCTGG AGGCCA TGGCCA TACTGG GAGCTG AGCGGT CACGAG CCTGCT CCTGGG GCCAGG GGTCTG GATTGG GGTGGA GCCAAT CCAGGG CAGGGT CCCCAC AGCCTG ACCCGA CCGTGG GGTTCG CAACCT CTGCCA AGGCTG GGGAGA GGATCT GTGCCT GCCGCT GCCCAG CTCTGT TCTGGG CTCTTG TCCTGA AAGCCT CATCCT GTCCCC TGTCCC CTGTCC CCCACC TCCCGT CCCTTC CTCACT GATTCG TGTCTG CCTCCT CCCCCC TACTCC TCGGGC TCATGG CTCTCC CTCCGG GCCCCA CCCCTC CTGCAC CACGGG CCACCC AGCAGC CGGAAA AGCAGC AGACGC CCAACA AGAGGC CCTGGG AGAGCC TCCGGA AAGCCC ACGGGA CGCCCA CGTGGG TGAAGA AGGAGC TGGAGC CGCTGC AGCCGT CGCCGC TGGAGC TTCGCA GCGTGG AGTGGG AGAGGT CGGGCG CCACGA TCCCGC TGGTGG GCCAGG ACATCA TCGACC TCCAGA CCGAGG TCTGAG CGGGTG GGCGGC GGCCAC GCACTG GGCCAC GGAGGA GGGATG CTGCTC CGCCCG CTCCTG CCGCAG ACGGGC ACAGAC ACGCTC GCGGGC AGCGGG CCAGGC CCGCAC CCCGGC CTCAGG GCGCTC AGACGG CGGCCA GGCACA GGGCCC GCAGTG CTGGGA CCAGAG CCAGAT GCAGGA CAGGAG GCGGCC CGGCCA GCGGGC ACAGGG CACCAG AGGCCG AAGGTG CCTCAG ACTCCG CCCTCC TCGGGC CGAGGC CCAGCG GGXXXX\n",
      "iiiiie iiiiie eexxxx eexxxx eeexxx eeeexx eeeexx eeeexx eeeexx eeeexx iiiiee eeeexx eeeexx eeieee iixxxx iixxxx eeieee iixxxx eiieee <end>\n"
     ]
    }
   ],
   "source": [
    "predict();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next time: Transformers\n",
    "\n",
    "Attention seems interesting, but all the sequence model stuff gets in the way. What if [Attention Is All You Need](https://arxiv.org/abs/1706.03762)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
